{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "results_dir = \"Analyzer Results\"\n",
    "\n",
    "input_dir = \"TT Input\"\n",
    "\n",
    "\"\"\" output_dir = \"Top Tester Results\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a4b0fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataframes: ['RESULTS', 'RESULTS_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MERGED_EXP', 'RESULTS_MTT', 'RESULTS_MTT_MERGED', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_MTT_MERGED_EXP', 'RESULTS_TT', 'RESULTS_TT_MERGED', 'RESULTS_TT_MERGED_DATE', 'RESULTS_TT_MERGED_EXP', 'SegmentOrder']\n",
      "Fit dataframes: ['RESULTS_FIT', 'RESULTS_MERGED_DATE_FIT', 'RESULTS_MERGED_EXP_FIT', 'RESULTS_MERGED_FIT', 'RESULTS_MTT_FIT', 'RESULTS_MTT_MERGED_DATE_FIT', 'RESULTS_MTT_MERGED_EXP_FIT', 'RESULTS_MTT_MERGED_FIT', 'RESULTS_TT_FIT', 'RESULTS_TT_MERGED_DATE_FIT', 'RESULTS_TT_MERGED_EXP_FIT', 'RESULTS_TT_MERGED_FIT', 'SegmentOrder_FIT']\n",
      "Found 13 raw and 13 fit dataframes in Analyzer Results.\n",
      "\n",
      "Found 18 experiments, 9 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50, offset_PPI_4, offset_PPI_6, offset_PPI_8, offset_PPI_10, offset_PPI_12, offset_PPI_14, offset_PPI_16, offset_PPI_18, offset_PPI_20, offset_PPI_50\n",
      " reactionTime, peakTime, difference, peakValue, PTPA, PTTA, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "dfs = {}\n",
    "dfs_fit = {}\n",
    "\n",
    "files = [file for file in os.listdir(results_dir) if file.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(results_dir, file)\n",
    "    key = file.split('.')[0]\n",
    "    if key.endswith('_FIT'):\n",
    "        dfs_fit[key] = pd.read_excel(file_path)\n",
    "    else:\n",
    "        dfs[key] = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Raw dataframes:\", list(dfs.keys()))\n",
    "print(\"Fit dataframes:\", list(dfs_fit.keys()))\n",
    "print(f\"Found {len(dfs)} raw and {len(dfs_fit)} fit dataframes in {results_dir}.\")\n",
    "if len(dfs) != len(dfs_fit):\n",
    "    print(\"Warning: Mismatch between raw and fit dataframes!\")\n",
    "\n",
    "experiments = dfs[list(dfs.keys())[1]]['experiment'].unique().tolist()\n",
    "variables = dfs[list(dfs.keys())[1]].columns[4:].tolist()\n",
    "parameters = dfs[list(dfs.keys())[1]].columns[:4].tolist()\n",
    "print(f\"\\nFound {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbc39f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded RESULTS_MT10.xlsx into dataframe with key 'RESULTS_MT10'.\n",
      "Loaded RESULTS_MT20.xlsx into dataframe with key 'RESULTS_MT20'.\n",
      "Loaded RESULTS_MT30.xlsx into dataframe with key 'RESULTS_MT30'.\n",
      "Loaded RESULTS_MT40.xlsx into dataframe with key 'RESULTS_MT40'.\n",
      "Loaded RESULTS_MT50.xlsx into dataframe with key 'RESULTS_MT50'.\n",
      "Loaded RESULTS_T10.xlsx into dataframe with key 'RESULTS_T10'.\n",
      "Loaded RESULTS_T20.xlsx into dataframe with key 'RESULTS_T20'.\n",
      "Loaded RESULTS_T30.xlsx into dataframe with key 'RESULTS_T30'.\n",
      "Loaded RESULTS_T40.xlsx into dataframe with key 'RESULTS_T40'.\n",
      "Loaded RESULTS_T50.xlsx into dataframe with key 'RESULTS_T50'.\n",
      "All dataframes: ['RESULTS', 'RESULTS_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MERGED_EXP', 'RESULTS_MTT', 'RESULTS_MTT_MERGED', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_MTT_MERGED_EXP', 'RESULTS_TT', 'RESULTS_TT_MERGED', 'RESULTS_TT_MERGED_DATE', 'RESULTS_TT_MERGED_EXP', 'SegmentOrder', 'RESULTS_MT10', 'RESULTS_MT20', 'RESULTS_MT30', 'RESULTS_MT40', 'RESULTS_MT50', 'RESULTS_T10', 'RESULTS_T20', 'RESULTS_T30', 'RESULTS_T40', 'RESULTS_T50']\n",
      "\n",
      "Found 18 experiments, 9 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50, offset_PPI_4, offset_PPI_6, offset_PPI_8, offset_PPI_10, offset_PPI_12, offset_PPI_14, offset_PPI_16, offset_PPI_18, offset_PPI_20, offset_PPI_50\n",
      " reactionTime, peakTime, difference, peakValue, PTPA, PTTA, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "before = len(dfs)\n",
    "files = [file for file in os.listdir(input_dir) if file.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_dir, file)\n",
    "    key = file.split('.')[0]\n",
    "    dfs[key] = pd.read_excel(file_path)\n",
    "    print(f\"Loaded {file} into dataframe with key '{key}'.\")\n",
    "\n",
    "print(\"All dataframes:\", list(dfs.keys()))\n",
    "\n",
    "experiments = dfs[list(dfs.keys())[1]]['experiment'].unique().tolist()\n",
    "variables = dfs[list(dfs.keys())[1]].columns[4:].tolist()\n",
    "parameters = dfs[list(dfs.keys())[1]].columns[:4].tolist()\n",
    "print(f\"\\nFound {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c67d21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def compare_dataframes(df1, df2, parameters, variables):\n",
    "    results = []\n",
    "    # Get all unique parameter combinations in df1\n",
    "    param_combos = df1[parameters].drop_duplicates()\n",
    "    for _, combo in param_combos.iterrows():\n",
    "        # Filter both dataframes for this parameter combo\n",
    "        mask1 = (df1[parameters] == combo.values).all(axis=1)\n",
    "        mask2 = (df2[parameters] == combo.values).all(axis=1)\n",
    "        if mask1.sum() == 0 or mask2.sum() == 0:\n",
    "            continue  # Skip if combo not present in both\n",
    "        for var in variables:\n",
    "            data1 = df1.loc[mask1, var].dropna()\n",
    "            data2 = df2.loc[mask2, var].dropna()\n",
    "            if len(data1) < 2 or len(data2) < 2:\n",
    "                continue  # Need at least 2 samples for Mann-Whitney\n",
    "            stat, p = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "            results.append({\n",
    "                **dict(zip(parameters, combo.values)),\n",
    "                'variable': var,\n",
    "                'statistic': stat,\n",
    "                'p_value': p,\n",
    "                'n_df1': len(data1),\n",
    "                'n_df2': len(data2)\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89bc3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import ast\n",
    "\n",
    "def flatten_column(col):\n",
    "    # Flattens a column of lists, stringified lists, or scalars into a single list of numbers\n",
    "    out = []\n",
    "    for item in col.dropna():\n",
    "        if isinstance(item, list):\n",
    "            out.extend(item)\n",
    "        elif isinstance(item, str):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(item)\n",
    "                if isinstance(parsed, list):\n",
    "                    out.extend(parsed)\n",
    "                elif isinstance(parsed, (int, float, np.integer, np.floating)):\n",
    "                    out.append(parsed)\n",
    "            except Exception:\n",
    "                continue  # Ignore strings that can't be parsed\n",
    "        elif isinstance(item, (int, float, np.integer, np.floating)):\n",
    "            out.append(item)\n",
    "        # Ignore non-numeric, non-list\n",
    "    return pd.Series(out)\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "def compare_general_trends(df1, df2, variables):\n",
    "    summary = []\n",
    "    for var in variables:\n",
    "        flat1 = flatten_column(df1[var])\n",
    "        flat2 = flatten_column(df2[var])\n",
    "        if len(flat1) > 0 and len(flat2) > 0:\n",
    "            mean_diff = flat1.mean() - flat2.mean()\n",
    "            stats = {\n",
    "                'mean_difference': mean_diff,\n",
    "                'df1_median': flat1.median(),\n",
    "                'df1_std': flat1.std(),\n",
    "                'df1_n': flat1.count(),\n",
    "                'df2_median': flat2.median(),\n",
    "                'df2_std': flat2.std(),\n",
    "                'df2_n': flat2.count(),\n",
    "            }\n",
    "            summary.append({\n",
    "                'variable': var,\n",
    "                **stats\n",
    "            })\n",
    "        else:\n",
    "            summary.append({\n",
    "                'variable': var,\n",
    "                'mean_difference': 'no data',\n",
    "                'df1_median': 'no data',\n",
    "                'df1_std': 'no data',\n",
    "                'df1_n': len(flat1),\n",
    "                'df2_median': 'no data',\n",
    "                'df2_std': 'no data',\n",
    "                'df2_n': len(flat2),\n",
    "            })\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fd298ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def test_general_trend_significance(df1, df2, variables):\n",
    "    results = []\n",
    "    for var in variables:\n",
    "        flat1 = flatten_column(df1[var])\n",
    "        flat2 = flatten_column(df2[var])\n",
    "        if len(flat1) > 1 and len(flat2) > 1:\n",
    "            stat, p = mannwhitneyu(flat1, flat2, alternative='two-sided')\n",
    "            results.append({\n",
    "                'variable': var,\n",
    "                'n_df1': len(flat1),\n",
    "                'n_df2': len(flat2),\n",
    "                'statistic': stat,\n",
    "                'p_value': p\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'variable': var,\n",
    "                'n_df1': len(flat1),\n",
    "                'n_df2': len(flat2),\n",
    "                'statistic': 'no data',\n",
    "                'p_value': 'no data'\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "917ff8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfs['RESULTS_T10']\n",
    "df2 = dfs['RESULTS_MT10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f49da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "result_df = compare_dataframes(df1, df2, parameters, variables)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7885fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       variable  mean_difference  df1_median      df1_std  df1_n  df2_median  \\\n",
      "0  reactionTime        -0.343295       10.00     1.951810    171       10.00   \n",
      "1      peakTime         0.078816       30.00     6.633581    171       30.00   \n",
      "2    difference         0.422111       20.00     6.921547    171       20.00   \n",
      "3     peakValue        17.664747      138.00    63.514900    171      113.00   \n",
      "4          PTPA        17.037672      138.16    62.497836    171      113.69   \n",
      "5          PTTA        15.580123      124.08    57.929477    171      100.61   \n",
      "6           RMS         5.757767       48.49    24.497296    171       44.20   \n",
      "7           tau        -9.996915      128.32    53.181116    171      140.81   \n",
      "8           AUC       851.252639    11856.75  6113.397730    171    10704.35   \n",
      "\n",
      "       df2_std  df2_n  \n",
      "0     1.989860   1447  \n",
      "1     4.912407   1447  \n",
      "2     5.310162   1447  \n",
      "3    60.770962   1447  \n",
      "4    60.128009   1447  \n",
      "5    55.742306   1447  \n",
      "6    24.472297   1447  \n",
      "7    49.859830   1447  \n",
      "8  6427.479697   1447  \n"
     ]
    }
   ],
   "source": [
    "trend_df = compare_general_trends(df1, df2, variables)\n",
    "print(trend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5648b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10:\n",
      "       variable  mean_difference  df1_median      df1_std  df1_n  df2_median  \\\n",
      "0  reactionTime        -0.343295       10.00     1.951810    171       10.00   \n",
      "1      peakTime         0.078816       30.00     6.633581    171       30.00   \n",
      "2    difference         0.422111       20.00     6.921547    171       20.00   \n",
      "3     peakValue        17.664747      138.00    63.514900    171      113.00   \n",
      "4          PTPA        17.037672      138.16    62.497836    171      113.69   \n",
      "5          PTTA        15.580123      124.08    57.929477    171      100.61   \n",
      "6           RMS         5.757767       48.49    24.497296    171       44.20   \n",
      "7           tau        -9.996915      128.32    53.181116    171      140.81   \n",
      "8           AUC       851.252639    11856.75  6113.397730    171    10704.35   \n",
      "\n",
      "       df2_std  df2_n  \n",
      "0     1.989860   1447  \n",
      "1     4.912407   1447  \n",
      "2     5.310162   1447  \n",
      "3    60.770962   1447  \n",
      "4    60.128009   1447  \n",
      "5    55.742306   1447  \n",
      "6    24.472297   1447  \n",
      "7    49.859830   1447  \n",
      "8  6427.479697   1447  \n",
      "       variable  n_df1  n_df2  statistic   p_value\n",
      "0  reactionTime    171   1447   108563.0  0.002827\n",
      "1      peakTime    171   1447   119403.5  0.334882\n",
      "2    difference    171   1447   131870.0  0.121879\n",
      "3     peakValue    171   1447   145076.5  0.000219\n",
      "4          PTPA    171   1447   144707.5  0.000281\n",
      "5          PTTA    171   1447   144462.0  0.000331\n",
      "6           RMS    171   1447   141835.5  0.001716\n",
      "7           tau    171   1447   105780.0  0.001905\n",
      "8           AUC    171   1447   135887.0  0.035206\n",
      "Top 20:\n",
      "       variable  mean_difference  df1_median      df1_std  df1_n  df2_median  \\\n",
      "0  reactionTime        -0.245130       10.00     1.877671    339       10.00   \n",
      "1      peakTime         0.333379       30.00     6.569447    339       30.00   \n",
      "2    difference         0.578508       20.00     6.837900    339       20.00   \n",
      "3     peakValue        14.979150      132.00    63.277076    339      113.00   \n",
      "4          PTPA        14.669080      131.80    62.437900    339      113.02   \n",
      "5          PTTA        14.343240      119.05    58.858694    339       99.60   \n",
      "6           RMS         5.304086       48.49    25.079569    339       43.84   \n",
      "7           tau        -6.633734      131.65    51.626891    339      141.15   \n",
      "8           AUC       818.572426    11133.77  6473.885236    339    10630.78   \n",
      "\n",
      "       df2_std  df2_n  \n",
      "0     2.004887   1365  \n",
      "1     4.653540   1365  \n",
      "2     5.072776   1365  \n",
      "3    60.695008   1365  \n",
      "4    60.050522   1365  \n",
      "5    55.529855   1365  \n",
      "6    24.416407   1365  \n",
      "7    49.670252   1365  \n",
      "8  6400.247962   1365  \n",
      "       variable  n_df1  n_df2  statistic   p_value\n",
      "0  reactionTime    339   1365   211677.0  0.005697\n",
      "1      peakTime    339   1365   235798.5  0.481124\n",
      "2    difference    339   1365   251708.0  0.005858\n",
      "3     peakValue    339   1365   265319.0  0.000028\n",
      "4          PTPA    339   1365   265029.0  0.000033\n",
      "5          PTTA    339   1365   265858.0  0.000021\n",
      "6           RMS    339   1365   261616.5  0.000191\n",
      "7           tau    339   1365   207459.5  0.003194\n",
      "8           AUC    339   1365   250574.0  0.017854\n",
      "Top 30:\n",
      "       variable  mean_difference  df1_median      df1_std  df1_n  df2_median  \\\n",
      "0  reactionTime        -0.105460      10.000     1.896574    506       10.00   \n",
      "1      peakTime         0.639640      30.000     6.110811    506       30.00   \n",
      "2    difference         0.745101      20.000     6.403287    506       20.00   \n",
      "3     peakValue        12.900714     125.000    63.365713    506      112.00   \n",
      "4          PTPA        12.712861     124.920    62.508161    506      112.68   \n",
      "5          PTTA        12.646897     113.855    59.001448    506       99.27   \n",
      "6           RMS         4.917829      47.755    25.533483    506       43.54   \n",
      "7           tau        -5.469787     134.850    48.113892    506      141.18   \n",
      "8           AUC       778.855715   11091.885  6415.422542    506    10569.81   \n",
      "\n",
      "       df2_std  df2_n  \n",
      "0     2.019352   1281  \n",
      "1     4.637739   1281  \n",
      "2     5.076026   1281  \n",
      "3    60.505857   1281  \n",
      "4    59.832819   1281  \n",
      "5    55.281929   1281  \n",
      "6    24.304764   1281  \n",
      "7    50.189644   1281  \n",
      "8  6407.091224   1281  \n",
      "       variable  n_df1  n_df2  statistic   p_value\n",
      "0  reactionTime    506   1281   309381.5  0.088257\n",
      "1      peakTime    506   1281   338736.0  0.054507\n",
      "2    difference    506   1281   348143.0  0.007205\n",
      "3     peakValue    506   1281   363830.0  0.000053\n",
      "4          PTPA    506   1281   363743.5  0.000055\n",
      "5          PTTA    506   1281   365514.0  0.000025\n",
      "6           RMS    506   1281   361403.5  0.000147\n",
      "7           tau    506   1281   299643.0  0.012851\n",
      "8           AUC    506   1281   350703.0  0.006776\n",
      "Top 40:\n",
      "       variable  mean_difference  df1_median      df1_std  df1_n  df2_median  \\\n",
      "0  reactionTime        -0.096187      10.000     1.864547    668       10.00   \n",
      "1      peakTime         0.502221      30.000     5.891882    668       30.00   \n",
      "2    difference         0.598409      20.000     6.216349    668       20.00   \n",
      "3     peakValue        11.401100     123.000    63.568011    668      112.00   \n",
      "4          PTPA        11.249917     123.575    62.851236    668      112.34   \n",
      "5          PTTA        10.744875     111.845    59.217253    668       99.27   \n",
      "6           RMS         4.292142      46.840    25.349588    668       43.46   \n",
      "7           tau        -3.917408     135.040    49.151661    668      141.36   \n",
      "8           AUC       694.933513   11023.485  6385.128394    668    10543.41   \n",
      "\n",
      "       df2_std  df2_n  \n",
      "0     2.020604   1201  \n",
      "1     4.592782   1201  \n",
      "2     5.025827   1201  \n",
      "3    60.254074   1201  \n",
      "4    59.564668   1201  \n",
      "5    54.999141   1201  \n",
      "6    24.231657   1201  \n",
      "7    49.890110   1201  \n",
      "8  6402.844953   1201  \n",
      "       variable  n_df1  n_df2  statistic   p_value\n",
      "0  reactionTime    668   1201   385434.5  0.109662\n",
      "1      peakTime    668   1201   412667.0  0.182617\n",
      "2    difference    668   1201   421086.5  0.049946\n",
      "3     peakValue    668   1201   443106.0  0.000174\n",
      "4          PTPA    668   1201   442884.0  0.000189\n",
      "5          PTTA    668   1201   442402.0  0.000224\n",
      "6           RMS    668   1201   440967.0  0.000367\n",
      "7           tau    668   1201   376821.0  0.029675\n",
      "8           AUC    668   1201   430374.5  0.008920\n",
      "Top 50:\n",
      "       variable  mean_difference  df1_median      df1_std  df1_n  df2_median  \\\n",
      "0  reactionTime        -0.032855       10.00     1.897814    837      10.000   \n",
      "1      peakTime         0.298686       30.00     5.570098    837      30.000   \n",
      "2    difference         0.331541       20.00     5.953776    837      20.000   \n",
      "3     peakValue         7.479391      120.00    63.017700    837     113.000   \n",
      "4          PTPA         7.429910      119.39    62.382742    837     113.350   \n",
      "5          PTTA         7.171852      108.66    58.477266    837     100.435   \n",
      "6           RMS         2.725588       45.77    25.086025    837      43.760   \n",
      "7           tau        -2.836523      136.50    49.796143    837     141.540   \n",
      "8           AUC       404.404818    10907.08  6393.580470    837   10606.880   \n",
      "\n",
      "       df2_std  df2_n  \n",
      "0     1.989421   1116  \n",
      "1     4.604166   1116  \n",
      "2     4.999572   1116  \n",
      "3    59.951744   1116  \n",
      "4    59.234982   1116  \n",
      "5    54.652367   1116  \n",
      "6    24.134924   1116  \n",
      "7    49.674226   1116  \n",
      "8  6366.926895   1116  \n",
      "       variable  n_df1  n_df2  statistic   p_value\n",
      "0  reactionTime    837   1116   462688.0  0.687498\n",
      "1      peakTime    837   1116   472703.0  0.552546\n",
      "2    difference    837   1116   475564.0  0.447762\n",
      "3     peakValue    837   1116   497124.0  0.014734\n",
      "4          PTPA    837   1116   497023.0  0.015073\n",
      "5          PTTA    837   1116   496624.0  0.016473\n",
      "6           RMS    837   1116   495073.0  0.023057\n",
      "7           tau    837   1116   442023.0  0.042467\n",
      "8           AUC    837   1116   484859.5  0.148642\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10:\")\n",
    "trend_df = compare_general_trends(dfs['RESULTS_T10'], dfs['RESULTS_MT10'], variables)\n",
    "print(trend_df)\n",
    "sig_df = test_general_trend_significance(dfs['RESULTS_T10'], dfs['RESULTS_MT10'], variables)\n",
    "print(sig_df)\n",
    "\n",
    "print(\"Top 20:\")\n",
    "trend_df = compare_general_trends(dfs['RESULTS_T20'], dfs['RESULTS_MT20'], variables)\n",
    "print(trend_df)\n",
    "sig_df = test_general_trend_significance(dfs['RESULTS_T20'], dfs['RESULTS_MT20'], variables)\n",
    "print(sig_df)\n",
    "\n",
    "print(\"Top 30:\")\n",
    "trend_df = compare_general_trends(dfs['RESULTS_T30'], dfs['RESULTS_MT30'], variables)\n",
    "print(trend_df)\n",
    "sig_df = test_general_trend_significance(dfs['RESULTS_T30'], dfs['RESULTS_MT30'], variables)\n",
    "print(sig_df)\n",
    "\n",
    "print(\"Top 40:\")\n",
    "trend_df = compare_general_trends(dfs['RESULTS_T40'], dfs['RESULTS_MT40'], variables)\n",
    "print(trend_df)\n",
    "sig_df = test_general_trend_significance(dfs['RESULTS_T40'], dfs['RESULTS_MT40'], variables)\n",
    "print(sig_df)\n",
    "\n",
    "print(\"Top 50:\")\n",
    "trend_df = compare_general_trends(dfs['RESULTS_T50'], dfs['RESULTS_MT50'], variables)\n",
    "print(trend_df)\n",
    "sig_df = test_general_trend_significance(dfs['RESULTS_T50'], dfs['RESULTS_MT50'], variables)\n",
    "print(sig_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
