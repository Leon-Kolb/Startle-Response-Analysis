{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "351d88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "results_dir = \"Analyzer Results\"\n",
    "\n",
    "input_dir = \"TT Input\"\n",
    "\n",
    "output_dir = \"Top Tester Results\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9a4b0fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataframes: ['RESULTS', 'RESULTS_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MERGED_EXP', 'RESULTS_MTT', 'RESULTS_MTT_MERGED', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_MTT_MERGED_EXP', 'RESULTS_TT', 'RESULTS_TT_MERGED', 'RESULTS_TT_MERGED_DATE', 'RESULTS_TT_MERGED_EXP', 'SegmentOrder']\n",
      "Fit dataframes: ['RESULTS_FIT', 'RESULTS_MERGED_DATE_FIT', 'RESULTS_MERGED_EXP_FIT', 'RESULTS_MERGED_FIT', 'RESULTS_MTT_FIT', 'RESULTS_MTT_MERGED_DATE_FIT', 'RESULTS_MTT_MERGED_EXP_FIT', 'RESULTS_MTT_MERGED_FIT', 'RESULTS_TT_FIT', 'RESULTS_TT_MERGED_DATE_FIT', 'RESULTS_TT_MERGED_EXP_FIT', 'RESULTS_TT_MERGED_FIT', 'SegmentOrder_FIT']\n",
      "Found 13 raw and 13 fit dataframes in Analyzer Results.\n",
      "\n",
      "Found 18 experiments, 9 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50, offset_PPI_4, offset_PPI_6, offset_PPI_8, offset_PPI_10, offset_PPI_12, offset_PPI_14, offset_PPI_16, offset_PPI_18, offset_PPI_20, offset_PPI_50\n",
      " reactionTime, peakTime, difference, peakValue, PTPA, PTTA, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "dfs = {}\n",
    "dfs_fit = {}\n",
    "\n",
    "files = [file for file in os.listdir(results_dir) if file.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(results_dir, file)\n",
    "    key = file.split('.')[0]\n",
    "    if key.endswith('_FIT'):\n",
    "        dfs_fit[key] = pd.read_excel(file_path)\n",
    "    else:\n",
    "        dfs[key] = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Raw dataframes:\", list(dfs.keys()))\n",
    "print(\"Fit dataframes:\", list(dfs_fit.keys()))\n",
    "print(f\"Found {len(dfs)} raw and {len(dfs_fit)} fit dataframes in {results_dir}.\")\n",
    "if len(dfs) != len(dfs_fit):\n",
    "    print(\"Warning: Mismatch between raw and fit dataframes!\")\n",
    "\n",
    "experiments = dfs[list(dfs.keys())[1]]['experiment'].unique().tolist()\n",
    "variables = dfs[list(dfs.keys())[1]].columns[4:].tolist()\n",
    "parameters = dfs[list(dfs.keys())[1]].columns[:4].tolist()\n",
    "print(f\"\\nFound {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fbc39f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded RESULTS_MT10.xlsx into dataframe with key 'RESULTS_MT10'.\n",
      "Loaded RESULTS_MT20.xlsx into dataframe with key 'RESULTS_MT20'.\n",
      "Loaded RESULTS_MT30.xlsx into dataframe with key 'RESULTS_MT30'.\n",
      "Loaded RESULTS_T10.xlsx into dataframe with key 'RESULTS_T10'.\n",
      "Loaded RESULTS_T20.xlsx into dataframe with key 'RESULTS_T20'.\n",
      "Loaded RESULTS_T30.xlsx into dataframe with key 'RESULTS_T30'.\n",
      "All dataframes: ['RESULTS', 'RESULTS_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MERGED_EXP', 'RESULTS_MTT', 'RESULTS_MTT_MERGED', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_MTT_MERGED_EXP', 'RESULTS_TT', 'RESULTS_TT_MERGED', 'RESULTS_TT_MERGED_DATE', 'RESULTS_TT_MERGED_EXP', 'SegmentOrder', 'RESULTS_MT10', 'RESULTS_MT20', 'RESULTS_MT30', 'RESULTS_T10', 'RESULTS_T20', 'RESULTS_T30']\n",
      "\n",
      "Found 18 experiments, 9 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50, offset_PPI_4, offset_PPI_6, offset_PPI_8, offset_PPI_10, offset_PPI_12, offset_PPI_14, offset_PPI_16, offset_PPI_18, offset_PPI_20, offset_PPI_50\n",
      " reactionTime, peakTime, difference, peakValue, PTPA, PTTA, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "before = len(dfs)\n",
    "files = [file for file in os.listdir(input_dir) if file.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_dir, file)\n",
    "    key = file.split('.')[0]\n",
    "    dfs[key] = pd.read_excel(file_path)\n",
    "    print(f\"Loaded {file} into dataframe with key '{key}'.\")\n",
    "\n",
    "print(\"All dataframes:\", list(dfs.keys()))\n",
    "\n",
    "experiments = dfs[list(dfs.keys())[1]]['experiment'].unique().tolist()\n",
    "variables = dfs[list(dfs.keys())[1]].columns[4:].tolist()\n",
    "parameters = dfs[list(dfs.keys())[1]].columns[:4].tolist()\n",
    "print(f\"\\nFound {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c67d21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def compare_dataframes(df1, df2, parameters, variables):\n",
    "    results = []\n",
    "    # Get all unique parameter combinations in df1\n",
    "    param_combos = df1[parameters].drop_duplicates()\n",
    "    for _, combo in param_combos.iterrows():\n",
    "        # Filter both dataframes for this parameter combo\n",
    "        mask1 = (df1[parameters] == combo.values).all(axis=1)\n",
    "        mask2 = (df2[parameters] == combo.values).all(axis=1)\n",
    "        if mask1.sum() == 0 or mask2.sum() == 0:\n",
    "            continue  # Skip if combo not present in both\n",
    "        for var in variables:\n",
    "            data1 = df1.loc[mask1, var].dropna()\n",
    "            data2 = df2.loc[mask2, var].dropna()\n",
    "            if len(data1) < 2 or len(data2) < 2:\n",
    "                continue  # Need at least 2 samples for Mann-Whitney\n",
    "            stat, p = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "            results.append({\n",
    "                **dict(zip(parameters, combo.values)),\n",
    "                'variable': var,\n",
    "                'statistic': stat,\n",
    "                'p_value': p,\n",
    "                'n_df1': len(data1),\n",
    "                'n_df2': len(data2)\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "89bc3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import ast\n",
    "\n",
    "def flatten_column(col):\n",
    "    # Flattens a column of lists, stringified lists, or scalars into a single list of numbers\n",
    "    out = []\n",
    "    for item in col.dropna():\n",
    "        if isinstance(item, list):\n",
    "            out.extend(item)\n",
    "        elif isinstance(item, str):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(item)\n",
    "                if isinstance(parsed, list):\n",
    "                    out.extend(parsed)\n",
    "                elif isinstance(parsed, (int, float, np.integer, np.floating)):\n",
    "                    out.append(parsed)\n",
    "            except Exception:\n",
    "                continue  # Ignore strings that can't be parsed\n",
    "        elif isinstance(item, (int, float, np.integer, np.floating)):\n",
    "            out.append(item)\n",
    "        # Ignore non-numeric, non-list\n",
    "    return pd.Series(out)\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "def compare_general_trends(df1, df2, variables):\n",
    "    summary = []\n",
    "    for var in variables:\n",
    "        flat1 = flatten_column(df1[var])\n",
    "        flat2 = flatten_column(df2[var])\n",
    "        if len(flat1) > 0 and len(flat2) > 0:\n",
    "            stats1 = {\n",
    "                'mean': flat1.mean(),\n",
    "                'median': flat1.median(),\n",
    "                'std': flat1.std(),\n",
    "                'n': flat1.count()\n",
    "            }\n",
    "            stats2 = {\n",
    "                'mean': flat2.mean(),\n",
    "                'median': flat2.median(),\n",
    "                'std': flat2.std(),\n",
    "                'n': flat2.count()\n",
    "            }\n",
    "            summary.append({\n",
    "                'variable': var,\n",
    "                'df1_mean': stats1['mean'],\n",
    "                'df1_median': stats1['median'],\n",
    "                'df1_std': stats1['std'],\n",
    "                'df1_n': stats1['n'],\n",
    "                'df2_mean': stats2['mean'],\n",
    "                'df2_median': stats2['median'],\n",
    "                'df2_std': stats2['std'],\n",
    "                'df2_n': stats2['n'],\n",
    "            })\n",
    "        else:\n",
    "            summary.append({\n",
    "                'variable': var,\n",
    "                'df1_mean': 'no data',\n",
    "                'df1_median': 'no data',\n",
    "                'df1_std': 'no data',\n",
    "                'df1_n': len(flat1),\n",
    "                'df2_mean': 'no data',\n",
    "                'df2_median': 'no data',\n",
    "                'df2_std': 'no data',\n",
    "                'df2_n': len(flat2),\n",
    "            })\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6fd298ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def test_general_trend_significance(df1, df2, variables):\n",
    "    results = []\n",
    "    for var in variables:\n",
    "        flat1 = flatten_column(df1[var])\n",
    "        flat2 = flatten_column(df2[var])\n",
    "        if len(flat1) > 1 and len(flat2) > 1:\n",
    "            stat, p = mannwhitneyu(flat1, flat2, alternative='two-sided')\n",
    "            results.append({\n",
    "                'variable': var,\n",
    "                'n_df1': len(flat1),\n",
    "                'n_df2': len(flat2),\n",
    "                'statistic': stat,\n",
    "                'p_value': p\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'variable': var,\n",
    "                'n_df1': len(flat1),\n",
    "                'n_df2': len(flat2),\n",
    "                'statistic': 'no data',\n",
    "                'p_value': 'no data'\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "917ff8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfs['RESULTS_T30']\n",
    "df2 = dfs['RESULTS_MT30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3f49da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "result_df = compare_dataframes(df1, df2, parameters, variables)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7885fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       variable      df1_mean  df1_median      df1_std  df1_n      df2_mean  \\\n",
      "0  reactionTime     10.494071      10.000     1.896574    506     10.599532   \n",
      "1      peakTime     31.023715      30.000     6.110811    506     30.384075   \n",
      "2    difference     20.529644      20.000     6.403287    506     19.784543   \n",
      "3     peakValue    134.675889     125.000    63.365713    506    121.775176   \n",
      "4          PTPA    134.327787     124.920    62.508161    506    121.614926   \n",
      "5          PTTA    122.229723     113.855    59.001448    506    109.582826   \n",
      "6           RMS     52.534901      47.755    25.533483    506     47.617073   \n",
      "7           tau    133.718300     134.850    48.113892    506    139.188087   \n",
      "8           AUC  12893.197213   11091.885  6415.422542    506  12114.341499   \n",
      "\n",
      "   df2_median      df2_std  df2_n  \n",
      "0       10.00     2.019352   1281  \n",
      "1       30.00     4.637739   1281  \n",
      "2       20.00     5.076026   1281  \n",
      "3      112.00    60.505857   1281  \n",
      "4      112.68    59.832819   1281  \n",
      "5       99.27    55.281929   1281  \n",
      "6       43.54    24.304764   1281  \n",
      "7      141.18    50.189644   1281  \n",
      "8    10569.81  6407.091224   1281  \n"
     ]
    }
   ],
   "source": [
    "trend_df = compare_general_trends(df1, df2, variables)\n",
    "print(trend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5648b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       variable  n_df1  n_df2  statistic   p_value\n",
      "0  reactionTime    506   1281   309381.5  0.088257\n",
      "1      peakTime    506   1281   338736.0  0.054507\n",
      "2    difference    506   1281   348143.0  0.007205\n",
      "3     peakValue    506   1281   363830.0  0.000053\n",
      "4          PTPA    506   1281   363743.5  0.000055\n",
      "5          PTTA    506   1281   365514.0  0.000025\n",
      "6           RMS    506   1281   361403.5  0.000147\n",
      "7           tau    506   1281   299643.0  0.012851\n",
      "8           AUC    506   1281   350703.0  0.006776\n"
     ]
    }
   ],
   "source": [
    "sig_df = test_general_trend_significance(df1, df2, variables)\n",
    "print(sig_df)\n",
    "# Optionally save:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
