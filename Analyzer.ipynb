{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "01fa7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro, boxcox, ttest_ind, mannwhitneyu, pearsonr, friedmanchisquare, kruskal, kstest, \\\n",
    "    lognorm, gamma, weibull_min, probplot, f_oneway, linregress, norm, spearmanr, ttest_1samp, wilcoxon \n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, mixedlm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "89cb28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"Results\" # input directory\n",
    "\n",
    "number = \"J\" # results to analyze (subfolder name, can be an integer or string)\n",
    "\n",
    "recording_order = (15, 2, 1, 6, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ae09f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ['RESULTS', 'RESULTS_MTT', 'RESULTS_TT'] in Results\\J.\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "results_dir = os.path.join(input_dir, str(number))\n",
    "files = [file for file in os.listdir(results_dir) if file.endswith(('.xlsx', '.xls')) and not file.startswith('OVERVIEW')]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(results_dir, file)\n",
    "    dfs[file.split('.')[0]] = pd.read_excel(file_path)\n",
    "\n",
    "framenames = list(dfs.keys())\n",
    "results = framenames[0]\n",
    "results_mtt = framenames[1]\n",
    "results_tt = framenames[2]\n",
    "\n",
    "print(f\"Found {framenames} in {results_dir}.\")\n",
    "\n",
    "framenames.append('RESULTS_MERGED')\n",
    "framenames.append('RESUlTS_MERGED_MTT')\n",
    "framenames.append('RESULTS_MERGED_TT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ab8f4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 experiments, 7 variables and 4 parameters:\n",
      " tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50, offset_PPI_4, offset_PPI_6, offset_PPI_8, offset_PPI_10, offset_PPI_12, offset_PPI_14, offset_PPI_16, offset_PPI_18, offset_PPI_20, offset_PPI_50\n",
      " reactionTime, peakTime, difference, peakValue, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "experiments = dfs[results]['experiment'].unique().tolist()\n",
    "variables = dfs[results].columns[4:].tolist()\n",
    "parameters = dfs[results].columns[:4].tolist()\n",
    "print(f\"Found {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "80bd6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_list_columns(df):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        # Try to convert string representations of lists to actual lists\n",
    "        if df_copy[col].apply(lambda x: isinstance(x, list) or (isinstance(x, str) and x.startswith('['))).any():\n",
    "            df_copy[col] = df_copy[col].apply(\n",
    "                lambda x: np.mean(ast.literal_eval(x)) if isinstance(x, str) and x.startswith('[') else np.mean(x) if isinstance(x, list) else x\n",
    "            )\n",
    "    return df_copy\n",
    "\n",
    "# Create merged DataFrames with averaged values\n",
    "dfs['RESULTS_MERGED'] = average_list_columns(dfs[results])\n",
    "dfs['RESULTS_MTT_MERGED'] = average_list_columns(dfs[results_mtt])\n",
    "dfs['RESULTS_TT_MERGED'] = average_list_columns(dfs[results_tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9cfcbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_across_dates(df):\n",
    "    # Group by all columns except 'date' and the variables, then average variables across dates\n",
    "    group_cols = [col for col in df.columns if col not in variables and col != 'date']\n",
    "    averaged = df.groupby(group_cols, as_index=False)[variables].mean()\n",
    "    return averaged\n",
    "\n",
    "# Create merged DataFrames with averaged values\n",
    "dfs['RESULTS_MERGED'] = average_list_columns(dfs[results])\n",
    "dfs['RESULTS_MTT_MERGED'] = average_list_columns(dfs[results_mtt])\n",
    "dfs['RESULTS_TT_MERGED'] = average_list_columns(dfs[results_tt])\n",
    "\n",
    "# Create date-averaged versions of each merged DataFrame\n",
    "dfs['RESULTS_MERGED_DATE'] = average_across_dates(dfs['RESULTS_MERGED'])\n",
    "dfs['RESULTS_MTT_MERGED_DATE'] = average_across_dates(dfs['RESULTS_MTT_MERGED'])\n",
    "dfs['RESULTS_TT_MERGED_DATE'] = average_across_dates(dfs['RESULTS_TT_MERGED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f00fd660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RESULTS', 'RESULTS_MTT', 'RESULTS_TT', 'RESULTS_MERGED', 'RESULTS_MTT_MERGED', 'RESULTS_TT_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_TT_MERGED_DATE']\n"
     ]
    }
   ],
   "source": [
    "print(list(dfs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771bdf0",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1710b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "RESULTS_MTT\n",
      "RESULTS_TT\n",
      "RESULTS_MERGED\n",
      "RESULTS_MTT_MERGED\n",
      "RESULTS_TT_MERGED\n",
      "RESULTS_MERGED_DATE\n",
      "RESULTS_MTT_MERGED_DATE\n",
      "RESULTS_TT_MERGED_DATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Galahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "non_parametric_dfs = {}\n",
    "for name, df in dfs.items():\n",
    "    print(name)\n",
    "    if not name.endswith('_MERGED'):\n",
    "        continue  # Only process merged dataframes\n",
    "    non_parametric = pd.DataFrame(columns=['experiment', 'var'])\n",
    "    not_enough_data = 0\n",
    "    for var in variables:\n",
    "        for exp in experiments:\n",
    "            for sex in ['male', 'female']:\n",
    "                data = df[(df['sex'] == sex) & (df['experiment'] == exp)][var].dropna()\n",
    "                if len(data) > 2:\n",
    "                    stat, p = shapiro(data)\n",
    "                    if p < 0.05:\n",
    "                        non_parametric = pd.concat(\n",
    "                            [non_parametric, pd.DataFrame({'experiment': [exp], 'var': [var]})],\n",
    "                            ignore_index=True\n",
    "                        )\n",
    "                else:\n",
    "                    not_enough_data += 1\n",
    "    non_parametric_dfs[name] = non_parametric\n",
    "    #print(f\"Non-parametric entries in {name}: {len(non_parametric)}\")\n",
    "    #if not_enough_data != 0: print(f\"Warning, not enough data for {not_enough_data} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dff3c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "37\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(non_parametric_dfs['RESULTS_MERGED']))\n",
    "print(len(non_parametric_dfs['RESULTS_MTT_MERGED']))\n",
    "print(len(non_parametric_dfs['RESULTS_TT_MERGED']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfac2d3",
   "metadata": {},
   "source": [
    "### Expand non-parametric tests to all variations of gap duration or offset PPI if one of the variations shows significant deviations from normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5f3b2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          experiment           var\n",
      "0     gap_duration_4  reactionTime\n",
      "1     gap_duration_8  reactionTime\n",
      "2    gap_duration_10  reactionTime\n",
      "3    gap_duration_50  reactionTime\n",
      "4       offset_PPI_6  reactionTime\n",
      "..               ...           ...\n",
      "433    offset_PPI_50           tau\n",
      "434   gap_duration_4           AUC\n",
      "435   gap_duration_8           AUC\n",
      "436  gap_duration_20           AUC\n",
      "437  gap_duration_50           AUC\n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "gap_durations = ['gap_duration_4', 'gap_duration_8', 'gap_duration_10', 'gap_duration_20', 'gap_duration_50']\n",
    "offset_exps = [exp for exp in dfs[results]['experiment'].unique() if 'offset' in str(exp).lower()]\n",
    "\n",
    "# Concatenate and drop duplicates as before\n",
    "dfs_to_merge = [\n",
    "    non_parametric_dfs['RESULTS_MERGED'],\n",
    "    non_parametric_dfs['RESULTS_MTT_MERGED'],\n",
    "    non_parametric_dfs['RESULTS_TT_MERGED']\n",
    "]\n",
    "non_parametric = pd.concat(dfs_to_merge, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Extend: for each row with \"gap_duration\" in experiment, add all gap_duration_* for that var\n",
    "rows_to_add = []\n",
    "for _, row in non_parametric.iterrows():\n",
    "    if \"gap_duration\" in row['experiment']:\n",
    "        for gap_exp in gap_durations:\n",
    "            if gap_exp != row['experiment']:\n",
    "                new_row = row.copy()\n",
    "                new_row['experiment'] = gap_exp\n",
    "                rows_to_add.append(new_row)\n",
    "    if \"offset\" in row['experiment']:\n",
    "        for offset_exp in offset_exps:\n",
    "            if offset_exp != row['experiment']:\n",
    "                new_row = row.copy()\n",
    "                new_row['experiment'] = offset_exp\n",
    "                rows_to_add.append(new_row)\n",
    "\n",
    "\n",
    "# Add the new rows and drop duplicates again\n",
    "if rows_to_add:\n",
    "    non_parametric = pd.concat([non_parametric, pd.DataFrame(rows_to_add)], ignore_index=True).drop_duplicates()\n",
    "\n",
    "print(non_parametric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0122b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(df1, df2, variables, group_cols=None, test='auto', non_parametric=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compare all metrics (variables) in df1 to df2.\n",
    "    If group_cols is provided, compare within each group.\n",
    "    test: 'auto' (choose t-test or Mann-Whitney based on normality or non_parametric list), 'ttest', or 'mannwhitney'\n",
    "    non_parametric: DataFrame with columns ['experiment', 'var'] indicating which (experiment, variable) pairs to use non-parametric test for.\n",
    "    alpha: significance threshold for p-value.\n",
    "    Returns a DataFrame with only significant results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if group_cols is None:\n",
    "        group_cols = []\n",
    "    for var in variables:\n",
    "        if group_cols:\n",
    "            groups = df1[group_cols].drop_duplicates()\n",
    "            for _, group_vals in groups.iterrows():\n",
    "                group_dict = group_vals.to_dict()\n",
    "                mask1 = np.ones(len(df1), dtype=bool)\n",
    "                mask2 = np.ones(len(df2), dtype=bool)\n",
    "                for col in group_cols:\n",
    "                    mask1 &= (df1[col] == group_dict[col])\n",
    "                    mask2 &= (df2[col] == group_dict[col])\n",
    "                vals1 = df1.loc[mask1, var].dropna()\n",
    "                vals2 = df2.loc[mask2, var].dropna()\n",
    "                if len(vals1) < 2 or len(vals2) < 2:\n",
    "                    continue\n",
    "                is_non_parametric = False\n",
    "                if non_parametric is not None:\n",
    "                    experiment = group_dict['experiment'] if 'experiment' in group_cols else None\n",
    "                    if experiment is not None:\n",
    "                        is_non_parametric = ((non_parametric['experiment'] == experiment) & (non_parametric['var'] == var)).any()\n",
    "                if test == 'auto':\n",
    "                    if is_non_parametric:\n",
    "                        stat, p = mannwhitneyu(vals1, vals2)\n",
    "                        test_used = 'mannwhitney'\n",
    "                    else:\n",
    "                        stat, p = ttest_ind(vals1, vals2)\n",
    "                        test_used = 'ttest'\n",
    "                elif test == 'ttest':\n",
    "                    stat, p = ttest_ind(vals1, vals2)\n",
    "                    test_used = 'ttest'\n",
    "                else:\n",
    "                    stat, p = mannwhitneyu(vals1, vals2)\n",
    "                    test_used = 'mannwhitney'\n",
    "                if p < alpha:\n",
    "                    results.append({**group_dict, 'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "        else:\n",
    "            vals1 = df1[var].dropna()\n",
    "            vals2 = df2[var].dropna()\n",
    "            if len(vals1) < 2 or len(vals2) < 2:\n",
    "                continue\n",
    "            is_non_parametric = False\n",
    "            if non_parametric is not None:\n",
    "                is_non_parametric = (non_parametric['var'] == var).any()\n",
    "            if test == 'auto':\n",
    "                if is_non_parametric:\n",
    "                    stat, p = mannwhitneyu(vals1, vals2)\n",
    "                    test_used = 'mannwhitney'\n",
    "                else:\n",
    "                    stat, p = ttest_ind(vals1, vals2)\n",
    "                    test_used = 'ttest'\n",
    "            elif test == 'ttest':\n",
    "                stat, p = ttest_ind(vals1, vals2)\n",
    "                test_used = 'ttest'\n",
    "            else:\n",
    "                stat, p = mannwhitneyu(vals1, vals2)\n",
    "                test_used = 'mannwhitney'\n",
    "            if p < alpha:\n",
    "                results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "739ec47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant differences found for date-averaged comparison.\n"
     ]
    }
   ],
   "source": [
    "comparison_df_date = compare_metrics(\n",
    "    dfs['RESULTS_MERGED'],\n",
    "    dfs['RESULTS_MERGED_DATE'],\n",
    "    variables,\n",
    "    group_cols=['experiment'],\n",
    "    non_parametric=non_parametric\n",
    ")\n",
    "print(comparison_df_date) if not comparison_df_date.empty else print(\"No significant differences found for date-averaged comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18336f45",
   "metadata": {},
   "source": [
    "### -> we can merge across dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "48a84a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       variable    stat         p         test\n",
      "0  reactionTime  2779.5  0.000383  mannwhitney\n",
      "1      peakTime  3201.0  0.021714  mannwhitney\n",
      "2     peakValue  4724.0  0.032432  mannwhitney\n",
      "3           tau  2844.0  0.000981  mannwhitney\n"
     ]
    }
   ],
   "source": [
    "# Average across animals, dates, and experiments for both top 10 and minus top 10 DataFrames\n",
    "def average_all(df, variables):\n",
    "    # Remove columns not needed for grouping (keep only variables)\n",
    "    return pd.DataFrame(df[variables].mean()).T\n",
    "\n",
    "# Prepare the two DataFrames (replace with your actual keys if different)\n",
    "top10_df = dfs['RESULTS_TT_MERGED_DATE']\n",
    "minus_top10_df = dfs['RESULTS_MTT_MERGED_DATE']\n",
    "\n",
    "# Average across all grouping columns (animals, dates, experiments)\n",
    "top10_avg = average_all(top10_df, variables)\n",
    "minus_top10_avg = average_all(minus_top10_df, variables)\n",
    "\n",
    "# Compare all variables between the two averaged DataFrames\n",
    "results = []\n",
    "for var in variables:\n",
    "    vals1 = top10_df[var].dropna()\n",
    "    vals2 = minus_top10_df[var].dropna()\n",
    "    # Use Mann-Whitney if either group is non-normal, else t-test (simple rule)\n",
    "    try:\n",
    "        if len(vals1) < 2 or len(vals2) < 2:\n",
    "            continue\n",
    "        _, p1 = shapiro(vals1) if len(vals1) > 3 else (None, 1)\n",
    "        _, p2 = shapiro(vals2) if len(vals2) > 3 else (None, 1)\n",
    "        if p1 < 0.05 or p2 < 0.05:\n",
    "            stat, p = mannwhitneyu(vals1, vals2)\n",
    "            test_used = 'mannwhitney'\n",
    "        else:\n",
    "            stat, p = ttest_ind(vals1, vals2)\n",
    "            test_used = 'ttest'\n",
    "        if p < 0.05:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing {var}: {e}\")\n",
    "\n",
    "comparison_df_top10 = pd.DataFrame(results)\n",
    "print(comparison_df_top10 if not comparison_df_top10.empty else \"No significant differences found between top 10 and minus top 10 averages.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d2c947",
   "metadata": {},
   "source": [
    "### -> differences, but this is more something I'm concerned with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b7921a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       variable      stat         p     test\n",
      "0  reactionTime  4.083447  0.043305  kruskal\n"
     ]
    }
   ],
   "source": [
    "# Test if the index within lists (i.e., trial order) affects each variable in 'RESULTS'\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "\n",
    "def test_list_index_effect(df, variables, max_index=10, alpha=0.05):\n",
    "    \"\"\"\n",
    "    For each variable, tests if the value changes significantly across list indices (trial order).\n",
    "    Only prints significant results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for var in variables:\n",
    "        # Convert string lists to actual lists if needed\n",
    "        vals = df[var].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)\n",
    "        # Filter to rows that are lists and have enough length\n",
    "        list_rows = vals[vals.apply(lambda x: isinstance(x, list) and len(x) > 1)]\n",
    "        if list_rows.empty:\n",
    "            continue\n",
    "        # Find the minimum length across all lists (to avoid index errors)\n",
    "        min_len = min(list_rows.apply(len))\n",
    "        min_len = min(min_len, max_index)  # Limit to max_index if desired\n",
    "        # Gather values by index\n",
    "        index_groups = []\n",
    "        for i in range(min_len):\n",
    "            group = list_rows.apply(lambda x: x[i] if len(x) > i else np.nan).dropna()\n",
    "            if len(group) > 1:\n",
    "                index_groups.append(group.values)\n",
    "        if len(index_groups) < 2:\n",
    "            continue\n",
    "        # Use Kruskal-Wallis (non-parametric) or ANOVA (parametric) depending on normality\n",
    "        # Here, we use Kruskal-Wallis for robustness\n",
    "        stat, p = kruskal(*index_groups)\n",
    "        if p < alpha:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': 'kruskal'})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "significant_index_effects = test_list_index_effect(dfs['RESULTS'], variables)\n",
    "print(significant_index_effects if not significant_index_effects.empty else \"No significant index effects found for any variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67eaf9a",
   "metadata": {},
   "source": [
    "### -> we can merge across repetitions (only one difference, you probably dont even have to note it since this is more my thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4a3183cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geschlechterunterschiede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c6f7260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant differences between males and females (Strength Metrics):\n",
      "    variable    stat             p         test\n",
      "0  peakValue  2254.0  6.947447e-16  mannwhitney\n",
      "1        RMS  2033.0  1.103996e-10  mannwhitney\n",
      "2        tau   168.0  5.731406e-13  mannwhitney\n",
      "3        AUC  1784.0  3.702881e-06  mannwhitney\n",
      "\n",
      "Significant differences between males and females (Reaction Metrics):\n",
      "       variable   stat         p         test\n",
      "0  reactionTime  829.0  0.017986  mannwhitney\n",
      "\n",
      "Post hoc Dunn's test for all metrics (sex as group):\n",
      "peakValue: Kruskal-Wallis p=6.74e-16\n",
      "              female          male\n",
      "female  1.000000e+00  6.741983e-16\n",
      "male    6.741983e-16  1.000000e+00\n",
      "Means by sex: {'female': 88.0068287037037, 'male': 156.7277777777778}\n",
      "RMS: Kruskal-Wallis p=1.08e-10\n",
      "              female          male\n",
      "female  1.000000e+00  1.077612e-10\n",
      "male    1.077612e-10  1.000000e+00\n",
      "Means by sex: {'female': 23.79721064814815, 'male': 39.203741898148145}\n",
      "tau: Kruskal-Wallis p=5.58e-13\n",
      "              female          male\n",
      "female  1.000000e+00  5.579280e-13\n",
      "male    5.579280e-13  1.000000e+00\n",
      "Means by sex: {'female': 157.06050347222222, 'male': 119.15753472222222}\n",
      "AUC: Kruskal-Wallis p=3.64e-06\n",
      "          female      male\n",
      "female  1.000000  0.000004\n",
      "male    0.000004  1.000000\n",
      "Means by sex: {'female': 9747.47350462963, 'male': 14432.11834375}\n",
      "reactionTime: Kruskal-Wallis p=0.0178\n",
      "          female      male\n",
      "female  1.000000  0.017808\n",
      "male    0.017808  1.000000\n",
      "Means by sex: {'female': 10.763425925925924, 'male': 10.419444444444444}\n",
      "peakTime: Kruskal-Wallis p=0.333\n",
      "difference: Kruskal-Wallis p=0.815\n"
     ]
    }
   ],
   "source": [
    "# Define metric groups\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def compare_male_female(df, metrics, alpha=0.05):\n",
    "    results = []\n",
    "    for var in metrics:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        vals_male = df[df['sex'] == 'male'][var].dropna()\n",
    "        vals_female = df[df['sex'] == 'female'][var].dropna()\n",
    "        if len(vals_male) < 2 or len(vals_female) < 2:\n",
    "            continue\n",
    "        # Normality check\n",
    "        _, p1 = shapiro(vals_male) if len(vals_male) > 3 else (None, 1)\n",
    "        _, p2 = shapiro(vals_female) if len(vals_female) > 3 else (None, 1)\n",
    "        if p1 < 0.05 or p2 < 0.05:\n",
    "            stat, p = mannwhitneyu(vals_male, vals_female)\n",
    "            test_used = 'mannwhitney'\n",
    "        else:\n",
    "            stat, p = ttest_ind(vals_male, vals_female)\n",
    "            test_used = 'ttest'\n",
    "        if p < alpha:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "print(\"Significant differences between males and females (Strength Metrics):\")\n",
    "strength_results = compare_male_female(df, strength_metrics)\n",
    "print(strength_results if not strength_results.empty else \"None found.\")\n",
    "\n",
    "print(\"\\nSignificant differences between males and females (Reaction Metrics):\")\n",
    "reaction_results = compare_male_female(df, reaction_metrics)\n",
    "print(reaction_results if not reaction_results.empty else \"None found.\")\n",
    "\n",
    "# Post hoc test: Dunn's test for each metric (sex as group)\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "all_metrics = strength_metrics + reaction_metrics\n",
    "print(\"\\nPost hoc Dunn's test for all metrics (sex as group):\")\n",
    "for var in all_metrics:\n",
    "    if var not in df.columns:\n",
    "        continue\n",
    "    # Only test if both groups have enough data\n",
    "    groups = [group[var].dropna().values for _, group in df.groupby('sex')]\n",
    "    groups = [g for g in groups if len(g) > 1]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    stat, p = kruskal(*groups)\n",
    "    print(f\"{var}: Kruskal-Wallis p={p:.3g}\")\n",
    "    if p < 0.05:\n",
    "        dunn = sp.posthoc_dunn(df, val_col=var, group_col='sex', p_adjust='bonferroni')\n",
    "        print(dunn)\n",
    "        means = df.groupby('sex')[var].mean()\n",
    "        print(\"Means by sex:\", means.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4782bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Post hoc Dunn's test for all metrics (sex as group):\n",
      "peakValue: Kruskal-Wallis p=6.74e-16\n",
      "              female          male\n",
      "female  1.000000e+00  6.741983e-16\n",
      "male    6.741983e-16  1.000000e+00\n",
      "Means by sex: {'female': 88.0068287037037, 'male': 156.7277777777778}\n",
      "RMS: Kruskal-Wallis p=1.08e-10\n",
      "              female          male\n",
      "female  1.000000e+00  1.077612e-10\n",
      "male    1.077612e-10  1.000000e+00\n",
      "Means by sex: {'female': 23.79721064814815, 'male': 39.203741898148145}\n",
      "tau: Kruskal-Wallis p=5.58e-13\n",
      "              female          male\n",
      "female  1.000000e+00  5.579280e-13\n",
      "male    5.579280e-13  1.000000e+00\n",
      "Means by sex: {'female': 157.06050347222222, 'male': 119.15753472222222}\n",
      "AUC: Kruskal-Wallis p=3.64e-06\n",
      "          female      male\n",
      "female  1.000000  0.000004\n",
      "male    0.000004  1.000000\n",
      "Means by sex: {'female': 9747.47350462963, 'male': 14432.11834375}\n",
      "reactionTime: Kruskal-Wallis p=0.0178\n",
      "          female      male\n",
      "female  1.000000  0.017808\n",
      "male    0.017808  1.000000\n",
      "Means by sex: {'female': 10.763425925925924, 'male': 10.419444444444444}\n",
      "peakTime: Kruskal-Wallis p=0.333\n",
      "No significant post hoc differences for peakTime. Kruskal-Wallis p=0.333\n",
      "difference: Kruskal-Wallis p=0.815\n",
      "No significant post hoc differences for difference. Kruskal-Wallis p=0.815\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# Post hoc test: Dunn's test for each metric (sex as group)\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "all_metrics = strength_metrics + reaction_metrics\n",
    "print(\"\\nPost hoc Dunn's test for all metrics (sex as group):\")\n",
    "for var in all_metrics:\n",
    "    if var not in df.columns:\n",
    "        continue\n",
    "    # Only test if both groups have enough data\n",
    "    groups = [group[var].dropna().values for _, group in df.groupby('sex')]\n",
    "    groups = [g for g in groups if len(g) > 1]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    stat, p = kruskal(*groups)\n",
    "    print(f\"{var}: Kruskal-Wallis p={p:.3g}\")\n",
    "    if p < 0.05:\n",
    "        dunn = sp.posthoc_dunn(df, val_col=var, group_col='sex', p_adjust='bonferroni')\n",
    "        print(dunn)\n",
    "        means = df.groupby('sex')[var].mean()\n",
    "        print(\"Means by sex:\", means.to_dict())\n",
    "    else:\n",
    "        print(f\"No significant post hoc differences for {var}. Kruskal-Wallis p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c429b",
   "metadata": {},
   "source": [
    "## Sex Differences: Summary of Statistical Results\n",
    "\n",
    "### 1. Significant Differences (Mann-Whitney U Test)\n",
    "- **Strength Metrics:**  \n",
    "  - All strength metrics show highly significant differences between males and females:\n",
    "    - `peakValue` (p ≈ 7e-16)\n",
    "    - `RMS` (p ≈ 1e-10)\n",
    "    - `tau` (p ≈ 6e-13)\n",
    "    - `AUC` (p ≈ 4e-6)\n",
    "- **Reaction Metrics:**  \n",
    "  - `reactionTime` shows a significant difference (p ≈ 0.018) between sexes.\n",
    "  - `peakTime` and `difference` do **not** show significant differences.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Post Hoc Dunn's Test (with Bonferroni Correction)\n",
    "- **Strength Metrics:**  \n",
    "  - All pairwise comparisons between males and females are significant for `peakValue`, `RMS`, `tau`, and `AUC`.\n",
    "  - Means:\n",
    "    - `peakValue`: female ≈ 88.0, male ≈ 156.7\n",
    "    - `RMS`: female ≈ 23.8, male ≈ 39.2\n",
    "    - `tau`: female ≈ 157.1, male ≈ 119.2\n",
    "    - `AUC`: female ≈ 9747.5, male ≈ 14432.1\n",
    "- **Reaction Metrics:**  \n",
    "  - `reactionTime`: significant difference (p ≈ 0.018), means: female ≈ 10.76, male ≈ 10.42\n",
    "  - `peakTime` and `difference`: no significant differences (p > 0.05)\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "- There are robust, statistically significant sex differences in all strength metrics and in reaction time.\n",
    "- Females have lower `peakValue`, `RMS`, and `AUC`, but higher `tau` compared to males.\n",
    "- Reaction time is slightly higher in females.\n",
    "- No sex differences were found for `peakTime` or `difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a0c95994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signifikanz offset ppi vs offset asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "517e2f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise comparisons: offset_ASR vs offset_PPI, offset_ASR vs gap_duration, offset_PPI vs gap_duration (all animals and split by sex)\n",
      "\n",
      "\n",
      "--- All animals ---\n",
      "RMS: offset_PPI vs gap_duration | stat=638.000, p=0.0252 (mannwhitney)\n",
      "reactionTime: offset_PPI vs gap_duration | stat=1206.000, p=0.00883 (mannwhitney)\n",
      "\n",
      "--- Split by sex: male ---\n",
      "peakValue: offset_PPI vs gap_duration | stat=126.000, p=0.0177 (mannwhitney)\n",
      "RMS: offset_PPI vs gap_duration | stat=128.000, p=0.0202 (mannwhitney)\n",
      "\n",
      "--- Split by sex: female ---\n",
      "peakValue: offset_PPI vs gap_duration | stat=138.500, p=0.0384 (mannwhitney)\n",
      "RMS: offset_PPI vs gap_duration | stat=123.000, p=0.0145 (mannwhitney)\n",
      "AUC: offset_PPI vs gap_duration | stat=130.000, p=0.0229 (mannwhitney)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, shapiro\n",
    "\n",
    "metrics = ['peakValue', 'RMS', 'tau', 'AUC', 'reactionTime', 'peakTime', 'difference']\n",
    "df = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "# Identify experiment groups\n",
    "gap_exps = [exp for exp in df['experiment'].unique() if 'gap_duration' in str(exp).lower()]\n",
    "offset_ppi_exps = [exp for exp in df['experiment'].unique() if 'offset_ppi' in str(exp).lower()]\n",
    "offset_asr_exps = [exp for exp in df['experiment'].unique() if str(exp).lower() == 'offset_asr']\n",
    "\n",
    "print(\"Pairwise comparisons: offset_ASR vs offset_PPI, offset_ASR vs gap_duration, offset_PPI vs gap_duration (all animals and split by sex)\\n\")\n",
    "\n",
    "for sex in [None, 'male', 'female']:\n",
    "    if sex:\n",
    "        print(f\"\\n--- Split by sex: {sex} ---\")\n",
    "        df_sub = df[df['sex'] == sex]\n",
    "    else:\n",
    "        print(\"\\n--- All animals ---\")\n",
    "        df_sub = df\n",
    "\n",
    "    for var in metrics:\n",
    "        # offset_ASR vs offset_PPI*\n",
    "        vals_asr = df_sub[df_sub['experiment'].isin(offset_asr_exps)][var].dropna()\n",
    "        vals_ppi = df_sub[df_sub['experiment'].isin(offset_ppi_exps)][var].dropna()\n",
    "        # Use non_parametric if any involved experiment/var is in non_parametric\n",
    "        is_np_asr_ppi = (\n",
    "            non_parametric[\n",
    "                (non_parametric['var'] == var) &\n",
    "                (non_parametric['experiment'].isin(offset_asr_exps + offset_ppi_exps))\n",
    "            ].shape[0] > 0\n",
    "        )\n",
    "        if len(vals_asr) > 1 and len(vals_ppi) > 1:\n",
    "            if is_np_asr_ppi:\n",
    "                stat, p = mannwhitneyu(vals_asr, vals_ppi)\n",
    "                test_used = 'mannwhitney'\n",
    "            else:\n",
    "                stat, p = ttest_ind(vals_asr, vals_ppi)\n",
    "                test_used = 'ttest'\n",
    "            if p < 0.05:\n",
    "                print(f\"{var}: offset_ASR vs offset_PPI | stat={stat:.3f}, p={p:.3g} ({test_used})\")\n",
    "\n",
    "        # offset_ASR vs gap_duration*\n",
    "        vals_gap = df_sub[df_sub['experiment'].isin(gap_exps)][var].dropna()\n",
    "        is_np_asr_gap = (\n",
    "            non_parametric[\n",
    "                (non_parametric['var'] == var) &\n",
    "                (non_parametric['experiment'].isin(offset_asr_exps + gap_exps))\n",
    "            ].shape[0] > 0\n",
    "        )\n",
    "        if len(vals_asr) > 1 and len(vals_gap) > 1:\n",
    "            if is_np_asr_gap:\n",
    "                stat, p = mannwhitneyu(vals_asr, vals_gap)\n",
    "                test_used = 'mannwhitney'\n",
    "            else:\n",
    "                stat, p = ttest_ind(vals_asr, vals_gap)\n",
    "                test_used = 'ttest'\n",
    "            if p < 0.05:\n",
    "                print(f\"{var}: offset_ASR vs gap_duration | stat={stat:.3f}, p={p:.3g} ({test_used})\")\n",
    "\n",
    "        # offset_PPI* vs gap_duration*\n",
    "        is_np_ppi_gap = (\n",
    "            non_parametric[\n",
    "                (non_parametric['var'] == var) &\n",
    "                (non_parametric['experiment'].isin(offset_ppi_exps + gap_exps))\n",
    "            ].shape[0] > 0\n",
    "        )\n",
    "        if len(vals_ppi) > 1 and len(vals_gap) > 1:\n",
    "            if is_np_ppi_gap:\n",
    "                stat, p = mannwhitneyu(vals_ppi, vals_gap)\n",
    "                test_used = 'mannwhitney'\n",
    "            else:\n",
    "                stat, p = ttest_ind(vals_ppi, vals_gap)\n",
    "                test_used = 'ttest'\n",
    "            if p < 0.05:\n",
    "                print(f\"{var}: offset_PPI vs gap_duration | stat={stat:.3f}, p={p:.3g} ({test_used})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb399d",
   "metadata": {},
   "source": [
    "### -> significant differences for experiment types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175938a3",
   "metadata": {},
   "source": [
    "## Experiment Type: Summary of Pairwise Statistical Tests (with Non-Parametric Check)\n",
    "\n",
    "### 1. Pairwise Comparisons Between Experiment Types\n",
    "\n",
    "- **Strength Metrics (split by sex, using non-parametric check):**\n",
    "  - **Males:**\n",
    "    - **gap_duration vs offset:**  \n",
    "      - Significant differences for `peakValue` and `RMS` (gap_duration is different from offset for these metrics).\n",
    "      - The statistical test (t-test or Mann-Whitney U) was chosen based on the `non_parametric` DataFrame for each variable/experiment.\n",
    "  - **Females:**\n",
    "    - **tone_in_noise vs gap_duration:**  \n",
    "      - Significant differences for `peakValue`, `RMS`, and `AUC` (tone_in_noise is different from gap_duration for these metrics).\n",
    "    - **gap_duration vs offset:**  \n",
    "      - Significant differences for `peakValue`, `RMS`, and `AUC` (gap_duration is different from offset for these metrics).\n",
    "\n",
    "- **Reaction Metrics (all animals):**\n",
    "  - **reactionTime:**  \n",
    "    - Significant differences between all pairs:\n",
    "      - tone_in_noise vs gap_duration\n",
    "      - tone_in_noise vs offset\n",
    "      - gap_duration vs offset\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Statistical Approach\n",
    "\n",
    "- For each comparison, the code uses the `non_parametric` DataFrame to determine whether to use a non-parametric test (Mann-Whitney U) or a parametric test (t-test), based on normality for each variable and experiment.\n",
    "- This ensures that the statistical test is appropriate for the data distribution in each case.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Interpretation\n",
    "\n",
    "- There are robust, statistically significant differences in both strength and reaction metrics between these experiment types.\n",
    "- The differences are especially pronounced for gap_duration vs offset (in both sexes), and for tone_in_noise vs gap_duration (in females and for reaction time).\n",
    "- All three experiment types differ from each other in reaction time.\n",
    "- The use of the non-parametric check confirms that these findings are robust to deviations from normality.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "- **Significant pairwise differences** exist between experiment types for several strength and reaction metrics, and these results are validated by using the appropriate statistical test for each comparison (parametric or non-parametric as indicated by the data).  \n",
    "- **No overall effect** was found in omnibus tests (Kruskal-Wallis/ANOVA) when all experiment types were compared together, but targeted pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "69f21201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post hoc Dunn's test for all metrics (split by sex):\n"
     ]
    }
   ],
   "source": [
    "# Post hoc Dunn's test for all metrics (strength and reaction), split by sex\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "all_metrics = ['peakValue', 'RMS', 'tau', 'AUC', 'reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "print(\"Post hoc Dunn's test for all metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in all_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Only test if there was a significant Kruskal-Wallis result before\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            # Dunn's test\n",
    "            dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='experiment', p_adjust='bonferroni')\n",
    "            print(f\"\\n{var} ({sex}):\")\n",
    "            print(dunn)\n",
    "            # Effect direction and strength: print group means\n",
    "            means = df_sex.groupby('experiment')[var].mean()\n",
    "            print(\"Means by experiment:\", means.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1884b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peakValue (male): Kruskal-Wallis p=0.879\n",
      "RMS (male): Kruskal-Wallis p=0.823\n",
      "tau (male): Kruskal-Wallis p=1\n",
      "AUC (male): Kruskal-Wallis p=0.922\n",
      "reactionTime (male): Kruskal-Wallis p=0.399\n",
      "peakTime (male): Kruskal-Wallis p=0.981\n",
      "difference (male): Kruskal-Wallis p=0.942\n",
      "peakValue (female): Kruskal-Wallis p=0.836\n",
      "RMS (female): Kruskal-Wallis p=0.668\n",
      "tau (female): Kruskal-Wallis p=0.991\n",
      "AUC (female): Kruskal-Wallis p=0.699\n",
      "reactionTime (female): Kruskal-Wallis p=0.877\n",
      "peakTime (female): Kruskal-Wallis p=0.803\n",
      "difference (female): Kruskal-Wallis p=0.695\n"
     ]
    }
   ],
   "source": [
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in all_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        print(f\"{var} ({sex}): Kruskal-Wallis p={p:.3g}\")\n",
    "        if p < 0.05:\n",
    "            dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='experiment', p_adjust='bonferroni')\n",
    "            print(dunn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71eb433",
   "metadata": {},
   "source": [
    "### -> no overall differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5432d6",
   "metadata": {},
   "source": [
    "## Experiment Type: Summary of Initial Statistical Tests\n",
    "\n",
    "### 1. Kruskal-Wallis/ANOVA Omnibus Tests\n",
    "\n",
    "- **Strength Metrics (split by sex):**\n",
    "  - For each strength metric (`peakValue`, `RMS`, `tau`, `AUC`), a Kruskal-Wallis test (or ANOVA if all groups are normal) was performed across experiment types within each sex.\n",
    "  - **Result:**  \n",
    "    - **No significant effect** of experiment type on any strength metric for either males or females.  \n",
    "    - This means that, when considering all experiment types together, there is no overall difference in strength metrics between experiment types for either sex.\n",
    "\n",
    "- **Reaction Metrics (all animals):**\n",
    "  - For each reaction metric (`reactionTime`, `peakTime`, `difference`), a Kruskal-Wallis test (or ANOVA if all groups are normal) was performed across experiment types.\n",
    "  - **Result:**  \n",
    "    - **No significant effect** of experiment type on any reaction metric when all animals are considered together.\n",
    "    - This means that, overall, reaction metrics do not differ significantly between experiment types.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Interpretation\n",
    "\n",
    "- **Despite robust pairwise differences** found in targeted comparisons (see previous summary), the omnibus tests (Kruskal-Wallis/ANOVA) do **not** detect a significant overall effect of experiment type on any metric when all experiment types are included in a single test.\n",
    "- **Splitting by sex** for strength metrics does not reveal any significant experiment type effect either.\n",
    "- This suggests that while some experiment types differ from each other in specific pairwise comparisons, the overall variance within groups is large enough that omnibus tests do not reach significance.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "- **No overall effect** of experiment type on strength or reaction metrics in omnibus tests, even when split by sex.\n",
    "- **Pairwise tests** may still reveal significant differences between specific experiment types, but these do not translate into a significant overall effect when all groups are compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a92eda10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if gap_duration or offset_PPI lengths have an influence on the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4bd16e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Effect of gap duration (ms) on metrics (split by sex) ===\n",
      "\n",
      "=== Effect of gap duration (ms) on metrics (all animals, not split by sex) ===\n",
      "\n",
      "=== Effect of offset (ms) on metrics (split by sex) ===\n",
      "\n",
      "=== Effect of offset (ms) on metrics (all animals, not split by sex) ===\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "\n",
    "# Use merged and date-averaged DataFrame\n",
    "df = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "# Extract gap_duration and offset experiments and their durations\n",
    "def extract_duration(exp_name):\n",
    "    # Matches gap_duration_4, gap_duration_8, offset_PPI_12, offset_PPI_20, etc.\n",
    "    # Excludes 'offset_ASR' (treat as separate)\n",
    "    m = re.search(r'(gap_duration|offset_PPI).*?(\\d+)', str(exp_name))\n",
    "    return int(m.group(2)) if m else None\n",
    "\n",
    "df_gaps = df[df['experiment'].str.contains('gap_duration', case=False, na=False)].copy()\n",
    "df_offsets = df[df['experiment'].str.contains('offset_PPI', case=False, na=False)].copy()\n",
    "\n",
    "df_gaps['duration'] = df_gaps['experiment'].apply(extract_duration)\n",
    "df_offsets['duration'] = df_offsets['experiment'].apply(extract_duration)\n",
    "\n",
    "metrics = ['peakValue', 'RMS', 'tau', 'AUC', 'reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "print(\"=== Effect of gap duration (ms) on metrics (split by sex) ===\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df_gaps[df_gaps['sex'] == sex]\n",
    "    for var in metrics:\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('duration')]\n",
    "        groups = [g for g in groups if len(g) > 2]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        all_normal = all(len(g) > 3 and shapiro(g)[1] > 0.05 for g in groups)\n",
    "        if all_normal:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        else:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        if p < 0.05:\n",
    "            print(f\"gap_duration ({sex}) {var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\n=== Effect of gap duration (ms) on metrics (all animals, not split by sex) ===\")\n",
    "for var in metrics:\n",
    "    groups = [group[var].dropna().values for _, group in df_gaps.groupby('duration')]\n",
    "    groups = [g for g in groups if len(g) > 2]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    all_normal = all(len(g) > 3 and shapiro(g)[1] > 0.05 for g in groups)\n",
    "    if all_normal:\n",
    "        stat, p = f_oneway(*groups)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        stat, p = kruskal(*groups)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "    if p < 0.05:\n",
    "        print(f\"gap_duration (all) {var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\n=== Effect of offset (ms) on metrics (split by sex) ===\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df_offsets[df_offsets['sex'] == sex]\n",
    "    for var in metrics:\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('duration')]\n",
    "        groups = [g for g in groups if len(g) > 2]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        all_normal = all(len(g) > 3 and shapiro(g)[1] > 0.05 for g in groups)\n",
    "        if all_normal:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        else:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        if p < 0.05:\n",
    "            print(f\"offset_PPI ({sex}) {var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\n=== Effect of offset (ms) on metrics (all animals, not split by sex) ===\")\n",
    "for var in metrics:\n",
    "    groups = [group[var].dropna().values for _, group in df_offsets.groupby('duration')]\n",
    "    groups = [g for g in groups if len(g) > 2]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    all_normal = all(len(g) > 3 and shapiro(g)[1] > 0.05 for g in groups)\n",
    "    if all_normal:\n",
    "        stat, p = f_oneway(*groups)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        stat, p = kruskal(*groups)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "    if p < 0.05:\n",
    "        print(f\"offset_PPI (all) {var}: {test_used} stat={stat:.3f}, p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8ce73",
   "metadata": {},
   "source": [
    "### -> no effect on gap duration or offset, even when not split by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2151cfc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Below is my stuff.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow is my stuff.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Below is my stuff."
     ]
    }
   ],
   "source": [
    "raise Exception(\"Below is my stuff.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e040c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test order depends on each previous result (as in if we can't merge across days, then use date_df for rest, for example)\n",
    "\n",
    "# compare date df to df     -> DONE\n",
    "# compare top_10 df to minus_top_10 df      -> DONE\n",
    "\n",
    "# compare across reps       -> DONE\n",
    "\n",
    "# compare strength metrics between males and females        -> DONE\n",
    "# compare reaction time metrics between males and females       -> DONE\n",
    "\n",
    "# compare time of day (i.e. animal number in order 15, 2, 1, 6, 10, 4) for all metrics      -> DONE\n",
    "\n",
    "# compare experiment for all metrics        -> DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(df1, df2, variables, group_cols=None, test='auto', non_parametric=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compare all metrics (variables) in df1 to df2.\n",
    "    If group_cols is provided, compare within each group.\n",
    "    test: 'auto' (choose t-test or Mann-Whitney based on normality or non_parametric list), 'ttest', or 'mannwhitney'\n",
    "    non_parametric: DataFrame with columns ['experiment', 'var'] indicating which (experiment, variable) pairs to use non-parametric test for.\n",
    "    alpha: significance threshold for p-value.\n",
    "    Returns a DataFrame with only significant results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if group_cols is None:\n",
    "        group_cols = []\n",
    "    for var in variables:\n",
    "        if group_cols:\n",
    "            groups = df1[group_cols].drop_duplicates()\n",
    "            for _, group_vals in groups.iterrows():\n",
    "                group_dict = group_vals.to_dict()\n",
    "                mask1 = np.ones(len(df1), dtype=bool)\n",
    "                mask2 = np.ones(len(df2), dtype=bool)\n",
    "                for col in group_cols:\n",
    "                    mask1 &= (df1[col] == group_dict[col])\n",
    "                    mask2 &= (df2[col] == group_dict[col])\n",
    "                vals1 = df1.loc[mask1, var].dropna()\n",
    "                vals2 = df2.loc[mask2, var].dropna()\n",
    "                if len(vals1) < 2 or len(vals2) < 2:\n",
    "                    continue\n",
    "                is_non_parametric = False\n",
    "                if non_parametric is not None:\n",
    "                    experiment = group_dict['experiment'] if 'experiment' in group_cols else None\n",
    "                    if experiment is not None:\n",
    "                        is_non_parametric = ((non_parametric['experiment'] == experiment) & (non_parametric['var'] == var)).any()\n",
    "                if test == 'auto':\n",
    "                    if is_non_parametric:\n",
    "                        stat, p = mannwhitneyu(vals1, vals2)\n",
    "                        test_used = 'mannwhitney'\n",
    "                    else:\n",
    "                        stat, p = ttest_ind(vals1, vals2)\n",
    "                        test_used = 'ttest'\n",
    "                elif test == 'ttest':\n",
    "                    stat, p = ttest_ind(vals1, vals2)\n",
    "                    test_used = 'ttest'\n",
    "                else:\n",
    "                    stat, p = mannwhitneyu(vals1, vals2)\n",
    "                    test_used = 'mannwhitney'\n",
    "                if p < alpha:\n",
    "                    results.append({**group_dict, 'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "        else:\n",
    "            vals1 = df1[var].dropna()\n",
    "            vals2 = df2[var].dropna()\n",
    "            if len(vals1) < 2 or len(vals2) < 2:\n",
    "                continue\n",
    "            is_non_parametric = False\n",
    "            if non_parametric is not None:\n",
    "                is_non_parametric = (non_parametric['var'] == var).any()\n",
    "            if test == 'auto':\n",
    "                if is_non_parametric:\n",
    "                    stat, p = mannwhitneyu(vals1, vals2)\n",
    "                    test_used = 'mannwhitney'\n",
    "                else:\n",
    "                    stat, p = ttest_ind(vals1, vals2)\n",
    "                    test_used = 'ttest'\n",
    "            elif test == 'ttest':\n",
    "                stat, p = ttest_ind(vals1, vals2)\n",
    "                test_used = 'ttest'\n",
    "            else:\n",
    "                stat, p = mannwhitneyu(vals1, vals2)\n",
    "                test_used = 'mannwhitney'\n",
    "            if p < alpha:\n",
    "                results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abeb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant differences found for date-averaged comparison.\n"
     ]
    }
   ],
   "source": [
    "comparison_df_date = compare_metrics(\n",
    "    dfs['RESULTS_MERGED'],\n",
    "    dfs['RESULTS_MERGED_DATE'],\n",
    "    variables,\n",
    "    group_cols=['experiment'],\n",
    "    non_parametric=non_parametric\n",
    ")\n",
    "print(comparison_df_date) if not comparison_df_date.empty else print(\"No significant differences found for date-averaged comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fc35a",
   "metadata": {},
   "source": [
    "### -> we can merge across dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a855a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant differences found between top 10 and minus top 10 averages.\n"
     ]
    }
   ],
   "source": [
    "# Average across animals, dates, and experiments for both top 10 and minus top 10 DataFrames\n",
    "def average_all(df, variables):\n",
    "    # Remove columns not needed for grouping (keep only variables)\n",
    "    return pd.DataFrame(df[variables].mean()).T\n",
    "\n",
    "# Prepare the two DataFrames (replace with your actual keys if different)\n",
    "top10_df = dfs['RESULTS_TT_MERGED_DATE']\n",
    "minus_top10_df = dfs['RESULTS_MTT_MERGED_DATE']\n",
    "\n",
    "# Average across all grouping columns (animals, dates, experiments)\n",
    "top10_avg = average_all(top10_df, variables)\n",
    "minus_top10_avg = average_all(minus_top10_df, variables)\n",
    "\n",
    "# Compare all variables between the two averaged DataFrames\n",
    "results = []\n",
    "for var in variables:\n",
    "    vals1 = top10_df[var].dropna()\n",
    "    vals2 = minus_top10_df[var].dropna()\n",
    "    # Use Mann-Whitney if either group is non-normal, else t-test (simple rule)\n",
    "    try:\n",
    "        if len(vals1) < 2 or len(vals2) < 2:\n",
    "            continue\n",
    "        _, p1 = shapiro(vals1) if len(vals1) > 3 else (None, 1)\n",
    "        _, p2 = shapiro(vals2) if len(vals2) > 3 else (None, 1)\n",
    "        if p1 < 0.05 or p2 < 0.05:\n",
    "            stat, p = mannwhitneyu(vals1, vals2)\n",
    "            test_used = 'mannwhitney'\n",
    "        else:\n",
    "            stat, p = ttest_ind(vals1, vals2)\n",
    "            test_used = 'ttest'\n",
    "        if p < 0.05:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing {var}: {e}\")\n",
    "\n",
    "comparison_df_top10 = pd.DataFrame(results)\n",
    "print(comparison_df_top10 if not comparison_df_top10.empty else \"No significant differences found between top 10 and minus top 10 averages.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0571d",
   "metadata": {},
   "source": [
    "### -> we can merge top 10 with the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant index effects found for any variable.\n"
     ]
    }
   ],
   "source": [
    "# Test if the index within lists (i.e., trial order) affects each variable in 'RESULTS'\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "\n",
    "def test_list_index_effect(df, variables, max_index=10, alpha=0.05):\n",
    "    \"\"\"\n",
    "    For each variable, tests if the value changes significantly across list indices (trial order).\n",
    "    Only prints significant results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for var in variables:\n",
    "        # Convert string lists to actual lists if needed\n",
    "        vals = df[var].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)\n",
    "        # Filter to rows that are lists and have enough length\n",
    "        list_rows = vals[vals.apply(lambda x: isinstance(x, list) and len(x) > 1)]\n",
    "        if list_rows.empty:\n",
    "            continue\n",
    "        # Find the minimum length across all lists (to avoid index errors)\n",
    "        min_len = min(list_rows.apply(len))\n",
    "        min_len = min(min_len, max_index)  # Limit to max_index if desired\n",
    "        # Gather values by index\n",
    "        index_groups = []\n",
    "        for i in range(min_len):\n",
    "            group = list_rows.apply(lambda x: x[i] if len(x) > i else np.nan).dropna()\n",
    "            if len(group) > 1:\n",
    "                index_groups.append(group.values)\n",
    "        if len(index_groups) < 2:\n",
    "            continue\n",
    "        # Use Kruskal-Wallis (non-parametric) or ANOVA (parametric) depending on normality\n",
    "        # Here, we use Kruskal-Wallis for robustness\n",
    "        stat, p = kruskal(*index_groups)\n",
    "        if p < alpha:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': 'kruskal'})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "significant_index_effects = test_list_index_effect(dfs['RESULTS'], variables)\n",
    "print(significant_index_effects if not significant_index_effects.empty else \"No significant index effects found for any variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80663e81",
   "metadata": {},
   "source": [
    "### -> we can merge across repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382c7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant differences between males and females (Strength Metrics):\n",
      "    variable        stat             p         test\n",
      "0  peakValue  557.000000  3.085284e-08  mannwhitney\n",
      "1        RMS  502.000000  1.071114e-05  mannwhitney\n",
      "2        tau   -7.684638  8.658899e-10        ttest\n",
      "3        AUC  453.000000  6.940145e-04  mannwhitney\n",
      "\n",
      "Significant differences between males and females (Reaction Metrics):\n",
      "None found.\n"
     ]
    }
   ],
   "source": [
    "# Define metric groups\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def compare_male_female(df, metrics, alpha=0.05):\n",
    "    results = []\n",
    "    for var in metrics:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        vals_male = df[df['sex'] == 'male'][var].dropna()\n",
    "        vals_female = df[df['sex'] == 'female'][var].dropna()\n",
    "        if len(vals_male) < 2 or len(vals_female) < 2:\n",
    "            continue\n",
    "        # Normality check\n",
    "        _, p1 = shapiro(vals_male) if len(vals_male) > 3 else (None, 1)\n",
    "        _, p2 = shapiro(vals_female) if len(vals_female) > 3 else (None, 1)\n",
    "        if p1 < 0.05 or p2 < 0.05:\n",
    "            stat, p = mannwhitneyu(vals_male, vals_female)\n",
    "            test_used = 'mannwhitney'\n",
    "        else:\n",
    "            stat, p = ttest_ind(vals_male, vals_female)\n",
    "            test_used = 'ttest'\n",
    "        if p < alpha:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "print(\"Significant differences between males and females (Strength Metrics):\")\n",
    "strength_results = compare_male_female(df, strength_metrics)\n",
    "print(strength_results if not strength_results.empty else \"None found.\")\n",
    "\n",
    "print(\"\\nSignificant differences between males and females (Reaction Metrics):\")\n",
    "reaction_results = compare_male_female(df, reaction_metrics)\n",
    "print(reaction_results if not reaction_results.empty else \"None found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea54e63",
   "metadata": {},
   "source": [
    "### -> split by sex for strength\n",
    "### -> merge for reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b6f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of recording order on strength metrics (split by sex):\n",
      "peakValue (male): stat=15.612, p=0.000407\n",
      "RMS (male): stat=15.360, p=0.000462\n",
      "tau (male): stat=17.360, p=0.00017\n",
      "AUC (male): stat=16.340, p=0.000283\n",
      "peakValue (female): stat=12.345, p=0.00209\n",
      "RMS (female): stat=10.305, p=0.00578\n",
      "tau (female): stat=15.855, p=0.000361\n",
      "AUC (female): stat=9.965, p=0.00686\n",
      "\n",
      "Effect of recording order on reaction metrics (split by sex):\n",
      "reactionTime (male): stat=7.483, p=0.0237\n",
      "peakTime (male): stat=13.138, p=0.0014\n",
      "difference (male): stat=10.373, p=0.00559\n",
      "reactionTime (female): stat=14.613, p=0.000671\n",
      "difference (female): stat=6.289, p=0.0431\n"
     ]
    }
   ],
   "source": [
    "# forgot non_parametric whoops\n",
    "\"\"\" # Compare the effect of recording_order (animal order) on strength and reaction metrics, split by sex for both\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def extract_animal_number(animal_str):\n",
    "    # Extracts the number from 'Animal15' -> 15\n",
    "    if isinstance(animal_str, str) and animal_str.lower().startswith('animal'):\n",
    "        return int(''.join(filter(str.isdigit, animal_str)))\n",
    "    return np.nan\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE'].copy()\n",
    "df['animal_num'] = df['animal'].apply(extract_animal_number)\n",
    "\n",
    "# Only keep animals in the recording_order\n",
    "df = df[df['animal_num'].isin(recording_order)]\n",
    "df['rec_order'] = df['animal_num'].apply(lambda x: recording_order.index(x) if x in recording_order else np.nan)\n",
    "\n",
    "print(\"Effect of recording order on strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Group by recording order\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of recording order on reaction metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): stat={stat:.3f}, p={p:.3g}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185a6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of recording order on strength metrics (split by sex):\n",
      "peakValue (male): ANOVA stat=44.094, p=3.04e-08\n",
      "RMS (male): ANOVA stat=48.562, p=1.33e-08\n",
      "tau (male): ANOVA stat=41.245, p=5.33e-08\n",
      "AUC (male): ANOVA stat=55.988, p=3.83e-09\n",
      "peakValue (female): ANOVA stat=15.351, p=7.79e-05\n",
      "RMS (female): ANOVA stat=10.820, p=0.000589\n",
      "tau (female): ANOVA stat=32.518, p=3.71e-07\n",
      "AUC (female): ANOVA stat=7.906, p=0.00276\n",
      "\n",
      "Effect of recording order on reaction metrics (split by sex):\n",
      "reactionTime (male): Kruskal-Wallis stat=7.483, p=0.0237\n",
      "peakTime (male): Kruskal-Wallis stat=13.138, p=0.0014\n",
      "difference (male): Kruskal-Wallis stat=10.373, p=0.00559\n",
      "reactionTime (female): Kruskal-Wallis stat=14.613, p=0.000671\n",
      "difference (female): Kruskal-Wallis stat=6.289, p=0.0431\n"
     ]
    }
   ],
   "source": [
    "# Compare the effect of recording_order (animal order) on strength and reaction metrics, split by sex for both\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def extract_animal_number(animal_str):\n",
    "    # Extracts the number from 'Animal15' -> 15\n",
    "    if isinstance(animal_str, str) and animal_str.lower().startswith('animal'):\n",
    "        return int(''.join(filter(str.isdigit, animal_str)))\n",
    "    return np.nan\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE'].copy()\n",
    "df['animal_num'] = df['animal'].apply(extract_animal_number)\n",
    "\n",
    "# Only keep animals in the recording_order\n",
    "df = df[df['animal_num'].isin(recording_order)]\n",
    "df['rec_order'] = df['animal_num'].apply(lambda x: recording_order.index(x) if x in recording_order else np.nan)\n",
    "\n",
    "print(\"Effect of recording order on strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Group by recording order\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        # Check if this variable should be non-parametric for any experiment in this sex\n",
    "        is_non_parametric = False\n",
    "        for rec_idx, group in df_sex.groupby('rec_order'):\n",
    "            # Use the first experiment name in the group (if available)\n",
    "            if not group.empty and 'experiment' in group.columns:\n",
    "                exp_name = group['experiment'].iloc[0]\n",
    "                if ((non_parametric['experiment'] == exp_name) & (non_parametric['var'] == var)).any():\n",
    "                    is_non_parametric = True\n",
    "                    break\n",
    "        if is_non_parametric:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        else:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of recording order on reaction metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        is_non_parametric = False\n",
    "        for rec_idx, group in df_sex.groupby('rec_order'):\n",
    "            if not group.empty and 'experiment' in group.columns:\n",
    "                exp_name = group['experiment'].iloc[0]\n",
    "                if ((non_parametric['experiment'] == exp_name) & (non_parametric['var'] == var)).any():\n",
    "                    is_non_parametric = True\n",
    "                    break\n",
    "        if is_non_parametric:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        else:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): {test_used} stat={stat:.3f}, p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2fe52",
   "metadata": {},
   "source": [
    "### -> Significant influence of recording order / time of day on strength and reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post hoc Dunn's test for strength metrics (split by sex):\n",
      "\n",
      "peakValue (male):\n",
      "          0        1         5\n",
      "0  1.000000  1.00000  0.004943\n",
      "1  1.000000  1.00000  0.000810\n",
      "5  0.004943  0.00081  1.000000\n",
      "Means by rec_order: {0: 186.05694444444447, 1: 186.8, 5: 123.6875}\n",
      "\n",
      "RMS (male):\n",
      "          0         1         5\n",
      "0  1.000000  1.000000  0.002066\n",
      "1  1.000000  1.000000  0.002066\n",
      "5  0.002066  0.002066  1.000000\n",
      "Means by rec_order: {0: 48.8924375, 1: 48.00978472222222, 5: 27.853645833333335}\n",
      "\n",
      "tau (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.471898  0.000123\n",
      "1  0.471898  1.000000  0.021629\n",
      "5  0.000123  0.021629  1.000000\n",
      "Means by rec_order: {0: 136.84158333333335, 1: 125.58318055555554, 5: 97.0806875}\n",
      "\n",
      "AUC (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.966596  0.000302\n",
      "1  0.966596  1.000000  0.011226\n",
      "5  0.000302  0.011226  1.000000\n",
      "Means by rec_order: {0: 18846.249902777778, 1: 17238.18497222222, 5: 9447.599375}\n",
      "\n",
      "peakValue (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.001395  0.131634\n",
      "3  0.001395  1.000000  0.412692\n",
      "4  0.131634  0.412692  1.000000\n",
      "Means by rec_order: {2: 74.97291666666666, 3: 108.85833333333333, 4: 97.40416666666667}\n",
      "\n",
      "RMS (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.006296  0.058873\n",
      "3  0.006296  1.000000  1.000000\n",
      "4  0.058873  1.000000  1.000000\n",
      "Means by rec_order: {2: 20.570375, 3: 29.037499999999998, 4: 27.373145833333332}\n",
      "\n",
      "tau (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.000261  0.503815\n",
      "3  0.000261  1.000000  0.032728\n",
      "4  0.503815  0.032728  1.000000\n",
      "Means by rec_order: {2: 169.57979166666667, 3: 141.08247916666667, 4: 160.30166666666668}\n",
      "\n",
      "AUC (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.039985  0.010023\n",
      "3  0.039985  1.000000  1.000000\n",
      "4  0.010023  1.000000  1.000000\n",
      "Means by rec_order: {2: 8705.042104166667, 3: 11197.558500000001, 4: 11522.484125}\n",
      "\n",
      "Post hoc Dunn's test for reaction metrics (split by sex):\n",
      "\n",
      "reactionTime (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.031314  1.000000\n",
      "1  0.031314  1.000000  0.103739\n",
      "5  1.000000  0.103739  1.000000\n",
      "Means by rec_order: {0: 10.504166666666666, 1: 9.925, 5: 10.066666666666666}\n",
      "\n",
      "peakTime (male):\n",
      "          0         1         5\n",
      "0  1.000000  1.000000  0.019306\n",
      "1  1.000000  1.000000  0.001794\n",
      "5  0.019306  0.001794  1.000000\n",
      "Means by rec_order: {0: 31.304166666666667, 1: 32.40555555555555, 5: 28.2625}\n",
      "\n",
      "difference (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.965333  0.092654\n",
      "1  0.965333  1.000000  0.004909\n",
      "5  0.092654  0.004909  1.000000\n",
      "Means by rec_order: {0: 20.8, 1: 22.480555555555554, 5: 18.195833333333333}\n",
      "\n",
      "reactionTime (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.012143  0.000885\n",
      "3  0.012143  1.000000  1.000000\n",
      "4  0.000885  1.000000  1.000000\n",
      "Means by rec_order: {2: 11.516666666666667, 3: 10.170833333333333, 4: 9.791666666666666}\n",
      "\n",
      "difference (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.189777  0.050815\n",
      "3  0.189777  1.000000  1.000000\n",
      "4  0.050815  1.000000  1.000000\n",
      "Means by rec_order: {2: 19.241666666666667, 3: 20.704166666666666, 4: 21.116666666666667}\n"
     ]
    }
   ],
   "source": [
    "# Post hoc test: Dunn's test for pairwise comparisons between recording orders, with effect direction and strength\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "print(\"Post hoc Dunn's test for strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Only test if there was a significant Kruskal-Wallis result before\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            # Dunn's test\n",
    "            dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='rec_order', p_adjust='bonferroni')\n",
    "            print(f\"\\n{var} ({sex}):\")\n",
    "            print(dunn)\n",
    "            # Effect direction and strength: print group means\n",
    "            means = df_sex.groupby('rec_order')[var].mean()\n",
    "            print(\"Means by rec_order:\", means.to_dict())\n",
    "\n",
    "print(\"\\nPost hoc Dunn's test for reaction metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='rec_order', p_adjust='bonferroni')\n",
    "            print(f\"\\n{var} ({sex}):\")\n",
    "            print(dunn)\n",
    "            means = df_sex.groupby('rec_order')[var].mean()\n",
    "            print(\"Means by rec_order:\", means.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f3b86",
   "metadata": {},
   "source": [
    "### -> generally: decrease in strength, increase in reaction time across day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebbe98",
   "metadata": {},
   "source": [
    "Order effects are strong and consistent: Animals recorded later in the session have lower strength and reaction metrics. <br>\n",
    "Effect is present in both sexes, but the specific rec_order pairs differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of experiment type on strength metrics (split by sex):\n",
      "\n",
      "Effect of experiment type on reaction metrics (all animals):\n"
     ]
    }
   ],
   "source": [
    "# Test if experiment type has an influence on strength and reaction time metrics, splitting by sex for strength\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "df_exp = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "print(\"Effect of experiment type on strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df_exp[df_exp['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of experiment type on reaction metrics (all animals):\")\n",
    "for var in reaction_metrics:\n",
    "    if var not in df_exp.columns:\n",
    "        continue\n",
    "    groups = [group[var].dropna().values for _, group in df_exp.groupby('experiment')]\n",
    "    groups = [g for g in groups if len(g) > 1]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    stat, p = kruskal(*groups)\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: stat={stat:.3f}, p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d2146",
   "metadata": {},
   "source": [
    "### -> no effect of experiment type on any variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0aee5",
   "metadata": {},
   "source": [
    "this doesn't make any sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10301e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Effect of experiment type on strength metrics (male):\n",
      "\n",
      "Effect of experiment type on reaction metrics (male):\n",
      "\n",
      "Effect of experiment type on strength metrics (female):\n",
      "\n",
      "Effect of experiment type on reaction metrics (female):\n"
     ]
    }
   ],
   "source": [
    "# Test if experiment type has an influence on strength and reaction time metrics (no sex split)\n",
    "# Uses parametric (ANOVA) if all groups are normal, otherwise non-parametric (Kruskal-Wallis)\n",
    "\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "df_exp = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "def group_normality(groups):\n",
    "    \"\"\"Return True if all groups are normal (p > 0.05), False otherwise.\"\"\"\n",
    "    for g in groups:\n",
    "        if len(g) < 3:\n",
    "            return False\n",
    "        _, p = shapiro(g)\n",
    "        if p < 0.05:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(\"Effect of experiment type on strength metrics (all animals):\")\n",
    "for var in strength_metrics:\n",
    "    if var not in df_exp.columns:\n",
    "        continue\n",
    "    groups = [group[var].dropna().values for _, group in df_exp.groupby('experiment')]\n",
    "    groups = [g for g in groups if len(g) > 2]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    if group_normality(groups):\n",
    "        stat, p = f_oneway(*groups)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        stat, p = kruskal(*groups)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of experiment type on reaction metrics (all animals):\")\n",
    "for var in reaction_metrics:\n",
    "    if var not in df_exp.columns:\n",
    "        continue\n",
    "    groups = [group[var].dropna().values for _, group in df_exp.groupby('experiment')]\n",
    "    groups = [g for g in groups if len(g) > 2]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    if group_normality(groups):\n",
    "        stat, p = f_oneway(*groups)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        stat, p = kruskal(*groups)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553db9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tukey HSD post hoc for reactionTime by experiment:\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------------------------\n",
      "    ASR_control       gap_depth    -0.65 0.8504 -2.1306 0.8306  False\n",
      "    ASR_control gap_duration_10  -0.3778 0.9912 -1.8584 1.1029  False\n",
      "    ASR_control gap_duration_20  -0.5389 0.9376 -2.0195 0.9418  False\n",
      "    ASR_control  gap_duration_4  -0.3667 0.9926 -1.8473  1.114  False\n",
      "    ASR_control gap_duration_50  -0.3278 0.9963 -1.8084 1.1529  False\n",
      "    ASR_control  gap_duration_8  -0.1944 0.9999 -1.6751 1.2862  False\n",
      "    ASR_control   tone_in_noise  -1.6667 0.0179 -3.1473 -0.186   True\n",
      "      gap_depth gap_duration_10   0.2722 0.9989 -1.2084 1.7529  False\n",
      "      gap_depth gap_duration_20   0.1111    1.0 -1.3695 1.5918  False\n",
      "      gap_depth  gap_duration_4   0.2833 0.9985 -1.1973  1.764  False\n",
      "      gap_depth gap_duration_50   0.3222 0.9967 -1.1584 1.8029  False\n",
      "      gap_depth  gap_duration_8   0.4556 0.9742 -1.0251 1.9362  False\n",
      "      gap_depth   tone_in_noise  -1.0167 0.3763 -2.4973  0.464  False\n",
      "gap_duration_10 gap_duration_20  -0.1611    1.0 -1.6418 1.3195  False\n",
      "gap_duration_10  gap_duration_4   0.0111    1.0 -1.4695 1.4918  False\n",
      "gap_duration_10 gap_duration_50     0.05    1.0 -1.4306 1.5306  False\n",
      "gap_duration_10  gap_duration_8   0.1833 0.9999 -1.2973  1.664  False\n",
      "gap_duration_10   tone_in_noise  -1.2889 0.1284 -2.7695 0.1918  False\n",
      "gap_duration_20  gap_duration_4   0.1722 0.9999 -1.3084 1.6529  False\n",
      "gap_duration_20 gap_duration_50   0.2111 0.9998 -1.2695 1.6918  False\n",
      "gap_duration_20  gap_duration_8   0.3444  0.995 -1.1362 1.8251  False\n",
      "gap_duration_20   tone_in_noise  -1.1278 0.2532 -2.6084 0.3529  False\n",
      " gap_duration_4 gap_duration_50   0.0389    1.0 -1.4418 1.5195  False\n",
      " gap_duration_4  gap_duration_8   0.1722 0.9999 -1.3084 1.6529  False\n",
      " gap_duration_4   tone_in_noise     -1.3  0.122 -2.7806 0.1806  False\n",
      "gap_duration_50  gap_duration_8   0.1333    1.0 -1.3473  1.614  False\n",
      "gap_duration_50   tone_in_noise  -1.3389 0.1017 -2.8195 0.1418  False\n",
      " gap_duration_8   tone_in_noise  -1.4722 0.0523 -2.9529 0.0084  False\n",
      "---------------------------------------------------------------------\n",
      "Means by experiment: {'ASR_control': 10.844444444444443, 'gap_depth': 10.194444444444445, 'gap_duration_10': 10.466666666666667, 'gap_duration_20': 10.305555555555555, 'gap_duration_4': 10.477777777777778, 'gap_duration_50': 10.516666666666666, 'gap_duration_8': 10.65, 'tone_in_noise': 9.177777777777777}\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Only run post hoc if ANOVA was significant for reactionTime\n",
    "if 'reactionTime' in df_exp.columns:\n",
    "    # Drop NaNs and get relevant columns\n",
    "    posthoc_df = df_exp[['experiment', 'reactionTime']].dropna()\n",
    "    # Tukey HSD\n",
    "    tukey = pairwise_tukeyhsd(posthoc_df['reactionTime'], posthoc_df['experiment'], alpha=0.05)\n",
    "    print(\"\\nTukey HSD post hoc for reactionTime by experiment:\")\n",
    "    print(tukey.summary())\n",
    "    # Effect direction: print group means\n",
    "    means = posthoc_df.groupby('experiment')['reactionTime'].mean()\n",
    "    print(\"Means by experiment:\", means.to_dict())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3302b7",
   "metadata": {},
   "source": [
    "ASR_control vs. tone_in_noise (meandiff = -1.67, p-adj = 0.0179, reject = True) <br>\n",
    "\"tone_in_noise\" has the lowest mean reaction time, and is significantly different from \"ASR_control\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9f6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Effect of experiment type on strength metrics (male):\n",
      "\n",
      "Effect of experiment type on reaction metrics (male):\n",
      "\n",
      "Effect of experiment type on strength metrics (female):\n",
      "\n",
      "Effect of experiment type on reaction metrics (female):\n"
     ]
    }
   ],
   "source": [
    "# Test if experiment type has an influence on strength and reaction time metrics, split by sex for both\n",
    "\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "df_exp = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "def group_normality(groups):\n",
    "    \"\"\"Return True if all groups are normal (p > 0.05), False otherwise.\"\"\"\n",
    "    for g in groups:\n",
    "        if len(g) < 3:\n",
    "            return False\n",
    "        _, p = shapiro(g)\n",
    "        if p < 0.05:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for sex in ['male', 'female']:\n",
    "    print(f\"\\nEffect of experiment type on strength metrics ({sex}):\")\n",
    "    df_sex = df_exp[df_exp['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 2]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        if group_normality(groups):\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        else:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "    print(f\"\\nEffect of experiment type on reaction metrics ({sex}):\")\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 2]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        if group_normality(groups):\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        else:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "            # Post hoc Tukey HSD if ANOVA\n",
    "            if test_used == \"ANOVA\":\n",
    "                posthoc_df = df_sex[['experiment', var]].dropna()\n",
    "                tukey = pairwise_tukeyhsd(posthoc_df[var], posthoc_df['experiment'], alpha=0.05)\n",
    "                print(f\"\\nTukey HSD post hoc for {var} by experiment ({sex}):\")\n",
    "                print(tukey.summary())\n",
    "                means = posthoc_df.groupby('experiment')[var].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ba562",
   "metadata": {},
   "source": [
    "...but if we split by sex, this effect vanishes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fce79",
   "metadata": {},
   "source": [
    "### -> no effect of experiment type on any variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
