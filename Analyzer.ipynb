{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01fa7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro, boxcox, ttest_ind, mannwhitneyu, pearsonr, friedmanchisquare, kruskal, kstest, \\\n",
    "    lognorm, gamma, weibull_min, probplot, f_oneway, linregress, norm, spearmanr, ttest_1samp, wilcoxon \n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, mixedlm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89cb28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"Results\" # input directory\n",
    "\n",
    "number = 1 # results to analyze (subfolder name, can be an integer or string)\n",
    "\n",
    "recording_order = (15, 2, 1, 6, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae09f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ['RESULTS', 'RESULTS_MTT', 'RESULTS_TT'] in Results\\1.\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "results_dir = os.path.join(input_dir, str(number))\n",
    "files = [file for file in os.listdir(results_dir) if file.endswith(('.xlsx', '.xls')) and not file.startswith('OVERVIEW')]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(results_dir, file)\n",
    "    dfs[file.split('.')[0]] = pd.read_excel(file_path)\n",
    "\n",
    "framenames = list(dfs.keys())\n",
    "results = framenames[0]\n",
    "results_mtt = framenames[1]\n",
    "results_tt = framenames[2]\n",
    "\n",
    "print(f\"Found {framenames} in {results_dir}.\")\n",
    "\n",
    "framenames.append('RESULTS_MERGED')\n",
    "framenames.append('RESUlTS_MERGED_MTT')\n",
    "framenames.append('RESULTS_MERGED_TT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab8f4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 experiments, 7 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50\n",
      " reactionTime, peakTime, difference, peakValue, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "experiments = dfs[results]['experiment'].unique().tolist()\n",
    "variables = dfs[results].columns[4:].tolist()\n",
    "parameters = dfs[results].columns[:4].tolist()\n",
    "print(f\"Found {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80bd6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_list_columns(df):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        # Try to convert string representations of lists to actual lists\n",
    "        if df_copy[col].apply(lambda x: isinstance(x, list) or (isinstance(x, str) and x.startswith('['))).any():\n",
    "            df_copy[col] = df_copy[col].apply(\n",
    "                lambda x: np.mean(ast.literal_eval(x)) if isinstance(x, str) and x.startswith('[') else np.mean(x) if isinstance(x, list) else x\n",
    "            )\n",
    "    return df_copy\n",
    "\n",
    "# Create merged DataFrames with averaged values\n",
    "dfs['RESULTS_MERGED'] = average_list_columns(dfs[results])\n",
    "dfs['RESULTS_MTT_MERGED'] = average_list_columns(dfs[results_mtt])\n",
    "dfs['RESULTS_TT_MERGED'] = average_list_columns(dfs[results_tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cfcbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_across_dates(df):\n",
    "    # Group by all columns except 'date' and the variables, then average variables across dates\n",
    "    group_cols = [col for col in df.columns if col not in variables and col != 'date']\n",
    "    averaged = df.groupby(group_cols, as_index=False)[variables].mean()\n",
    "    return averaged\n",
    "\n",
    "# Create merged DataFrames with averaged values\n",
    "dfs['RESULTS_MERGED'] = average_list_columns(dfs[results])\n",
    "dfs['RESULTS_MTT_MERGED'] = average_list_columns(dfs[results_mtt])\n",
    "dfs['RESULTS_TT_MERGED'] = average_list_columns(dfs[results_tt])\n",
    "\n",
    "# Create date-averaged versions of each merged DataFrame\n",
    "dfs['RESULTS_MERGED_DATE'] = average_across_dates(dfs['RESULTS_MERGED'])\n",
    "dfs['RESULTS_MTT_MERGED_DATE'] = average_across_dates(dfs['RESULTS_MTT_MERGED'])\n",
    "dfs['RESULTS_TT_MERGED_DATE'] = average_across_dates(dfs['RESULTS_TT_MERGED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f00fd660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RESULTS', 'RESULTS_MTT', 'RESULTS_TT', 'RESULTS_MERGED', 'RESULTS_MTT_MERGED', 'RESULTS_TT_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_TT_MERGED_DATE']\n"
     ]
    }
   ],
   "source": [
    "print(list(dfs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771bdf0",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1710b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "RESULTS_MTT\n",
      "RESULTS_TT\n",
      "RESULTS_MERGED\n",
      "RESULTS_MTT_MERGED\n",
      "RESULTS_TT_MERGED\n",
      "RESULTS_MERGED_DATE\n",
      "RESULTS_MTT_MERGED_DATE\n",
      "RESULTS_TT_MERGED_DATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Galahad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "non_parametric_dfs = {}\n",
    "for name, df in dfs.items():\n",
    "    print(name)\n",
    "    if not name.endswith('_MERGED'):\n",
    "        continue  # Only process merged dataframes\n",
    "    non_parametric = pd.DataFrame(columns=['experiment', 'var'])\n",
    "    not_enough_data = 0\n",
    "    for var in variables:\n",
    "        for exp in experiments:\n",
    "            for sex in ['male', 'female']:\n",
    "                data = df[(df['sex'] == sex) & (df['experiment'] == exp)][var].dropna()\n",
    "                if len(data) > 2:\n",
    "                    stat, p = shapiro(data)\n",
    "                    if p < 0.05:\n",
    "                        non_parametric = pd.concat(\n",
    "                            [non_parametric, pd.DataFrame({'experiment': [exp], 'var': [var]})],\n",
    "                            ignore_index=True\n",
    "                        )\n",
    "                else:\n",
    "                    not_enough_data += 1\n",
    "    non_parametric_dfs[name] = non_parametric\n",
    "    #print(f\"Non-parametric entries in {name}: {len(non_parametric)}\")\n",
    "    #if not_enough_data != 0: print(f\"Warning, not enough data for {not_enough_data} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dff3c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(non_parametric_dfs['RESULTS_MERGED']))\n",
    "print(len(non_parametric_dfs['RESULTS_MTT_MERGED']))\n",
    "print(len(non_parametric_dfs['RESULTS_TT_MERGED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f3b2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         experiment           var\n",
      "0       ASR_control  reactionTime\n",
      "1    gap_duration_4  reactionTime\n",
      "2    gap_duration_8  reactionTime\n",
      "3   gap_duration_10  reactionTime\n",
      "4   gap_duration_50  reactionTime\n",
      "5       ASR_control      peakTime\n",
      "6         gap_depth      peakTime\n",
      "7     tone_in_noise      peakTime\n",
      "8    gap_duration_4      peakTime\n",
      "9    gap_duration_8      peakTime\n",
      "10  gap_duration_10      peakTime\n",
      "11  gap_duration_20      peakTime\n",
      "12  gap_duration_50      peakTime\n",
      "13      ASR_control    difference\n",
      "14  gap_duration_20    difference\n",
      "15  gap_duration_50    difference\n",
      "16        gap_depth           AUC\n",
      "17        gap_depth           RMS\n",
      "18        gap_depth  reactionTime\n",
      "19    tone_in_noise  reactionTime\n",
      "20  gap_duration_20  reactionTime\n",
      "21        gap_depth    difference\n",
      "22  gap_duration_10    difference\n",
      "23   gap_duration_4           tau\n",
      "24  gap_duration_10           AUC\n",
      "61   gap_duration_4    difference\n",
      "62   gap_duration_8    difference\n",
      "77   gap_duration_8           tau\n",
      "78  gap_duration_10           tau\n",
      "79  gap_duration_20           tau\n",
      "80  gap_duration_50           tau\n",
      "81   gap_duration_4           AUC\n",
      "82   gap_duration_8           AUC\n",
      "83  gap_duration_20           AUC\n",
      "84  gap_duration_50           AUC\n"
     ]
    }
   ],
   "source": [
    "gap_durations = ['gap_duration_4', 'gap_duration_8', 'gap_duration_10', 'gap_duration_20', 'gap_duration_50']\n",
    "\n",
    "# Concatenate and drop duplicates as before\n",
    "dfs_to_merge = [\n",
    "    non_parametric_dfs['RESULTS_MERGED'],\n",
    "    non_parametric_dfs['RESULTS_MTT_MERGED'],\n",
    "    non_parametric_dfs['RESULTS_TT_MERGED']\n",
    "]\n",
    "non_parametric = pd.concat(dfs_to_merge, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Extend: for each row with \"gap_duration\" in experiment, add all gap_duration_* for that var\n",
    "rows_to_add = []\n",
    "for _, row in non_parametric.iterrows():\n",
    "    if \"gap_duration\" in row['experiment']:\n",
    "        for gap_exp in gap_durations:\n",
    "            if gap_exp != row['experiment']:\n",
    "                new_row = row.copy()\n",
    "                new_row['experiment'] = gap_exp\n",
    "                rows_to_add.append(new_row)\n",
    "\n",
    "# Add the new rows and drop duplicates again\n",
    "if rows_to_add:\n",
    "    non_parametric = pd.concat([non_parametric, pd.DataFrame(rows_to_add)], ignore_index=True).drop_duplicates()\n",
    "\n",
    "print(non_parametric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e040c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test order depends on each previous result (as in if we can't merge across days, then use date_df for rest, for example)\n",
    "\n",
    "# compare date df to df     -> DONE\n",
    "# compare top_10 df to minus_top_10 df      -> DONE\n",
    "\n",
    "# compare across reps       -> DONE\n",
    "\n",
    "# compare strength metrics between males and females        -> DONE\n",
    "# compare reaction time metrics between males and females       -> DONE\n",
    "\n",
    "# compare time of day (i.e. animal number in order 15, 2, 1, 6, 10, 4) for all metrics      -> DONE\n",
    "\n",
    "# compare experiment for all metrics        -> DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(df1, df2, variables, group_cols=None, test='auto', non_parametric=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compare all metrics (variables) in df1 to df2.\n",
    "    If group_cols is provided, compare within each group.\n",
    "    test: 'auto' (choose t-test or Mann-Whitney based on normality or non_parametric list), 'ttest', or 'mannwhitney'\n",
    "    non_parametric: DataFrame with columns ['experiment', 'var'] indicating which (experiment, variable) pairs to use non-parametric test for.\n",
    "    alpha: significance threshold for p-value.\n",
    "    Returns a DataFrame with only significant results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if group_cols is None:\n",
    "        group_cols = []\n",
    "    for var in variables:\n",
    "        if group_cols:\n",
    "            groups = df1[group_cols].drop_duplicates()\n",
    "            for _, group_vals in groups.iterrows():\n",
    "                group_dict = group_vals.to_dict()\n",
    "                mask1 = np.ones(len(df1), dtype=bool)\n",
    "                mask2 = np.ones(len(df2), dtype=bool)\n",
    "                for col in group_cols:\n",
    "                    mask1 &= (df1[col] == group_dict[col])\n",
    "                    mask2 &= (df2[col] == group_dict[col])\n",
    "                vals1 = df1.loc[mask1, var].dropna()\n",
    "                vals2 = df2.loc[mask2, var].dropna()\n",
    "                if len(vals1) < 2 or len(vals2) < 2:\n",
    "                    continue\n",
    "                is_non_parametric = False\n",
    "                if non_parametric is not None:\n",
    "                    experiment = group_dict['experiment'] if 'experiment' in group_cols else None\n",
    "                    if experiment is not None:\n",
    "                        is_non_parametric = ((non_parametric['experiment'] == experiment) & (non_parametric['var'] == var)).any()\n",
    "                if test == 'auto':\n",
    "                    if is_non_parametric:\n",
    "                        stat, p = mannwhitneyu(vals1, vals2)\n",
    "                        test_used = 'mannwhitney'\n",
    "                    else:\n",
    "                        stat, p = ttest_ind(vals1, vals2)\n",
    "                        test_used = 'ttest'\n",
    "                elif test == 'ttest':\n",
    "                    stat, p = ttest_ind(vals1, vals2)\n",
    "                    test_used = 'ttest'\n",
    "                else:\n",
    "                    stat, p = mannwhitneyu(vals1, vals2)\n",
    "                    test_used = 'mannwhitney'\n",
    "                if p < alpha:\n",
    "                    results.append({**group_dict, 'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "        else:\n",
    "            vals1 = df1[var].dropna()\n",
    "            vals2 = df2[var].dropna()\n",
    "            if len(vals1) < 2 or len(vals2) < 2:\n",
    "                continue\n",
    "            is_non_parametric = False\n",
    "            if non_parametric is not None:\n",
    "                is_non_parametric = (non_parametric['var'] == var).any()\n",
    "            if test == 'auto':\n",
    "                if is_non_parametric:\n",
    "                    stat, p = mannwhitneyu(vals1, vals2)\n",
    "                    test_used = 'mannwhitney'\n",
    "                else:\n",
    "                    stat, p = ttest_ind(vals1, vals2)\n",
    "                    test_used = 'ttest'\n",
    "            elif test == 'ttest':\n",
    "                stat, p = ttest_ind(vals1, vals2)\n",
    "                test_used = 'ttest'\n",
    "            else:\n",
    "                stat, p = mannwhitneyu(vals1, vals2)\n",
    "                test_used = 'mannwhitney'\n",
    "            if p < alpha:\n",
    "                results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5abeb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant differences found for date-averaged comparison.\n"
     ]
    }
   ],
   "source": [
    "comparison_df_date = compare_metrics(\n",
    "    dfs['RESULTS_MERGED'],\n",
    "    dfs['RESULTS_MERGED_DATE'],\n",
    "    variables,\n",
    "    group_cols=['experiment'],\n",
    "    non_parametric=non_parametric\n",
    ")\n",
    "print(comparison_df_date) if not comparison_df_date.empty else print(\"No significant differences found for date-averaged comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fc35a",
   "metadata": {},
   "source": [
    "### -> we can merge across dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a855a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant differences found between top 10 and minus top 10 averages.\n"
     ]
    }
   ],
   "source": [
    "# Average across animals, dates, and experiments for both top 10 and minus top 10 DataFrames\n",
    "def average_all(df, variables):\n",
    "    # Remove columns not needed for grouping (keep only variables)\n",
    "    return pd.DataFrame(df[variables].mean()).T\n",
    "\n",
    "# Prepare the two DataFrames (replace with your actual keys if different)\n",
    "top10_df = dfs['RESULTS_TT_MERGED_DATE']\n",
    "minus_top10_df = dfs['RESULTS_MTT_MERGED_DATE']\n",
    "\n",
    "# Average across all grouping columns (animals, dates, experiments)\n",
    "top10_avg = average_all(top10_df, variables)\n",
    "minus_top10_avg = average_all(minus_top10_df, variables)\n",
    "\n",
    "# Compare all variables between the two averaged DataFrames\n",
    "results = []\n",
    "for var in variables:\n",
    "    vals1 = top10_df[var].dropna()\n",
    "    vals2 = minus_top10_df[var].dropna()\n",
    "    # Use Mann-Whitney if either group is non-normal, else t-test (simple rule)\n",
    "    try:\n",
    "        if len(vals1) < 2 or len(vals2) < 2:\n",
    "            continue\n",
    "        _, p1 = shapiro(vals1) if len(vals1) > 3 else (None, 1)\n",
    "        _, p2 = shapiro(vals2) if len(vals2) > 3 else (None, 1)\n",
    "        if p1 < 0.05 or p2 < 0.05:\n",
    "            stat, p = mannwhitneyu(vals1, vals2)\n",
    "            test_used = 'mannwhitney'\n",
    "        else:\n",
    "            stat, p = ttest_ind(vals1, vals2)\n",
    "            test_used = 'ttest'\n",
    "        if p < 0.05:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing {var}: {e}\")\n",
    "\n",
    "comparison_df_top10 = pd.DataFrame(results)\n",
    "print(comparison_df_top10 if not comparison_df_top10.empty else \"No significant differences found between top 10 and minus top 10 averages.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0571d",
   "metadata": {},
   "source": [
    "### -> we can merge top 10 with the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a018d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant index effects found for any variable.\n"
     ]
    }
   ],
   "source": [
    "# Test if the index within lists (i.e., trial order) affects each variable in 'RESULTS'\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "\n",
    "def test_list_index_effect(df, variables, max_index=10, alpha=0.05):\n",
    "    \"\"\"\n",
    "    For each variable, tests if the value changes significantly across list indices (trial order).\n",
    "    Only prints significant results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for var in variables:\n",
    "        # Convert string lists to actual lists if needed\n",
    "        vals = df[var].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)\n",
    "        # Filter to rows that are lists and have enough length\n",
    "        list_rows = vals[vals.apply(lambda x: isinstance(x, list) and len(x) > 1)]\n",
    "        if list_rows.empty:\n",
    "            continue\n",
    "        # Find the minimum length across all lists (to avoid index errors)\n",
    "        min_len = min(list_rows.apply(len))\n",
    "        min_len = min(min_len, max_index)  # Limit to max_index if desired\n",
    "        # Gather values by index\n",
    "        index_groups = []\n",
    "        for i in range(min_len):\n",
    "            group = list_rows.apply(lambda x: x[i] if len(x) > i else np.nan).dropna()\n",
    "            if len(group) > 1:\n",
    "                index_groups.append(group.values)\n",
    "        if len(index_groups) < 2:\n",
    "            continue\n",
    "        # Use Kruskal-Wallis (non-parametric) or ANOVA (parametric) depending on normality\n",
    "        # Here, we use Kruskal-Wallis for robustness\n",
    "        stat, p = kruskal(*index_groups)\n",
    "        if p < alpha:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': 'kruskal'})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "significant_index_effects = test_list_index_effect(dfs['RESULTS'], variables)\n",
    "print(significant_index_effects if not significant_index_effects.empty else \"No significant index effects found for any variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80663e81",
   "metadata": {},
   "source": [
    "### -> we can merge across repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9382c7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant differences between males and females (Strength Metrics):\n",
      "    variable        stat             p         test\n",
      "0  peakValue  557.000000  3.085284e-08  mannwhitney\n",
      "1        RMS  502.000000  1.071114e-05  mannwhitney\n",
      "2        tau   -7.684638  8.658899e-10        ttest\n",
      "3        AUC  453.000000  6.940145e-04  mannwhitney\n",
      "\n",
      "Significant differences between males and females (Reaction Metrics):\n",
      "None found.\n"
     ]
    }
   ],
   "source": [
    "# Define metric groups\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def compare_male_female(df, metrics, alpha=0.05):\n",
    "    results = []\n",
    "    for var in metrics:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        vals_male = df[df['sex'] == 'male'][var].dropna()\n",
    "        vals_female = df[df['sex'] == 'female'][var].dropna()\n",
    "        if len(vals_male) < 2 or len(vals_female) < 2:\n",
    "            continue\n",
    "        # Normality check\n",
    "        _, p1 = shapiro(vals_male) if len(vals_male) > 3 else (None, 1)\n",
    "        _, p2 = shapiro(vals_female) if len(vals_female) > 3 else (None, 1)\n",
    "        if p1 < 0.05 or p2 < 0.05:\n",
    "            stat, p = mannwhitneyu(vals_male, vals_female)\n",
    "            test_used = 'mannwhitney'\n",
    "        else:\n",
    "            stat, p = ttest_ind(vals_male, vals_female)\n",
    "            test_used = 'ttest'\n",
    "        if p < alpha:\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': test_used})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "print(\"Significant differences between males and females (Strength Metrics):\")\n",
    "strength_results = compare_male_female(df, strength_metrics)\n",
    "print(strength_results if not strength_results.empty else \"None found.\")\n",
    "\n",
    "print(\"\\nSignificant differences between males and females (Reaction Metrics):\")\n",
    "reaction_results = compare_male_female(df, reaction_metrics)\n",
    "print(reaction_results if not reaction_results.empty else \"None found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea54e63",
   "metadata": {},
   "source": [
    "### -> split by sex for strength\n",
    "### -> merge for reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b6f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of recording order on strength metrics (split by sex):\n",
      "peakValue (male): stat=15.612, p=0.000407\n",
      "RMS (male): stat=15.360, p=0.000462\n",
      "tau (male): stat=17.360, p=0.00017\n",
      "AUC (male): stat=16.340, p=0.000283\n",
      "peakValue (female): stat=12.345, p=0.00209\n",
      "RMS (female): stat=10.305, p=0.00578\n",
      "tau (female): stat=15.855, p=0.000361\n",
      "AUC (female): stat=9.965, p=0.00686\n",
      "\n",
      "Effect of recording order on reaction metrics (split by sex):\n",
      "reactionTime (male): stat=7.483, p=0.0237\n",
      "peakTime (male): stat=13.138, p=0.0014\n",
      "difference (male): stat=10.373, p=0.00559\n",
      "reactionTime (female): stat=14.613, p=0.000671\n",
      "difference (female): stat=6.289, p=0.0431\n"
     ]
    }
   ],
   "source": [
    "# forgot non_parametric whoops\n",
    "\"\"\" # Compare the effect of recording_order (animal order) on strength and reaction metrics, split by sex for both\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def extract_animal_number(animal_str):\n",
    "    # Extracts the number from 'Animal15' -> 15\n",
    "    if isinstance(animal_str, str) and animal_str.lower().startswith('animal'):\n",
    "        return int(''.join(filter(str.isdigit, animal_str)))\n",
    "    return np.nan\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE'].copy()\n",
    "df['animal_num'] = df['animal'].apply(extract_animal_number)\n",
    "\n",
    "# Only keep animals in the recording_order\n",
    "df = df[df['animal_num'].isin(recording_order)]\n",
    "df['rec_order'] = df['animal_num'].apply(lambda x: recording_order.index(x) if x in recording_order else np.nan)\n",
    "\n",
    "print(\"Effect of recording order on strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Group by recording order\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of recording order on reaction metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): stat={stat:.3f}, p={p:.3g}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4185a6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of recording order on strength metrics (split by sex):\n",
      "peakValue (male): ANOVA stat=44.094, p=3.04e-08\n",
      "RMS (male): ANOVA stat=48.562, p=1.33e-08\n",
      "tau (male): ANOVA stat=41.245, p=5.33e-08\n",
      "AUC (male): ANOVA stat=55.988, p=3.83e-09\n",
      "peakValue (female): ANOVA stat=15.351, p=7.79e-05\n",
      "RMS (female): ANOVA stat=10.820, p=0.000589\n",
      "tau (female): ANOVA stat=32.518, p=3.71e-07\n",
      "AUC (female): ANOVA stat=7.906, p=0.00276\n",
      "\n",
      "Effect of recording order on reaction metrics (split by sex):\n",
      "reactionTime (male): Kruskal-Wallis stat=7.483, p=0.0237\n",
      "peakTime (male): Kruskal-Wallis stat=13.138, p=0.0014\n",
      "difference (male): Kruskal-Wallis stat=10.373, p=0.00559\n",
      "reactionTime (female): Kruskal-Wallis stat=14.613, p=0.000671\n",
      "difference (female): Kruskal-Wallis stat=6.289, p=0.0431\n"
     ]
    }
   ],
   "source": [
    "# Compare the effect of recording_order (animal order) on strength and reaction metrics, split by sex for both\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "def extract_animal_number(animal_str):\n",
    "    # Extracts the number from 'Animal15' -> 15\n",
    "    if isinstance(animal_str, str) and animal_str.lower().startswith('animal'):\n",
    "        return int(''.join(filter(str.isdigit, animal_str)))\n",
    "    return np.nan\n",
    "\n",
    "df = dfs['RESULTS_MERGED_DATE'].copy()\n",
    "df['animal_num'] = df['animal'].apply(extract_animal_number)\n",
    "\n",
    "# Only keep animals in the recording_order\n",
    "df = df[df['animal_num'].isin(recording_order)]\n",
    "df['rec_order'] = df['animal_num'].apply(lambda x: recording_order.index(x) if x in recording_order else np.nan)\n",
    "\n",
    "print(\"Effect of recording order on strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Group by recording order\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        # Check if this variable should be non-parametric for any experiment in this sex\n",
    "        is_non_parametric = False\n",
    "        for rec_idx, group in df_sex.groupby('rec_order'):\n",
    "            # Use the first experiment name in the group (if available)\n",
    "            if not group.empty and 'experiment' in group.columns:\n",
    "                exp_name = group['experiment'].iloc[0]\n",
    "                if ((non_parametric['experiment'] == exp_name) & (non_parametric['var'] == var)).any():\n",
    "                    is_non_parametric = True\n",
    "                    break\n",
    "        if is_non_parametric:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        else:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of recording order on reaction metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        is_non_parametric = False\n",
    "        for rec_idx, group in df_sex.groupby('rec_order'):\n",
    "            if not group.empty and 'experiment' in group.columns:\n",
    "                exp_name = group['experiment'].iloc[0]\n",
    "                if ((non_parametric['experiment'] == exp_name) & (non_parametric['var'] == var)).any():\n",
    "                    is_non_parametric = True\n",
    "                    break\n",
    "        if is_non_parametric:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        else:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): {test_used} stat={stat:.3f}, p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2fe52",
   "metadata": {},
   "source": [
    "### -> Significant influence of recording order / time of day on strength and reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9012785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post hoc Dunn's test for strength metrics (split by sex):\n",
      "\n",
      "peakValue (male):\n",
      "          0        1         5\n",
      "0  1.000000  1.00000  0.004943\n",
      "1  1.000000  1.00000  0.000810\n",
      "5  0.004943  0.00081  1.000000\n",
      "Means by rec_order: {0: 186.05694444444447, 1: 186.8, 5: 123.6875}\n",
      "\n",
      "RMS (male):\n",
      "          0         1         5\n",
      "0  1.000000  1.000000  0.002066\n",
      "1  1.000000  1.000000  0.002066\n",
      "5  0.002066  0.002066  1.000000\n",
      "Means by rec_order: {0: 48.8924375, 1: 48.00978472222222, 5: 27.853645833333335}\n",
      "\n",
      "tau (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.471898  0.000123\n",
      "1  0.471898  1.000000  0.021629\n",
      "5  0.000123  0.021629  1.000000\n",
      "Means by rec_order: {0: 136.84158333333335, 1: 125.58318055555554, 5: 97.0806875}\n",
      "\n",
      "AUC (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.966596  0.000302\n",
      "1  0.966596  1.000000  0.011226\n",
      "5  0.000302  0.011226  1.000000\n",
      "Means by rec_order: {0: 18846.249902777778, 1: 17238.18497222222, 5: 9447.599375}\n",
      "\n",
      "peakValue (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.001395  0.131634\n",
      "3  0.001395  1.000000  0.412692\n",
      "4  0.131634  0.412692  1.000000\n",
      "Means by rec_order: {2: 74.97291666666666, 3: 108.85833333333333, 4: 97.40416666666667}\n",
      "\n",
      "RMS (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.006296  0.058873\n",
      "3  0.006296  1.000000  1.000000\n",
      "4  0.058873  1.000000  1.000000\n",
      "Means by rec_order: {2: 20.570375, 3: 29.037499999999998, 4: 27.373145833333332}\n",
      "\n",
      "tau (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.000261  0.503815\n",
      "3  0.000261  1.000000  0.032728\n",
      "4  0.503815  0.032728  1.000000\n",
      "Means by rec_order: {2: 169.57979166666667, 3: 141.08247916666667, 4: 160.30166666666668}\n",
      "\n",
      "AUC (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.039985  0.010023\n",
      "3  0.039985  1.000000  1.000000\n",
      "4  0.010023  1.000000  1.000000\n",
      "Means by rec_order: {2: 8705.042104166667, 3: 11197.558500000001, 4: 11522.484125}\n",
      "\n",
      "Post hoc Dunn's test for reaction metrics (split by sex):\n",
      "\n",
      "reactionTime (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.031314  1.000000\n",
      "1  0.031314  1.000000  0.103739\n",
      "5  1.000000  0.103739  1.000000\n",
      "Means by rec_order: {0: 10.504166666666666, 1: 9.925, 5: 10.066666666666666}\n",
      "\n",
      "peakTime (male):\n",
      "          0         1         5\n",
      "0  1.000000  1.000000  0.019306\n",
      "1  1.000000  1.000000  0.001794\n",
      "5  0.019306  0.001794  1.000000\n",
      "Means by rec_order: {0: 31.304166666666667, 1: 32.40555555555555, 5: 28.2625}\n",
      "\n",
      "difference (male):\n",
      "          0         1         5\n",
      "0  1.000000  0.965333  0.092654\n",
      "1  0.965333  1.000000  0.004909\n",
      "5  0.092654  0.004909  1.000000\n",
      "Means by rec_order: {0: 20.8, 1: 22.480555555555554, 5: 18.195833333333333}\n",
      "\n",
      "reactionTime (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.012143  0.000885\n",
      "3  0.012143  1.000000  1.000000\n",
      "4  0.000885  1.000000  1.000000\n",
      "Means by rec_order: {2: 11.516666666666667, 3: 10.170833333333333, 4: 9.791666666666666}\n",
      "\n",
      "difference (female):\n",
      "          2         3         4\n",
      "2  1.000000  0.189777  0.050815\n",
      "3  0.189777  1.000000  1.000000\n",
      "4  0.050815  1.000000  1.000000\n",
      "Means by rec_order: {2: 19.241666666666667, 3: 20.704166666666666, 4: 21.116666666666667}\n"
     ]
    }
   ],
   "source": [
    "# Post hoc test: Dunn's test for pairwise comparisons between recording orders, with effect direction and strength\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "print(\"Post hoc Dunn's test for strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        # Only test if there was a significant Kruskal-Wallis result before\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            # Dunn's test\n",
    "            dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='rec_order', p_adjust='bonferroni')\n",
    "            print(f\"\\n{var} ({sex}):\")\n",
    "            print(dunn)\n",
    "            # Effect direction and strength: print group means\n",
    "            means = df_sex.groupby('rec_order')[var].mean()\n",
    "            print(\"Means by rec_order:\", means.to_dict())\n",
    "\n",
    "print(\"\\nPost hoc Dunn's test for reaction metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('rec_order')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='rec_order', p_adjust='bonferroni')\n",
    "            print(f\"\\n{var} ({sex}):\")\n",
    "            print(dunn)\n",
    "            means = df_sex.groupby('rec_order')[var].mean()\n",
    "            print(\"Means by rec_order:\", means.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f3b86",
   "metadata": {},
   "source": [
    "### -> generally: decrease in strength, increase in reaction time across day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebbe98",
   "metadata": {},
   "source": [
    "Order effects are strong and consistent: Animals recorded later in the session have lower strength and reaction metrics. <br>\n",
    "Effect is present in both sexes, but the specific rec_order pairs differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5c0189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of experiment type on strength metrics (split by sex):\n",
      "\n",
      "Effect of experiment type on reaction metrics (all animals):\n"
     ]
    }
   ],
   "source": [
    "# Test if experiment type has an influence on strength and reaction time metrics, splitting by sex for strength\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "df_exp = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "print(\"Effect of experiment type on strength metrics (split by sex):\")\n",
    "for sex in ['male', 'female']:\n",
    "    df_sex = df_exp[df_exp['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        stat, p = kruskal(*groups)\n",
    "        if p < 0.05:\n",
    "            print(f\"{var} ({sex}): stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of experiment type on reaction metrics (all animals):\")\n",
    "for var in reaction_metrics:\n",
    "    if var not in df_exp.columns:\n",
    "        continue\n",
    "    groups = [group[var].dropna().values for _, group in df_exp.groupby('experiment')]\n",
    "    groups = [g for g in groups if len(g) > 1]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    stat, p = kruskal(*groups)\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: stat={stat:.3f}, p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d2146",
   "metadata": {},
   "source": [
    "### -> no effect of experiment type on any variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0aee5",
   "metadata": {},
   "source": [
    "this doesn't make any sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10301e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Effect of experiment type on strength metrics (male):\n",
      "\n",
      "Effect of experiment type on reaction metrics (male):\n",
      "\n",
      "Effect of experiment type on strength metrics (female):\n",
      "\n",
      "Effect of experiment type on reaction metrics (female):\n"
     ]
    }
   ],
   "source": [
    "# Test if experiment type has an influence on strength and reaction time metrics (no sex split)\n",
    "# Uses parametric (ANOVA) if all groups are normal, otherwise non-parametric (Kruskal-Wallis)\n",
    "\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "df_exp = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "def group_normality(groups):\n",
    "    \"\"\"Return True if all groups are normal (p > 0.05), False otherwise.\"\"\"\n",
    "    for g in groups:\n",
    "        if len(g) < 3:\n",
    "            return False\n",
    "        _, p = shapiro(g)\n",
    "        if p < 0.05:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(\"Effect of experiment type on strength metrics (all animals):\")\n",
    "for var in strength_metrics:\n",
    "    if var not in df_exp.columns:\n",
    "        continue\n",
    "    groups = [group[var].dropna().values for _, group in df_exp.groupby('experiment')]\n",
    "    groups = [g for g in groups if len(g) > 2]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    if group_normality(groups):\n",
    "        stat, p = f_oneway(*groups)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        stat, p = kruskal(*groups)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "print(\"\\nEffect of experiment type on reaction metrics (all animals):\")\n",
    "for var in reaction_metrics:\n",
    "    if var not in df_exp.columns:\n",
    "        continue\n",
    "    groups = [group[var].dropna().values for _, group in df_exp.groupby('experiment')]\n",
    "    groups = [g for g in groups if len(g) > 2]\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "    if group_normality(groups):\n",
    "        stat, p = f_oneway(*groups)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        stat, p = kruskal(*groups)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "553db9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tukey HSD post hoc for reactionTime by experiment:\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------------------------\n",
      "    ASR_control       gap_depth    -0.65 0.8504 -2.1306 0.8306  False\n",
      "    ASR_control gap_duration_10  -0.3778 0.9912 -1.8584 1.1029  False\n",
      "    ASR_control gap_duration_20  -0.5389 0.9376 -2.0195 0.9418  False\n",
      "    ASR_control  gap_duration_4  -0.3667 0.9926 -1.8473  1.114  False\n",
      "    ASR_control gap_duration_50  -0.3278 0.9963 -1.8084 1.1529  False\n",
      "    ASR_control  gap_duration_8  -0.1944 0.9999 -1.6751 1.2862  False\n",
      "    ASR_control   tone_in_noise  -1.6667 0.0179 -3.1473 -0.186   True\n",
      "      gap_depth gap_duration_10   0.2722 0.9989 -1.2084 1.7529  False\n",
      "      gap_depth gap_duration_20   0.1111    1.0 -1.3695 1.5918  False\n",
      "      gap_depth  gap_duration_4   0.2833 0.9985 -1.1973  1.764  False\n",
      "      gap_depth gap_duration_50   0.3222 0.9967 -1.1584 1.8029  False\n",
      "      gap_depth  gap_duration_8   0.4556 0.9742 -1.0251 1.9362  False\n",
      "      gap_depth   tone_in_noise  -1.0167 0.3763 -2.4973  0.464  False\n",
      "gap_duration_10 gap_duration_20  -0.1611    1.0 -1.6418 1.3195  False\n",
      "gap_duration_10  gap_duration_4   0.0111    1.0 -1.4695 1.4918  False\n",
      "gap_duration_10 gap_duration_50     0.05    1.0 -1.4306 1.5306  False\n",
      "gap_duration_10  gap_duration_8   0.1833 0.9999 -1.2973  1.664  False\n",
      "gap_duration_10   tone_in_noise  -1.2889 0.1284 -2.7695 0.1918  False\n",
      "gap_duration_20  gap_duration_4   0.1722 0.9999 -1.3084 1.6529  False\n",
      "gap_duration_20 gap_duration_50   0.2111 0.9998 -1.2695 1.6918  False\n",
      "gap_duration_20  gap_duration_8   0.3444  0.995 -1.1362 1.8251  False\n",
      "gap_duration_20   tone_in_noise  -1.1278 0.2532 -2.6084 0.3529  False\n",
      " gap_duration_4 gap_duration_50   0.0389    1.0 -1.4418 1.5195  False\n",
      " gap_duration_4  gap_duration_8   0.1722 0.9999 -1.3084 1.6529  False\n",
      " gap_duration_4   tone_in_noise     -1.3  0.122 -2.7806 0.1806  False\n",
      "gap_duration_50  gap_duration_8   0.1333    1.0 -1.3473  1.614  False\n",
      "gap_duration_50   tone_in_noise  -1.3389 0.1017 -2.8195 0.1418  False\n",
      " gap_duration_8   tone_in_noise  -1.4722 0.0523 -2.9529 0.0084  False\n",
      "---------------------------------------------------------------------\n",
      "Means by experiment: {'ASR_control': 10.844444444444443, 'gap_depth': 10.194444444444445, 'gap_duration_10': 10.466666666666667, 'gap_duration_20': 10.305555555555555, 'gap_duration_4': 10.477777777777778, 'gap_duration_50': 10.516666666666666, 'gap_duration_8': 10.65, 'tone_in_noise': 9.177777777777777}\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Only run post hoc if ANOVA was significant for reactionTime\n",
    "if 'reactionTime' in df_exp.columns:\n",
    "    # Drop NaNs and get relevant columns\n",
    "    posthoc_df = df_exp[['experiment', 'reactionTime']].dropna()\n",
    "    # Tukey HSD\n",
    "    tukey = pairwise_tukeyhsd(posthoc_df['reactionTime'], posthoc_df['experiment'], alpha=0.05)\n",
    "    print(\"\\nTukey HSD post hoc for reactionTime by experiment:\")\n",
    "    print(tukey.summary())\n",
    "    # Effect direction: print group means\n",
    "    means = posthoc_df.groupby('experiment')['reactionTime'].mean()\n",
    "    print(\"Means by experiment:\", means.to_dict())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3302b7",
   "metadata": {},
   "source": [
    "ASR_control vs. tone_in_noise (meandiff = -1.67, p-adj = 0.0179, reject = True) <br>\n",
    "\"tone_in_noise\" has the lowest mean reaction time, and is significantly different from \"ASR_control\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8ab9f6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Effect of experiment type on strength metrics (male):\n",
      "\n",
      "Effect of experiment type on reaction metrics (male):\n",
      "\n",
      "Effect of experiment type on strength metrics (female):\n",
      "\n",
      "Effect of experiment type on reaction metrics (female):\n"
     ]
    }
   ],
   "source": [
    "# Test if experiment type has an influence on strength and reaction time metrics, split by sex for both\n",
    "\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "df_exp = dfs['RESULTS_MERGED_DATE']\n",
    "\n",
    "def group_normality(groups):\n",
    "    \"\"\"Return True if all groups are normal (p > 0.05), False otherwise.\"\"\"\n",
    "    for g in groups:\n",
    "        if len(g) < 3:\n",
    "            return False\n",
    "        _, p = shapiro(g)\n",
    "        if p < 0.05:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for sex in ['male', 'female']:\n",
    "    print(f\"\\nEffect of experiment type on strength metrics ({sex}):\")\n",
    "    df_sex = df_exp[df_exp['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 2]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        if group_normality(groups):\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        else:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "\n",
    "    print(f\"\\nEffect of experiment type on reaction metrics ({sex}):\")\n",
    "    for var in reaction_metrics:\n",
    "        if var not in df_sex.columns:\n",
    "            continue\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('experiment')]\n",
    "        groups = [g for g in groups if len(g) > 2]\n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "        if group_normality(groups):\n",
    "            stat, p = f_oneway(*groups)\n",
    "            test_used = \"ANOVA\"\n",
    "        else:\n",
    "            stat, p = kruskal(*groups)\n",
    "            test_used = \"Kruskal-Wallis\"\n",
    "        if p < 0.05:\n",
    "            print(f\"{var}: {test_used} stat={stat:.3f}, p={p:.3g}\")\n",
    "            # Post hoc Tukey HSD if ANOVA\n",
    "            if test_used == \"ANOVA\":\n",
    "                posthoc_df = df_sex[['experiment', var]].dropna()\n",
    "                tukey = pairwise_tukeyhsd(posthoc_df[var], posthoc_df['experiment'], alpha=0.05)\n",
    "                print(f\"\\nTukey HSD post hoc for {var} by experiment ({sex}):\")\n",
    "                print(tukey.summary())\n",
    "                means = posthoc_df.groupby('experiment')[var].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ba562",
   "metadata": {},
   "source": [
    "...but if we split by sex, this effect vanishes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fce79",
   "metadata": {},
   "source": [
    "### -> no effect of experiment type on any variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
