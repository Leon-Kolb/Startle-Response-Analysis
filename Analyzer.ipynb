{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01fa7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro, boxcox, ttest_ind, mannwhitneyu, pearsonr, friedmanchisquare, kruskal, kstest, \\\n",
    "    lognorm, gamma, weibull_min, probplot, f_oneway, linregress, norm, spearmanr, ttest_1samp, wilcoxon \n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, mixedlm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "89cb28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"Results\" # input directory\n",
    "\n",
    "number = 1 # results to analyze (subfolder name, can be an integer or string)\n",
    "\n",
    "recording_order = (15, 2, 1, 6, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ['RESULTS', 'RESULTS_MTT', 'RESULTS_TT'] in Results\\1.\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "results_dir = os.path.join(input_dir, str(number))\n",
    "files = [file for file in os.listdir(results_dir) if file.endswith(('.xlsx', '.xls')) and not file.startswith('OVERVIEW')]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(results_dir, file)\n",
    "    dfs[file.split('.')[0]] = pd.read_excel(file_path)\n",
    "\n",
    "framenames = list(dfs.keys())\n",
    "results = framenames[0]\n",
    "results_mtt = framenames[1]\n",
    "results_tt = framenames[2]\n",
    "\n",
    "print(f\"Found {framenames} in {results_dir}.\")\n",
    "\n",
    "framenames.append('RESULTS_MERGED')\n",
    "framenames.append('RESUlTS_MERGED_MTT')\n",
    "framenames.append('RESULTS_MERGED_TT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771bdf0",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80bd6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read experiment column and create a list for every experiment without duplicates\n",
    "# run shapiro on every experiment with sex split and save the results as booleans into a dictionary\n",
    "# run correct tests on every metric, using the normality dictionary for guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab8f4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 experiments, 7 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50\n",
      " reactionTime, peakTime, difference, peakValue, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n"
     ]
    }
   ],
   "source": [
    "experiments = dfs[results]['experiment'].unique().tolist()\n",
    "variables = dfs[results].columns[4:].tolist()\n",
    "parameters = dfs[results].columns[:4].tolist()\n",
    "print(f\"Found {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1710b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1kolb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "c:\\Users\\1kolb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "c:\\Users\\1kolb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "c:\\Users\\1kolb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "c:\\Users\\1kolb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "non_parametric_dfs = {}\n",
    "for name, df in dfs.items():\n",
    "    if not name.endswith('_MERGED'):\n",
    "        continue  # Only process merged dataframes\n",
    "    non_parametric = pd.DataFrame(columns=['experiment', 'var'])\n",
    "    not_enough_data = 0\n",
    "    for var in variables:\n",
    "        for exp in experiments:\n",
    "            for sex in ['male', 'female']:\n",
    "                data = df[(df['sex'] == sex) & (df['experiment'] == exp)][var].dropna()\n",
    "                if len(data) > 2:\n",
    "                    stat, p = shapiro(data)\n",
    "                    if p < 0.05:\n",
    "                        non_parametric = pd.concat(\n",
    "                            [non_parametric, pd.DataFrame({'experiment': [exp], 'var': [var]})],\n",
    "                            ignore_index=True\n",
    "                        )\n",
    "                else:\n",
    "                    not_enough_data += 1\n",
    "    non_parametric_dfs[name] = non_parametric\n",
    "    #print(f\"Non-parametric entries in {name}: {len(non_parametric)}\")\n",
    "    #if not_enough_data != 0: print(f\"Warning, not enough data for {not_enough_data} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dff3c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(non_parametric_dfs['RESULTS_MERGED']))\n",
    "print(len(non_parametric_dfs['RESULTS_MTT_MERGED']))\n",
    "print(len(non_parametric_dfs['RESULTS_TT_MERGED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f3b2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         experiment           var\n",
      "0       ASR_control  reactionTime\n",
      "1    gap_duration_4  reactionTime\n",
      "2    gap_duration_8  reactionTime\n",
      "3   gap_duration_10  reactionTime\n",
      "4   gap_duration_50  reactionTime\n",
      "5       ASR_control      peakTime\n",
      "6         gap_depth      peakTime\n",
      "7     tone_in_noise      peakTime\n",
      "8    gap_duration_4      peakTime\n",
      "9    gap_duration_8      peakTime\n",
      "10  gap_duration_10      peakTime\n",
      "11  gap_duration_20      peakTime\n",
      "12  gap_duration_50      peakTime\n",
      "13      ASR_control    difference\n",
      "14  gap_duration_20    difference\n",
      "15  gap_duration_50    difference\n",
      "16        gap_depth           AUC\n",
      "17        gap_depth           RMS\n",
      "18        gap_depth  reactionTime\n",
      "19    tone_in_noise  reactionTime\n",
      "20  gap_duration_20  reactionTime\n",
      "21        gap_depth    difference\n",
      "22  gap_duration_10    difference\n",
      "23   gap_duration_4           tau\n",
      "24  gap_duration_10           AUC\n",
      "61   gap_duration_4    difference\n",
      "62   gap_duration_8    difference\n",
      "77   gap_duration_8           tau\n",
      "78  gap_duration_10           tau\n",
      "79  gap_duration_20           tau\n",
      "80  gap_duration_50           tau\n",
      "81   gap_duration_4           AUC\n",
      "82   gap_duration_8           AUC\n",
      "83  gap_duration_20           AUC\n",
      "84  gap_duration_50           AUC\n"
     ]
    }
   ],
   "source": [
    "gap_durations = ['gap_duration_4', 'gap_duration_8', 'gap_duration_10', 'gap_duration_20', 'gap_duration_50']\n",
    "\n",
    "# Concatenate and drop duplicates as before\n",
    "dfs_to_merge = [\n",
    "    non_parametric_dfs['RESULTS_MERGED'],\n",
    "    non_parametric_dfs['RESULTS_MTT_MERGED'],\n",
    "    non_parametric_dfs['RESULTS_TT_MERGED']\n",
    "]\n",
    "non_parametric = pd.concat(dfs_to_merge, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Extend: for each row with \"gap_duration\" in experiment, add all gap_duration_* for that var\n",
    "rows_to_add = []\n",
    "for _, row in non_parametric.iterrows():\n",
    "    if \"gap_duration\" in row['experiment']:\n",
    "        for gap_exp in gap_durations:\n",
    "            if gap_exp != row['experiment']:\n",
    "                new_row = row.copy()\n",
    "                new_row['experiment'] = gap_exp\n",
    "                rows_to_add.append(new_row)\n",
    "\n",
    "# Add the new rows and drop duplicates again\n",
    "if rows_to_add:\n",
    "    non_parametric = pd.concat([non_parametric, pd.DataFrame(rows_to_add)], ignore_index=True).drop_duplicates()\n",
    "\n",
    "print(non_parametric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e040c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dfs:\n",
    "# df: main df, merged in date and reps\n",
    "# date_df: df with date, merged in reps\n",
    "# reps_df: df with reps, merged in date\n",
    "# df_top_10: top 10 df, merged in date and reps\n",
    "# minus_top_10: df with top 10 removed, merged in date and reps\n",
    "\n",
    "# df\n",
    "# tt, mtt, dt, rp\n",
    "# tt_dt, tt_rp, mt_dt, mt_rp\n",
    "# dt_rp, tt_dt_rp, mt_dt_rp<\n",
    "\n",
    "# averaging across reps and dates only occurs in Analyzer\n",
    "# Peakfinder only outputs a merged df for overview\n",
    "# it also gives a top_10, minus_top_10 and main dataframe, each with repetitions and dates not averages\n",
    "\n",
    "\n",
    "# abbreviations: \n",
    "    # tt: top 10\n",
    "    # mtt: minus top 10\n",
    "    # dt: date\n",
    "    # rp: reps\n",
    "    # examples: tt_dt_rp: top 10 with date and reps | dt_rp: date and reps | df: fully merged df\n",
    "\n",
    "    # test_df is the currently tested df and can change depending on previous test results\n",
    "\n",
    "# test order depends on each previous result (as in if we can't merge across days, then use date_df for rest, for example)\n",
    "\n",
    "# compare date df to df\n",
    "# compare top_10 df to minus_top_10 df\n",
    "# compare reps df to df\n",
    "# compare strength metrics between males and females\n",
    "# compare reaction time metrics between males and females\n",
    "# compare time of day (i.e. animal number in order 15, 2, 1, 6, 10, 4) for all metrics\n",
    "# compare experiment for all metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
