{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f583c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "350cf2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"Analyzer Results\"\n",
    "\n",
    "output_dir = \"Tester Results\"\n",
    "\n",
    "recording_order = [15, 2, 1, 6, 10, 4]\n",
    "\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9889a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RESULTS', 'RESULTS_MERGED', 'RESULTS_MERGED_DATE', 'RESULTS_MERGED_EXP', 'RESULTS_MTT', 'RESULTS_MTT_MERGED', 'RESULTS_MTT_MERGED_DATE', 'RESULTS_MTT_MERGED_EXP', 'RESULTS_TT', 'RESULTS_TT_MERGED', 'RESULTS_TT_MERGED_DATE', 'RESULTS_TT_MERGED_EXP']\n",
      "Found 12 dataframes in Analyzer Results.\n",
      "\n",
      "Found 18 experiments, 7 variables and 4 parameters:\n",
      " ASR_control, gap_depth, tone_in_noise, gap_duration_4, gap_duration_8, gap_duration_10, gap_duration_20, gap_duration_50, offset_PPI_4, offset_PPI_6, offset_PPI_8, offset_PPI_10, offset_PPI_12, offset_PPI_14, offset_PPI_16, offset_PPI_18, offset_PPI_20, offset_PPI_50\n",
      " reactionTime, peakTime, difference, peakValue, RMS, tau, AUC\n",
      " animal, sex, date, experiment\n",
      "\n",
      "Strength metrics are peakValue, RMS, tau, AUC, reaction metrics are reactionTime, peakTime, difference.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "files = [file for file in os.listdir(results_dir) if file.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(results_dir, file)\n",
    "    dfs[file.split('.')[0]] = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "print(list(dfs.keys()))\n",
    "print(f\"Found {len(dfs)} dataframes in {results_dir}.\")\n",
    "\n",
    "experiments = dfs[list(dfs.keys())[1]]['experiment'].unique().tolist()\n",
    "variables = dfs[list(dfs.keys())[1]].columns[4:].tolist()\n",
    "parameters = dfs[list(dfs.keys())[1]].columns[:4].tolist()\n",
    "print(f\"\\nFound {len(experiments)} experiments, {len(variables)} variables and {len(parameters)} parameters:\")\n",
    "print(\" \"+', '.join(experiments))\n",
    "print(\" \"+', '.join(variables))\n",
    "print(\" \"+', '.join(parameters))\n",
    "print(f\"\\nStrength metrics are {', '.join(strength_metrics)}, reaction metrics are {', '.join(reaction_metrics)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a3c1a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f580e9",
   "metadata": {},
   "source": [
    "Expectations:\n",
    "- date fluctuations\n",
    "- no repetition differences\n",
    "- sex differences in strength metrics\n",
    "- experiment differences, in particular with increased gap / offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100aafa5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02299bc8",
   "metadata": {},
   "source": [
    "## Top Ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "674ee8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex     date      variable        stat         p          test  \\\n",
      "0  female  April16  reactionTime  914.500000  0.003310  mannwhitneyu   \n",
      "1  female  April16      peakTime  941.500000  0.000362  mannwhitneyu   \n",
      "2  female   June26           tau    2.710889  0.010070        t-test   \n",
      "3  female    May20      peakTime  883.500000  0.007059  mannwhitneyu   \n",
      "4  female    May20           AUC   -2.844176  0.007101        t-test   \n",
      "\n",
      "   posthoc_p posthoc_test  effect_strength  mean_diff  \n",
      "0   0.003251         Dunn        -0.411265   0.766667  \n",
      "1   0.000354         Dunn        -0.452932   0.924074  \n",
      "2   0.003721    Tukey HSD         0.686849   0.114580  \n",
      "3   0.006939         Dunn        -0.363426  -0.296296  \n",
      "4   0.003340    Tukey HSD        -0.719183  -0.125304  \n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# Compare all variables between RESULTS_MTT_MERGED and RESULTS_TT_MERGED (parametric for strength metrics, non-parametric for reaction metrics), split by sex and date\n",
    "from scipy.stats import mannwhitneyu, ttest_ind\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "df_mtt = dfs['RESULTS_MTT_MERGED']\n",
    "df_tt = dfs['RESULTS_TT_MERGED']\n",
    "\n",
    "results = []\n",
    "for sex in ['male', 'female']:\n",
    "    for date in df_mtt['date'].unique():\n",
    "        df_mtt_sex_date = df_mtt[(df_mtt['sex'] == sex) & (df_mtt['date'] == date)]\n",
    "        df_tt_sex_date = df_tt[(df_tt['sex'] == sex) & (df_tt['date'] == date)]\n",
    "        for var in variables:\n",
    "            vals_mtt = df_mtt_sex_date[var].dropna()\n",
    "            vals_tt = df_tt_sex_date[var].dropna()\n",
    "            if len(vals_mtt) > 1 and len(vals_tt) > 1:\n",
    "                mean_diff = vals_mtt.mean() - vals_tt.mean()\n",
    "                if var in strength_metrics:\n",
    "                    # Parametric t-test for strength metrics\n",
    "                    stat, p = ttest_ind(vals_mtt, vals_tt, equal_var=False)\n",
    "                    test_type = \"t-test\"\n",
    "                    # Cohen's d effect size\n",
    "                    pooled_std = ((vals_mtt.std(ddof=1) ** 2 + vals_tt.std(ddof=1) ** 2) / 2) ** 0.5\n",
    "                    effect_strength = mean_diff / pooled_std if pooled_std > 0 else None\n",
    "                    # Post hoc: Tukey HSD\n",
    "                    try:\n",
    "                        from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "                        combined = pd.concat([vals_mtt, vals_tt])\n",
    "                        group = ['MTT'] * len(vals_mtt) + ['TT'] * len(vals_tt)\n",
    "                        tukey = pairwise_tukeyhsd(combined, group)\n",
    "                        posthoc_p = tukey.pvalues[0] if len(tukey.pvalues) > 0 else None\n",
    "                        posthoc_test = \"Tukey HSD\"\n",
    "                    except Exception:\n",
    "                        posthoc_p = None\n",
    "                        posthoc_test = \"Tukey HSD\"\n",
    "                else:\n",
    "                    # Non-parametric Mann-Whitney U for reaction metrics\n",
    "                    stat, p = mannwhitneyu(vals_mtt, vals_tt)\n",
    "                    test_type = \"mannwhitneyu\"\n",
    "                    # Effect strength (rank-biserial)\n",
    "                    u, _ = mannwhitneyu(vals_mtt, vals_tt, alternative='two-sided')\n",
    "                    n1, n2 = len(vals_mtt), len(vals_tt)\n",
    "                    effect_strength = 1 - (2 * u) / (n1 * n2)\n",
    "                    # Post hoc: Dunn's test\n",
    "                    try:\n",
    "                        data = pd.DataFrame({var: pd.concat([vals_mtt, vals_tt]),\n",
    "                                            'group': ['MTT'] * len(vals_mtt) + ['TT'] * len(vals_tt)})\n",
    "                        dunn = sp.posthoc_dunn(data, val_col=var, group_col='group', p_adjust='bonferroni')\n",
    "                        posthoc_p = dunn.loc['MTT', 'TT']\n",
    "                        posthoc_test = \"Dunn\"\n",
    "                    except Exception:\n",
    "                        posthoc_p = None\n",
    "                        posthoc_test = \"Dunn\"\n",
    "                if p < 0.05:\n",
    "                    results.append({\n",
    "                        'sex': sex,\n",
    "                        'date': date,\n",
    "                        'variable': var,\n",
    "                        'stat': stat,\n",
    "                        'p': p,\n",
    "                        'test': test_type,\n",
    "                        'posthoc_p': posthoc_p,\n",
    "                        'posthoc_test': posthoc_test,\n",
    "                        'effect_strength': effect_strength,\n",
    "                        'mean_diff': mean_diff\n",
    "                    })\n",
    "\n",
    "test_top_ten = pd.DataFrame(results)\n",
    "print(test_top_ten)\n",
    "\n",
    "test_top_ten.to_excel(os.path.join(output_dir, \"TEST_TOP_TEN.xlsx\"), index=False)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3cad4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e9254",
   "metadata": {},
   "source": [
    "## Average Reaction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b7c32cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reaction time (excluding outliers): min = 8.00, max = 13.60\n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR bounds\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "vals = df['reactionTime'].dropna()\n",
    "\n",
    "q1 = vals.quantile(0.25)\n",
    "q3 = vals.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "filtered = vals[(vals >= lower) & (vals <= upper)]\n",
    "\n",
    "min_val = filtered.min()\n",
    "max_val = filtered.max()\n",
    "print(f\"Average reaction time (excluding outliers): min = {min_val:.2f}, max = {max_val:.2f}\")\n",
    "\n",
    "# Save result to file named by the result\n",
    "filename = f\"RT_iqr_{min_val:.2f}-{max_val:.2f}.xlsx\"\n",
    "iqr_df = pd.DataFrame({'min_reaction_time': [min_val], 'max_reaction_time': [max_val]})\n",
    "iqr_df.to_excel(os.path.join(output_dir, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8125f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148afc5",
   "metadata": {},
   "source": [
    "## Repetition Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f014a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant repetition effects found for any variable.\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# Test if the value changes over repetitions (trial order) for each variable in RESULTS_MTT (non-parametric)\n",
    "import ast\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "def test_repetition_effect(df, variables, max_reps=5, alpha=0.05):\n",
    "    results = []\n",
    "    for var in variables:\n",
    "        # Convert string lists to actual lists if needed\n",
    "        vals = df[var].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)\n",
    "        # Filter to rows that are lists and have enough length\n",
    "        list_rows = vals[vals.apply(lambda x: isinstance(x, list) and len(x) > 1)]\n",
    "        if list_rows.empty:\n",
    "            continue\n",
    "        # Find the minimum length across all lists (to avoid index errors)\n",
    "        min_len = min(list_rows.apply(len))\n",
    "        min_len = min(min_len, max_reps)\n",
    "        # Gather values by repetition index\n",
    "        rep_groups = []\n",
    "        for i in range(min_len):\n",
    "            group = list_rows.apply(lambda x: x[i] if len(x) > i else np.nan).dropna()\n",
    "            if len(group) > 1:\n",
    "                rep_groups.append(group.values)\n",
    "        if len(rep_groups) < 2:\n",
    "            continue\n",
    "        # Kruskal-Wallis test across repetitions\n",
    "        stat, p = kruskal(*rep_groups)\n",
    "        if p < alpha:\n",
    "            mean_diff = np.mean(rep_groups[0]) - np.mean(rep_groups[-1])\n",
    "            results.append({'variable': var, 'stat': stat, 'p': p, 'test': 'kruskal', 'mean_diff': mean_diff})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "repetition_effects = test_repetition_effect(dfs['RESULTS_MTT'], variables)\n",
    "test_repetition = pd.DataFrame(repetition_effects)\n",
    "\n",
    "if not repetition_effects.empty:\n",
    "    print(test_repetition)\n",
    "    test_repetition.to_excel(os.path.join(output_dir, \"TEST_REPETITION.xlsx\"), index=False)\n",
    "else:\n",
    "    print(\"No significant repetition effects found for any variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f25ede",
   "metadata": {},
   "source": [
    "### ---> merge across repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd47fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bf1d3",
   "metadata": {},
   "source": [
    "## Date Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0cb3fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sex      variable       stat             p  significant     posthoc_p  \\\n",
      "0   female     peakValue  56.469557  2.955105e-19         True  7.570389e-12   \n",
      "1   female           RMS  68.692063  3.152127e-22         True  9.869439e-12   \n",
      "2   female           tau   2.956243  5.488011e-02        False           NaN   \n",
      "3   female           AUC  97.016611  2.882260e-28         True  1.908584e-12   \n",
      "4   female  reactionTime  43.708603  3.226989e-10         True  3.220414e-10   \n",
      "5   female      peakTime   6.602514  3.683684e-02         True  4.982239e-02   \n",
      "6   female    difference  41.644566  9.057270e-10         True  4.913810e-08   \n",
      "7     male     peakValue  16.828890  2.347149e-07         True  2.560890e-06   \n",
      "8     male           RMS   5.830719  3.600036e-03         True  2.767602e-03   \n",
      "9     male           tau   6.269768  2.393950e-03         True  1.987673e-03   \n",
      "10    male           AUC   3.505178  3.238356e-02         True  2.962492e-02   \n",
      "11    male  reactionTime   6.049538  4.856904e-02         True  4.532128e-02   \n",
      "12    male      peakTime   7.310487  2.585519e-02         True  5.618624e-02   \n",
      "13    male    difference   1.652426  4.377036e-01        False           NaN   \n",
      "\n",
      "   posthoc_test    date1   date2  effect_strength  mean_diff  \n",
      "0     Tukey HSD  April16  June26        -2.279372  -0.307547  \n",
      "1     Tukey HSD  April16  June26        -2.328368  -0.369362  \n",
      "2          None     None    None              NaN        NaN  \n",
      "3     Tukey HSD  April16  June26        -2.638995  -0.438075  \n",
      "4          Dunn  April16  June26        -0.711248   1.430864  \n",
      "5          Dunn   June26   May20         0.230110  -0.607407  \n",
      "6          Dunn  April16  June26         0.585734  -2.019753  \n",
      "7     Tukey HSD  April16  June26        -0.865328  -0.207012  \n",
      "8     Tukey HSD  April16  June26        -0.599836  -0.155937  \n",
      "9     Tukey HSD  April16   May20         0.717412   0.184403  \n",
      "10    Tukey HSD  April16  June26        -0.497744  -0.132246  \n",
      "11         Dunn  April16   May20        -0.247942   0.219136  \n",
      "12         Dunn  April16  June26        -0.223594   0.979012  \n",
      "13         None     None    None              NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, f_oneway, kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "date_results = []\n",
    "\n",
    "for sex in df['sex'].unique():\n",
    "    df_sex = df[df['sex'] == sex]\n",
    "    for var in strength_metrics:\n",
    "        # Parametric ANOVA for strength metrics\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('date')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) > 1:\n",
    "            stat, p = f_oneway(*groups)\n",
    "            posthoc_p, posthoc_test, date1, date2, eff, mean_diff = None, None, None, None, None, None\n",
    "            if p < 0.05:\n",
    "                try:\n",
    "                    tukey = sp.posthoc_tukey_hsd(df_sex, val_col=var, group_col='date')\n",
    "                    min_p = tukey.replace(0, float('nan')).min().min()\n",
    "                    idx = tukey.stack().idxmin()\n",
    "                    date1, date2 = idx\n",
    "                    vals1 = df_sex[df_sex['date'] == date1][var].dropna()\n",
    "                    vals2 = df_sex[df_sex['date'] == date2][var].dropna()\n",
    "                    pooled_std = ((vals1.std(ddof=1) ** 2 + vals2.std(ddof=1) ** 2) / 2) ** 0.5\n",
    "                    eff = (vals1.mean() - vals2.mean()) / pooled_std if pooled_std > 0 else None\n",
    "                    mean_diff = vals1.mean() - vals2.mean()\n",
    "                    posthoc_p = min_p\n",
    "                    posthoc_test = \"Tukey HSD\"\n",
    "                except Exception:\n",
    "                    posthoc_p, posthoc_test, mean_diff = None, \"Tukey HSD\", None\n",
    "        else:\n",
    "            stat, p, posthoc_p, posthoc_test, date1, date2, eff, mean_diff = None, None, None, None, None, None, None, None\n",
    "        date_results.append({\n",
    "            'sex': sex,\n",
    "            'variable': var,\n",
    "            'stat': stat,\n",
    "            'p': p,\n",
    "            'significant': p is not None and p < 0.05,\n",
    "            'posthoc_p': posthoc_p,\n",
    "            'posthoc_test': posthoc_test,\n",
    "            'date1': date1,\n",
    "            'date2': date2,\n",
    "            'effect_strength': eff,\n",
    "            'mean_diff': mean_diff\n",
    "        })\n",
    "    for var in reaction_metrics:\n",
    "        # Non-parametric Kruskal-Wallis for reaction metrics\n",
    "        groups = [group[var].dropna().values for _, group in df_sex.groupby('date')]\n",
    "        groups = [g for g in groups if len(g) > 1]\n",
    "        if len(groups) > 1:\n",
    "            stat, p = kruskal(*groups)\n",
    "            posthoc_p, posthoc_test, date1, date2, eff, mean_diff = None, None, None, None, None, None\n",
    "            if p < 0.05:\n",
    "                try:\n",
    "                    dunn = sp.posthoc_dunn(df_sex, val_col=var, group_col='date', p_adjust='bonferroni')\n",
    "                    min_p = dunn.replace(0, float('nan')).min().min()\n",
    "                    idx = dunn.stack().idxmin()\n",
    "                    date1, date2 = idx\n",
    "                    vals1 = df_sex[df_sex['date'] == date1][var].dropna()\n",
    "                    vals2 = df_sex[df_sex['date'] == date2][var].dropna()\n",
    "                    u, _ = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "                    n1, n2 = len(vals1), len(vals2)\n",
    "                    eff = 1 - (2 * u) / (n1 * n2)\n",
    "                    mean_diff = vals1.mean() - vals2.mean()\n",
    "                    posthoc_p = min_p\n",
    "                    posthoc_test = \"Dunn\"\n",
    "                except Exception:\n",
    "                    posthoc_p, posthoc_test, mean_diff = None, \"Dunn\", None\n",
    "        else:\n",
    "            stat, p, posthoc_p, posthoc_test, date1, date2, eff, mean_diff = None, None, None, None, None, None, None, None\n",
    "        date_results.append({\n",
    "            'sex': sex,\n",
    "            'variable': var,\n",
    "            'stat': stat,\n",
    "            'p': p,\n",
    "            'significant': p is not None and p < 0.05,\n",
    "            'posthoc_p': posthoc_p,\n",
    "            'posthoc_test': posthoc_test,\n",
    "            'date1': date1,\n",
    "            'date2': date2,\n",
    "            'effect_strength': eff,\n",
    "            'mean_diff': mean_diff\n",
    "        })\n",
    "\n",
    "test_date = pd.DataFrame(date_results)\n",
    "print(test_date)\n",
    "\n",
    "test_date.to_excel(os.path.join(output_dir, \"TEST_DATE.xlsx\"), index=False)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f427808",
   "metadata": {},
   "source": [
    "## Date Effects on Metrics (Grouped by Sex)\n",
    "\n",
    "- **Females**\n",
    "  - Significant date effects for: `peakValue`, `RMS`, `AUC`, `reactionTime`, `peakTime`, `difference`\n",
    "  - Largest differences are between **April16** and **June26**\n",
    "  - Effect strengths are very large (e.g., peakValue: -2.28)\n",
    "  - `tau` is not significant\n",
    "\n",
    "- **Males**\n",
    "  - Significant date effects for: `peakValue`, `RMS`, `tau`, `AUC`, `reactionTime`, `peakTime`\n",
    "  - Most pronounced for `peakValue`, `RMS`, `tau`, `AUC` (April16 vs June26)\n",
    "  - Effect strengths are moderate to large (e.g., peakValue: -0.87)\n",
    "  - `difference` is not significant\n",
    "\n",
    "**Interpretation:**  \n",
    "- Date (batch/day) strongly impacts most metrics for both sexes.\n",
    "- Effect strengths are large, especially for strength metrics.\n",
    "- Always control for date in analysis; batch effects can overshadow experimental manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf00770",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5cfe6e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM p-values for strength metrics (predictors: experiment, sex, date):\n",
      "predictor  C(date)[T.June26]  C(date)[T.May20]  C(experiment)[T.gap_depth]  \\\n",
      "metric                                                                       \n",
      "AUC             9.352379e-18      7.317571e-06                    0.923026   \n",
      "RMS             3.523026e-18      4.026825e-09                    0.894243   \n",
      "peakValue       1.182816e-21      5.227890e-16                    0.880205   \n",
      "tau             5.429501e-02      1.102856e-04                    0.846302   \n",
      "\n",
      "predictor  C(experiment)[T.gap_duration_10]  C(experiment)[T.gap_duration_20]  \\\n",
      "metric                                                                          \n",
      "AUC                                0.732574                          0.826593   \n",
      "RMS                                0.519635                          0.565744   \n",
      "peakValue                          0.405871                          0.457347   \n",
      "tau                                0.783219                          0.513124   \n",
      "\n",
      "predictor  C(experiment)[T.gap_duration_4]  C(experiment)[T.gap_duration_50]  \\\n",
      "metric                                                                         \n",
      "AUC                               0.692902                          0.868628   \n",
      "RMS                               0.846716                          0.994056   \n",
      "peakValue                         0.818885                          0.884362   \n",
      "tau                               0.803103                          0.708032   \n",
      "\n",
      "predictor  C(experiment)[T.gap_duration_8]  C(experiment)[T.offset_PPI_10]  \\\n",
      "metric                                                                       \n",
      "AUC                               0.793417                        0.189096   \n",
      "RMS                               0.668252                        0.104438   \n",
      "peakValue                         0.622697                        0.098892   \n",
      "tau                               0.733983                        0.846334   \n",
      "\n",
      "predictor  C(experiment)[T.offset_PPI_12]  C(experiment)[T.offset_PPI_14]  \\\n",
      "metric                                                                      \n",
      "AUC                              0.235174                        0.234704   \n",
      "RMS                              0.121426                        0.156459   \n",
      "peakValue                        0.102548                        0.135446   \n",
      "tau                              0.731752                        0.799638   \n",
      "\n",
      "predictor  C(experiment)[T.offset_PPI_16]  C(experiment)[T.offset_PPI_18]  \\\n",
      "metric                                                                      \n",
      "AUC                              0.317879                        0.228261   \n",
      "RMS                              0.119801                        0.125320   \n",
      "peakValue                        0.095726                        0.107894   \n",
      "tau                              0.937977                        0.897945   \n",
      "\n",
      "predictor  C(experiment)[T.offset_PPI_20]  C(experiment)[T.offset_PPI_4]  \\\n",
      "metric                                                                     \n",
      "AUC                              0.281497                       0.220496   \n",
      "RMS                              0.125290                       0.095627   \n",
      "peakValue                        0.090236                       0.091365   \n",
      "tau                              0.434684                       0.949932   \n",
      "\n",
      "predictor  C(experiment)[T.offset_PPI_50]  C(experiment)[T.offset_PPI_6]  \\\n",
      "metric                                                                     \n",
      "AUC                              0.203479                       0.210523   \n",
      "RMS                              0.132906                       0.085095   \n",
      "peakValue                        0.194373                       0.079675   \n",
      "tau                              0.788847                       0.586574   \n",
      "\n",
      "predictor  C(experiment)[T.offset_PPI_8]  C(experiment)[T.tone_in_noise]  \\\n",
      "metric                                                                     \n",
      "AUC                             0.205490                        0.008834   \n",
      "RMS                             0.090286                        0.001115   \n",
      "peakValue                       0.071475                        0.000833   \n",
      "tau                             0.771570                        0.603607   \n",
      "\n",
      "predictor  C(sex)[T.male]     Intercept  \n",
      "metric                                   \n",
      "AUC          1.186293e-18  1.754659e-06  \n",
      "RMS          1.953991e-35  1.371159e-06  \n",
      "peakValue    1.247357e-54  6.418088e-06  \n",
      "tau          1.037370e-22  1.779137e-27  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "\n",
    "glm_results = []\n",
    "for metric in strength_metrics:\n",
    "    # Remove rows with missing values for predictors or metric\n",
    "    sub_df = df[['experiment', 'sex', 'date', metric]].dropna()\n",
    "    # Fit GLM (ordinary least squares) including date\n",
    "    model = smf.ols(f\"{metric} ~ C(experiment) + C(sex) + C(date)\", data=sub_df).fit()\n",
    "    # Collect p-values for predictors\n",
    "    for predictor, pval in model.pvalues.items():\n",
    "        glm_results.append({\n",
    "            \"metric\": metric,\n",
    "            \"predictor\": predictor,\n",
    "            \"p_value\": pval\n",
    "        })\n",
    "\n",
    "test_glm = pd.DataFrame(glm_results)\n",
    "test_glm_table = test_glm.pivot(index=\"metric\", columns=\"predictor\", values=\"p_value\")\n",
    "print(\"GLM p-values for strength metrics (predictors: experiment, sex, date):\")\n",
    "print(test_glm_table)\n",
    "\n",
    "# Save both the raw and pivoted results to files\n",
    "test_glm.to_excel(os.path.join(output_dir, \"TEST_GLM.xlsx\"), index=False)\n",
    "test_glm_table.to_excel(os.path.join(output_dir, \"TEST_GLM_TABLE.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435e8e2",
   "metadata": {},
   "source": [
    "## GLM Summary: Effects of Experiment, Sex, and Date\n",
    "\n",
    "- **Date effects:**  \n",
    "  - **AUC, RMS, peakValue:** Extremely strong date effects (June26, May20; p < 1e-5).\n",
    "  - **tau:** Moderate date effect (significant for May20, borderline for June26).\n",
    "\n",
    "- **Sex effects:**  \n",
    "  - **AUC, RMS, peakValue, tau:** All show highly significant sex differences (male vs. female; p < 1e-18).\n",
    "\n",
    "- **Experiment effects:**  \n",
    "  - **tone_in_noise:** Significant for AUC (p = 0.0088), RMS (p = 0.0011), peakValue (p = 0.00083).\n",
    "  - **Other experiments (gap durations, offset_PPI, etc.):** No significant effects (p > 0.05).\n",
    "\n",
    "**Summary:**  \n",
    "- The variables most affected are **AUC, RMS, peakValue** (by date, sex, and tone_in_noise experiment).\n",
    "- **tau** is mainly affected by sex and date.\n",
    "- Other experimental manipulations do **not** significantly alter strength metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "439a8bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date      variable         stat             p  significant  \\\n",
      "0   April16     peakValue    16.746598  1.037408e-25         True   \n",
      "1   April16           RMS    15.345657  1.345198e-23         True   \n",
      "2   April16           tau    -6.609417  3.943414e-09         True   \n",
      "3   April16           AUC    12.856188  5.834794e-20         True   \n",
      "4   April16  reactionTime   574.500000  4.731508e-08         True   \n",
      "5   April16      peakTime  1702.000000  1.222350e-01        False   \n",
      "6   April16    difference  2104.000000  6.944884e-05         True   \n",
      "7    June26     peakValue     7.270643  1.342305e-10         True   \n",
      "8    June26           RMS     4.571715  1.471229e-05         True   \n",
      "9    June26           tau    -6.935457  1.277682e-09         True   \n",
      "10   June26           AUC     2.071514  4.099126e-02         True   \n",
      "11   June26  reactionTime  1575.500000  4.525481e-01        False   \n",
      "12   June26      peakTime  1183.500000  8.026984e-02        False   \n",
      "13   June26    difference  1277.500000  2.659279e-01        False   \n",
      "14    May20     peakValue    12.779717  2.566306e-22         True   \n",
      "15    May20           RMS     8.413745  2.127741e-13         True   \n",
      "16    May20           tau    -5.985044  3.580442e-08         True   \n",
      "17    May20           AUC     4.741203  8.362908e-06         True   \n",
      "18    May20  reactionTime  1113.000000  3.027169e-02         True   \n",
      "19    May20      peakTime   916.500000  6.033294e-04         True   \n",
      "20    May20    difference  1190.000000  9.812993e-02        False   \n",
      "\n",
      "    effect_strength     posthoc_p posthoc_test  mean_diff          test  \\\n",
      "0          3.222884  4.884981e-14    Tukey HSD   0.435190        t-test   \n",
      "1          2.953273  4.884981e-14    Tukey HSD   0.446092        t-test   \n",
      "2         -1.271983  1.596929e-09    Tukey HSD  -0.194316        t-test   \n",
      "3          2.474174  4.884981e-14    Tukey HSD   0.411655        t-test   \n",
      "4          0.605967  4.649771e-08         Dunn  -1.046296  mannwhitneyu   \n",
      "5         -0.167353  1.214699e-01         Dunn   0.733951  mannwhitneyu   \n",
      "6         -0.443073  6.855449e-05         Dunn   1.780247  mannwhitneyu   \n",
      "7          1.399236  6.410894e-11    Tukey HSD   0.334656        t-test   \n",
      "8          0.879827  1.315534e-05    Tukey HSD   0.232667        t-test   \n",
      "9         -1.334729  3.313473e-10    Tukey HSD  -0.324576        t-test   \n",
      "10         0.398663  4.073852e-02    Tukey HSD   0.105826        t-test   \n",
      "11        -0.080590  4.506187e-01         Dunn   0.276543  mannwhitneyu   \n",
      "12         0.188272  7.971977e-02         Dunn  -0.833951  mannwhitneyu   \n",
      "13         0.123800  2.646022e-01         Dunn  -1.110494  mannwhitneyu   \n",
      "14         2.459458  4.884981e-14    Tukey HSD   0.405851        t-test   \n",
      "15         1.619226  2.515765e-13    Tukey HSD   0.306506        t-test   \n",
      "16        -1.151822  2.984541e-08    Tukey HSD  -0.313186        t-test   \n",
      "17         0.912445  6.647095e-06    Tukey HSD   0.202612        t-test   \n",
      "18         0.236626  3.003250e-02         Dunn  -0.418519  mannwhitneyu   \n",
      "19         0.371399  5.963184e-04         Dunn  -1.617901  mannwhitneyu   \n",
      "20         0.183813  9.750337e-02         Dunn  -1.199383  mannwhitneyu   \n",
      "\n",
      "      dunn_d  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4   0.605967  \n",
      "5  -0.167353  \n",
      "6  -0.443073  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n",
      "10       NaN  \n",
      "11 -0.080590  \n",
      "12  0.188272  \n",
      "13  0.123800  \n",
      "14       NaN  \n",
      "15       NaN  \n",
      "16       NaN  \n",
      "17       NaN  \n",
      "18  0.236626  \n",
      "19  0.371399  \n",
      "20  0.183813  \n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "sex_diff_results = []\n",
    "\n",
    "for date in df['date'].unique():\n",
    "    df_date = df[df['date'] == date]\n",
    "    for var in strength_metrics:\n",
    "        vals_male = df_date[df_date['sex'] == 'male'][var].dropna()\n",
    "        vals_female = df_date[df_date['sex'] == 'female'][var].dropna()\n",
    "        mean_diff = vals_male.mean() - vals_female.mean() if len(vals_male) > 0 and len(vals_female) > 0 else None\n",
    "        if len(vals_male) > 1 and len(vals_female) > 1:\n",
    "            stat, p = ttest_ind(vals_male, vals_female, equal_var=False)\n",
    "            pooled_std = ((vals_male.std(ddof=1) ** 2 + vals_female.std(ddof=1) ** 2) / 2) ** 0.5\n",
    "            eff = mean_diff / pooled_std if pooled_std > 0 else None\n",
    "            # Tukey HSD posthoc\n",
    "            try:\n",
    "                from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "                combined = pd.concat([vals_male, vals_female])\n",
    "                group = ['male'] * len(vals_male) + ['female'] * len(vals_female)\n",
    "                tukey = pairwise_tukeyhsd(combined, group)\n",
    "                posthoc_p = tukey.pvalues[0] if len(tukey.pvalues) > 0 else None\n",
    "                posthoc_test = \"Tukey HSD\"\n",
    "            except Exception:\n",
    "                posthoc_p = None\n",
    "                posthoc_test = \"Tukey HSD\"\n",
    "        else:\n",
    "            stat, p, eff, posthoc_p, posthoc_test = None, None, None, None, None\n",
    "        sex_diff_results.append({\n",
    "            'date': date,\n",
    "            'variable': var,\n",
    "            'stat': stat,\n",
    "            'p': p,\n",
    "            'significant': p is not None and p < 0.05,\n",
    "            'effect_strength': eff,\n",
    "            'posthoc_p': posthoc_p,\n",
    "            'posthoc_test': posthoc_test,\n",
    "            'mean_diff': mean_diff,\n",
    "            'test': 't-test'\n",
    "        })\n",
    "    for var in reaction_metrics:\n",
    "        vals_male = df_date[df_date['sex'] == 'male'][var].dropna()\n",
    "        vals_female = df_date[df_date['sex'] == 'female'][var].dropna()\n",
    "        mean_diff = vals_male.mean() - vals_female.mean() if len(vals_male) > 0 and len(vals_female) > 0 else None\n",
    "        if len(vals_male) > 1 and len(vals_female) > 1:\n",
    "            stat, p = mannwhitneyu(vals_male, vals_female, alternative='two-sided')\n",
    "            n1, n2 = len(vals_male), len(vals_female)\n",
    "            u, _ = mannwhitneyu(vals_male, vals_female, alternative='two-sided')\n",
    "            eff = 1 - (2 * u) / (n1 * n2)\n",
    "            # Dunn's posthoc\n",
    "            try:\n",
    "                data = pd.DataFrame({var: pd.concat([vals_male, vals_female]),\n",
    "                                    'group': ['male'] * len(vals_male) + ['female'] * len(vals_female)})\n",
    "                dunn = sp.posthoc_dunn(data, val_col=var, group_col='group', p_adjust='bonferroni')\n",
    "                posthoc_p = dunn.loc['male', 'female']\n",
    "                posthoc_test = \"Dunn\"\n",
    "                # Calculate Dunn's d (rank-biserial for posthoc)\n",
    "                vals1 = data[data['group'] == 'male'][var].dropna()\n",
    "                vals2 = data[data['group'] == 'female'][var].dropna()\n",
    "                if len(vals1) > 1 and len(vals2) > 1:\n",
    "                    u_post, _ = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "                    n1_post, n2_post = len(vals1), len(vals2)\n",
    "                    dunn_d = 1 - (2 * u_post) / (n1_post * n2_post)\n",
    "                else:\n",
    "                    dunn_d = None\n",
    "            except Exception:\n",
    "                posthoc_p = None\n",
    "                posthoc_test = \"Dunn\"\n",
    "                dunn_d = None\n",
    "        else:\n",
    "            stat, p, eff, posthoc_p, posthoc_test, dunn_d = None, None, None, None, None, None\n",
    "        sex_diff_results.append({\n",
    "            'date': date,\n",
    "            'variable': var,\n",
    "            'stat': stat,\n",
    "            'p': p,\n",
    "            'significant': p is not None and p < 0.05,\n",
    "            'effect_strength': eff,\n",
    "            'posthoc_p': posthoc_p,\n",
    "            'posthoc_test': posthoc_test,\n",
    "            'dunn_d': dunn_d,\n",
    "            'mean_diff': mean_diff,\n",
    "            'test': 'mannwhitneyu'\n",
    "        })\n",
    "\n",
    "test_sex = pd.DataFrame(sex_diff_results)\n",
    "print(test_sex)\n",
    "\n",
    "test_sex.to_excel(os.path.join(output_dir, \"TEST_SEX.xlsx\"), index=False)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcb9c0",
   "metadata": {},
   "source": [
    "### Summary of Sex Differences by Date\n",
    "\n",
    "- **Strength metrics** (peakValue, RMS, tau, AUC) show **large and highly significant sex differences** across all dates, with males generally having higher values except for tau (where males are lower).\n",
    "- **Effect strengths** for strength metrics are very large (often >1), indicating robust differences.\n",
    "- **Reaction metrics** (reactionTime, peakTime, difference) show **smaller and less consistent sex differences**. Some are significant (e.g., reactionTime and difference on April16, reactionTime and peakTime on May20), but most are not, especially on June26.\n",
    "- **Post hoc tests** (Tukey HSD for strength metrics, Dunn's for reaction metrics) confirm the primary results and provide adjusted p-values.\n",
    "- **Interpretation:** Sex differences are strong for strength metrics and moderate or absent for reaction metrics. The magnitude and significance of these differences can vary by date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6669d62",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a70e6",
   "metadata": {},
   "source": [
    "## Recording Order Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f0ec82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sex     date        metric          test        stat             p  \\\n",
      "0   female  April16     peakValue        t-test   -1.420735  1.617757e-01   \n",
      "1   female  April16           RMS        t-test   -2.561296  1.429029e-02   \n",
      "2   female  April16           tau        t-test   -2.920564  5.344195e-03   \n",
      "3   female  April16           AUC        t-test   -3.382671  1.812942e-03   \n",
      "4   female  April16  reactionTime  mannwhitneyu  469.000000  7.113408e-03   \n",
      "5   female  April16      peakTime  mannwhitneyu  103.500000  1.624793e-05   \n",
      "6   female  April16    difference  mannwhitneyu   94.000000  2.060878e-05   \n",
      "7   female   June26     peakValue        t-test   -2.040056  4.700479e-02   \n",
      "8   female   June26           RMS        t-test   -2.602420  1.231007e-02   \n",
      "9   female   June26           tau        t-test   -7.012162  4.782149e-09   \n",
      "10  female   June26           AUC        t-test   -3.727794  5.218556e-04   \n",
      "11  female   June26  reactionTime  mannwhitneyu  479.500000  3.827184e-03   \n",
      "12  female   June26      peakTime  mannwhitneyu  364.500000  4.186367e-01   \n",
      "13  female   June26    difference  mannwhitneyu  236.000000  1.066708e-01   \n",
      "14  female    May20     peakValue        t-test   -0.697978  4.884945e-01   \n",
      "15  female    May20           RMS        t-test   -1.312535  1.969100e-01   \n",
      "16  female    May20           tau        t-test    0.797570  4.288557e-01   \n",
      "17  female    May20           AUC        t-test   -1.915106  6.503972e-02   \n",
      "18  female    May20  reactionTime  mannwhitneyu  368.000000  4.206524e-01   \n",
      "19  female    May20      peakTime  mannwhitneyu  206.500000  2.659018e-02   \n",
      "20  female    May20    difference  mannwhitneyu  217.500000  5.013355e-02   \n",
      "21    male  April16     peakValue        t-test    4.672102  3.440385e-05   \n",
      "22    male  April16           RMS        t-test    6.213061  1.988015e-07   \n",
      "23    male  April16           tau        t-test    5.922219  3.404626e-07   \n",
      "24    male  April16           AUC        t-test    9.195431  3.938399e-12   \n",
      "25    male  April16  reactionTime  mannwhitneyu  346.000000  6.879486e-01   \n",
      "26    male  April16      peakTime  mannwhitneyu  400.500000  1.573995e-01   \n",
      "27    male  April16    difference  mannwhitneyu  344.000000  7.198789e-01   \n",
      "28    male   June26     peakValue        t-test   22.836436  3.830204e-15   \n",
      "29    male   June26           RMS        t-test   23.891858  5.998010e-19   \n",
      "30    male   June26           tau        t-test    0.507892  6.136870e-01   \n",
      "31    male   June26           AUC        t-test   17.729142  3.780902e-20   \n",
      "32    male   June26  reactionTime  mannwhitneyu   46.000000  2.116930e-08   \n",
      "33    male   June26      peakTime  mannwhitneyu  610.000000  1.172429e-07   \n",
      "34    male   June26    difference  mannwhitneyu  604.500000  2.263897e-07   \n",
      "35    male    May20     peakValue        t-test    1.120333  2.684480e-01   \n",
      "36    male    May20           RMS        t-test    6.407689  4.505653e-08   \n",
      "37    male    May20           tau        t-test    8.073242  4.850712e-10   \n",
      "38    male    May20           AUC        t-test    8.986888  4.886684e-12   \n",
      "39    male    May20  reactionTime  mannwhitneyu  388.500000  2.157245e-01   \n",
      "40    male    May20      peakTime  mannwhitneyu  417.500000  7.830439e-02   \n",
      "41    male    May20    difference  mannwhitneyu  386.500000  2.524303e-01   \n",
      "\n",
      "    effect_strength     posthoc_p posthoc_test  significant  mean_diff  \n",
      "0         -0.380465  2.235651e-01    Tukey HSD        False  -0.023551  \n",
      "1         -0.716959  1.952593e-02    Tukey HSD         True  -0.048799  \n",
      "2         -0.788799  1.303706e-02    Tukey HSD         True  -0.070757  \n",
      "3         -0.976121  1.381354e-03    Tukey HSD         True  -0.076261  \n",
      "4         -0.447531  6.917272e-03         Dunn         True   0.441667  \n",
      "5          0.680556  1.554291e-05         Dunn         True  -0.597222  \n",
      "6          0.709877  1.977040e-05         Dunn         True  -1.038889  \n",
      "7         -0.552015  7.733851e-02    Tukey HSD         True  -0.091117  \n",
      "8         -0.701630  2.650051e-02    Tukey HSD         True  -0.134546  \n",
      "9         -1.818874  4.735338e-07    Tukey HSD         True  -0.187518  \n",
      "10        -1.009914  1.750203e-03    Tukey HSD         True  -0.191206  \n",
      "11        -0.479938  3.715058e-03         Dunn         True   1.023148  \n",
      "12        -0.125000  4.128442e-01         Dunn        False   1.002778  \n",
      "13         0.271605  1.046838e-01         Dunn        False  -0.020370  \n",
      "14        -0.186534  5.491509e-01    Tukey HSD        False  -0.033549  \n",
      "15        -0.368507  2.197576e-01    Tukey HSD        False  -0.064452  \n",
      "16         0.200718  5.365970e-01    Tukey HSD        False   0.041329  \n",
      "17        -0.565976  4.947419e-02    Tukey HSD        False  -0.090051  \n",
      "18        -0.135802  4.153322e-01         Dunn        False   0.601852  \n",
      "19         0.362654  2.595006e-02         Dunn         True  -0.272222  \n",
      "20         0.328704  4.906085e-02         Dunn        False  -0.874074  \n",
      "21         1.312628  4.921318e-05    Tukey HSD         True   0.196815  \n",
      "22         1.724621  4.708978e-07    Tukey HSD         True   0.263006  \n",
      "23         1.596442  3.460275e-06    Tukey HSD         True   0.235115  \n",
      "24         2.477168  1.031475e-10    Tukey HSD         True   0.343301  \n",
      "25        -0.067901  6.810865e-01         Dunn        False   0.238889  \n",
      "26        -0.236111  1.546858e-01         Dunn        False   0.364815  \n",
      "27        -0.061728  7.130104e-01         Dunn        False   0.125926  \n",
      "28         7.434396  0.000000e+00    Tukey HSD         True   0.587065  \n",
      "29         7.288961  0.000000e+00    Tukey HSD         True   0.625391  \n",
      "30         0.129648  6.867448e-01    Tukey HSD        False   0.036902  \n",
      "31         5.000274  0.000000e+00    Tukey HSD         True   0.590028  \n",
      "32         0.858025  1.997042e-08         Dunn         True  -1.220370  \n",
      "33        -0.882716  1.114314e-07         Dunn         True   5.812963  \n",
      "34        -0.865741  2.154435e-07         Dunn         True   7.033333  \n",
      "35         0.305311  3.207410e-01    Tukey HSD        False   0.038563  \n",
      "36         1.673962  2.225227e-06    Tukey HSD         True   0.246473  \n",
      "37         1.947439  2.906487e-07    Tukey HSD         True   0.410728  \n",
      "38         2.258436  5.070133e-09    Tukey HSD         True   0.395801  \n",
      "39        -0.199074  2.121596e-01         Dunn        False   0.460185  \n",
      "40        -0.288580  7.671450e-02         Dunn        False   1.364815  \n",
      "41        -0.192901  2.486249e-01         Dunn        False   0.904630  \n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "recording_order = [15, 2, 1, 6, 10, 4]\n",
    "order_map = {f'Animal{num}': i+1 for i, num in enumerate(recording_order)}\n",
    "\n",
    "results = []\n",
    "\n",
    "for sex in df['sex'].unique():\n",
    "    for date in df['date'].unique():\n",
    "        df_sub = df[(df['sex'] == sex) & (df['date'] == date)].copy()\n",
    "        df_sub['recording_order'] = df_sub['animal'].map(order_map)\n",
    "        df_sub = df_sub[df_sub['recording_order'].notnull()]\n",
    "        median_order = df_sub['recording_order'].median()\n",
    "        df_sub['group'] = ['early' if o <= median_order else 'late' for o in df_sub['recording_order']]\n",
    "        for metric in strength_metrics:\n",
    "            vals_early = df_sub[df_sub['group'] == 'early'][metric].dropna()\n",
    "            vals_late = df_sub[df_sub['group'] == 'late'][metric].dropna()\n",
    "            mean_diff = vals_early.mean() - vals_late.mean() if len(vals_early) > 0 and len(vals_late) > 0 else None\n",
    "            if len(vals_early) > 1 and len(vals_late) > 1:\n",
    "                # Parametric t-test\n",
    "                stat, p = ttest_ind(vals_early, vals_late, equal_var=False)\n",
    "                # Effect strength (Cohen's d)\n",
    "                pooled_std = ((vals_early.std(ddof=1) ** 2 + vals_late.std(ddof=1) ** 2) / 2) ** 0.5\n",
    "                effect_strength = mean_diff / pooled_std if pooled_std > 0 else None\n",
    "                # Post hoc: Tukey HSD\n",
    "                try:\n",
    "                    combined = pd.concat([vals_early, vals_late])\n",
    "                    group = ['early'] * len(vals_early) + ['late'] * len(vals_late)\n",
    "                    tukey = sp.posthoc_tukey_hsd(pd.DataFrame({metric: combined, 'group': group}), val_col=metric, group_col='group')\n",
    "                    posthoc_p = tukey.loc['early', 'late']\n",
    "                except Exception:\n",
    "                    posthoc_p = None\n",
    "                results.append({\n",
    "                    'sex': sex,\n",
    "                    'date': date,\n",
    "                    'metric': metric,\n",
    "                    'test': 't-test',\n",
    "                    'stat': stat,\n",
    "                    'p': p,\n",
    "                    'effect_strength': effect_strength,\n",
    "                    'posthoc_p': posthoc_p,\n",
    "                    'posthoc_test': 'Tukey HSD',\n",
    "                    'significant': p < 0.05,\n",
    "                    'mean_diff': mean_diff\n",
    "                })\n",
    "        for metric in reaction_metrics:\n",
    "            vals_early = df_sub[df_sub['group'] == 'early'][metric].dropna()\n",
    "            vals_late = df_sub[df_sub['group'] == 'late'][metric].dropna()\n",
    "            mean_diff = vals_early.mean() - vals_late.mean() if len(vals_early) > 0 and len(vals_late) > 0 else None\n",
    "            if len(vals_early) > 1 and len(vals_late) > 1:\n",
    "                # Non-parametric Mann-Whitney U\n",
    "                stat, p = mannwhitneyu(vals_early, vals_late, alternative='two-sided')\n",
    "                n1, n2 = len(vals_early), len(vals_late)\n",
    "                u, _ = mannwhitneyu(vals_early, vals_late, alternative='two-sided')\n",
    "                effect_strength = 1 - (2 * u) / (n1 * n2)\n",
    "                # Post hoc: Dunn's test\n",
    "                try:\n",
    "                    data = pd.DataFrame({metric: pd.concat([vals_early, vals_late]),\n",
    "                                        'group': ['early'] * len(vals_early) + ['late'] * len(vals_late)})\n",
    "                    dunn = sp.posthoc_dunn(data, val_col=metric, group_col='group', p_adjust='bonferroni')\n",
    "                    posthoc_p = dunn.loc['early', 'late']\n",
    "                except Exception:\n",
    "                    posthoc_p = None\n",
    "                results.append({\n",
    "                    'sex': sex,\n",
    "                    'date': date,\n",
    "                    'metric': metric,\n",
    "                    'test': 'mannwhitneyu',\n",
    "                    'stat': stat,\n",
    "                    'p': p,\n",
    "                    'effect_strength': effect_strength,\n",
    "                    'posthoc_p': posthoc_p,\n",
    "                    'posthoc_test': 'Dunn',\n",
    "                    'significant': p < 0.05,\n",
    "                    'mean_diff': mean_diff\n",
    "                })\n",
    "\n",
    "test_rec_order = pd.DataFrame(results)\n",
    "print(test_rec_order)\n",
    "\n",
    "test_rec_order.to_excel(os.path.join(output_dir, \"TEST_REC_ORDER.xlsx\"), index=False)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20391e",
   "metadata": {},
   "source": [
    "## Summary: Does Recording Order Impact Metrics? (Grouped by Date & Sex)\n",
    "\n",
    "### **Strength Metrics (Parametric t-test, Cohen's d, Tukey HSD post hoc)**\n",
    "- **Significant effects of recording order** (p < 0.05, Tukey HSD post hoc also significant) are seen for:\n",
    "    - **Females:** RMS, tau, AUC (April16 & June26); peakValue (June26)\n",
    "    - **Males:** peakValue, RMS, tau, AUC (April16, June26, May20)\n",
    "- **Effect strengths (Cohen's d)** are moderate to very large (e.g., RMS: 1.7, AUC: 2.5, tau: 1.9, peakValue: 1.37.4).\n",
    "- **Interpretation:** Recording order can strongly impact strength metrics, especially in males and on June26.\n",
    "\n",
    "### **Reaction Metrics (Mann-Whitney U, Rank-biserial, Dunn post hoc)**\n",
    "- **Significant effects** for:\n",
    "    - **Females:** reactionTime, peakTime, difference (April16 & June26)\n",
    "    - **Males:** reactionTime, peakTime, difference (June26)\n",
    "- **Effect strengths** (rank-biserial) are moderate to large (e.g., peakTime/difference: ~0.70.8).\n",
    "- **Interpretation:** Recording order also impacts reaction metrics, but effects are less consistent than for strength metrics.\n",
    "\n",
    "### **General Notes**\n",
    "- **Post hoc tests** (Tukey HSD for strength, Dunn for reaction) confirm most significant findings.\n",
    "- **Effect strengths** are often large, indicating robust differences between early and late recordings.\n",
    "- **Some metrics/dates/sexes show no significant effect** (e.g., May20/female, tau in male/June26).\n",
    "\n",
    "\n",
    "**Conclusion:**  \n",
    "Recording order can significantly affect both strength and reaction metrics, with large effect sizes and consistent post hoc support, especially in males and on certain dates. Always control for recording order in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a92171b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sex     date        metric  mean_early  mean_late     direction  \\\n",
      "0   female  April16     peakValue    0.110367   0.133918  late > early   \n",
      "1   female  April16           RMS    0.106122   0.154921  late > early   \n",
      "2   female  April16           tau    0.664748   0.735505  late > early   \n",
      "3   female  April16           AUC    0.110491   0.186752  late > early   \n",
      "4   female  April16  reactionTime   11.719444  11.277778  early > late   \n",
      "5   female  April16      peakTime   30.058333  30.655556  late > early   \n",
      "6   female  April16    difference   18.338889  19.377778  late > early   \n",
      "7   female   June26     peakValue    0.395391   0.486508  late > early   \n",
      "8   female   June26           RMS    0.446902   0.581448  late > early   \n",
      "9   female   June26           tau    0.629340   0.816857  late > early   \n",
      "10  female   June26           AUC    0.510251   0.701457  late > early   \n",
      "11  female   June26  reactionTime   10.482407   9.459259  early > late   \n",
      "12  female   June26      peakTime   31.180556  30.177778  early > late   \n",
      "13  female   June26    difference   20.698148  20.718519  late > early   \n",
      "14  female    May20     peakValue    0.335091   0.368640  late > early   \n",
      "15  female    May20           RMS    0.342353   0.406805  late > early   \n",
      "16  female    May20           tau    0.636577   0.595247  early > late   \n",
      "17  female    May20           AUC    0.352813   0.442864  late > early   \n",
      "18  female    May20  reactionTime   10.925926  10.324074  early > late   \n",
      "19  female    May20      peakTime   31.362963  31.635185  late > early   \n",
      "20  female    May20    difference   20.437037  21.311111  late > early   \n",
      "21    male  April16     peakValue    0.619012   0.422197  early > late   \n",
      "22    male  April16           RMS    0.656149   0.393143  early > late   \n",
      "23    male  April16           tau    0.572389   0.337274  early > late   \n",
      "24    male  April16           AUC    0.662000   0.318700  early > late   \n",
      "25    male  April16  reactionTime   10.605556  10.366667  early > late   \n",
      "26    male  April16      peakTime   31.112963  30.748148  early > late   \n",
      "27    male  April16    difference   20.507407  20.381481  early > late   \n",
      "28    male   June26     peakValue    0.956107   0.369043  early > late   \n",
      "29    male   June26           RMS    0.932881   0.307490  early > late   \n",
      "30    male   June26           tau    0.379570   0.342668  early > late   \n",
      "31    male   June26           AUC    0.876489   0.286461  early > late   \n",
      "32    male   June26  reactionTime   10.011111  11.231481  late > early   \n",
      "33    male   June26      peakTime   31.950000  26.137037  early > late   \n",
      "34    male   June26    difference   21.938889  14.905556  early > late   \n",
      "35    male    May20     peakValue    0.764979   0.726416  early > late   \n",
      "36    male    May20           RMS    0.752501   0.506028  early > late   \n",
      "37    male    May20           tau    0.446523   0.035796  early > late   \n",
      "38    male    May20           AUC    0.717376   0.321575  early > late   \n",
      "39    male    May20  reactionTime   10.460185  10.000000  early > late   \n",
      "40    male    May20      peakTime   30.290741  28.925926  early > late   \n",
      "41    male    May20    difference   19.830556  18.925926  early > late   \n",
      "\n",
      "        diff  \n",
      "0  -0.023551  \n",
      "1  -0.048799  \n",
      "2  -0.070757  \n",
      "3  -0.076261  \n",
      "4   0.441667  \n",
      "5  -0.597222  \n",
      "6  -1.038889  \n",
      "7  -0.091117  \n",
      "8  -0.134546  \n",
      "9  -0.187518  \n",
      "10 -0.191206  \n",
      "11  1.023148  \n",
      "12  1.002778  \n",
      "13 -0.020370  \n",
      "14 -0.033549  \n",
      "15 -0.064452  \n",
      "16  0.041329  \n",
      "17 -0.090051  \n",
      "18  0.601852  \n",
      "19 -0.272222  \n",
      "20 -0.874074  \n",
      "21  0.196815  \n",
      "22  0.263006  \n",
      "23  0.235115  \n",
      "24  0.343301  \n",
      "25  0.238889  \n",
      "26  0.364815  \n",
      "27  0.125926  \n",
      "28  0.587065  \n",
      "29  0.625391  \n",
      "30  0.036902  \n",
      "31  0.590028  \n",
      "32 -1.220370  \n",
      "33  5.812963  \n",
      "34  7.033333  \n",
      "35  0.038563  \n",
      "36  0.246473  \n",
      "37  0.410728  \n",
      "38  0.395801  \n",
      "39  0.460185  \n",
      "40  1.364815  \n",
      "41  0.904630  \n"
     ]
    }
   ],
   "source": [
    "# Show direction of recording order effect for significant results\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "recording_order = [15, 2, 1, 6, 10, 4]\n",
    "order_map = {f'Animal{num}': i+1 for i, num in enumerate(recording_order)}\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for sex in df['sex'].unique():\n",
    "    for date in df['date'].unique():\n",
    "        df_sub = df[(df['sex'] == sex) & (df['date'] == date)].copy()\n",
    "        df_sub['recording_order'] = df_sub['animal'].map(order_map)\n",
    "        df_sub = df_sub[df_sub['recording_order'].notnull()]\n",
    "        median_order = df_sub['recording_order'].median()\n",
    "        df_sub['group'] = ['early' if o <= median_order else 'late' for o in df_sub['recording_order']]\n",
    "        for metric in strength_metrics + reaction_metrics:\n",
    "            vals_early = df_sub[df_sub['group'] == 'early'][metric].dropna()\n",
    "            vals_late = df_sub[df_sub['group'] == 'late'][metric].dropna()\n",
    "            if len(vals_early) > 1 and len(vals_late) > 1:\n",
    "                mean_early = vals_early.mean()\n",
    "                mean_late = vals_late.mean()\n",
    "                direction = \"early > late\" if mean_early > mean_late else \"late > early\"\n",
    "                summary_rows.append({\n",
    "                    'sex': sex,\n",
    "                    'date': date,\n",
    "                    'metric': metric,\n",
    "                    'mean_early': mean_early,\n",
    "                    'mean_late': mean_late,\n",
    "                    'direction': direction,\n",
    "                    'diff': mean_early - mean_late\n",
    "                })\n",
    "\n",
    "test_rec_order_direction = pd.DataFrame(summary_rows)\n",
    "print(test_rec_order_direction)\n",
    "\n",
    "test_rec_order_direction.to_excel(os.path.join(output_dir, \"TEST_REC_ORDER_DIRECTION.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad9c11",
   "metadata": {},
   "source": [
    "## Summary: Direction of Recording Order Effects\n",
    "\n",
    "- **Females:**  \n",
    "  - For all dates, strength metrics (`peakValue`, `RMS`, `tau`, `AUC`) are **higher in late recordings** (`late > early`).\n",
    "  - Reaction metrics (`reactionTime`, `peakTime`, `difference`) are mostly **higher in late recordings**, except `reactionTime` (which is higher in early recordings).\n",
    "  - The effect is consistent: **late recordings tend to have higher values** for most metrics.\n",
    "\n",
    "- **Males:**  \n",
    "  - For all dates and all metrics, **early recordings have higher values** (`early > late`), except for `reactionTime` on June26 (where late is higher).\n",
    "  - The effect is strong and consistent: **early recordings show higher strength and reaction metrics**.\n",
    "\n",
    "- **Magnitude:**  \n",
    "  - The difference (`diff`) between early and late groups is often substantial, especially for males (e.g., peakValue, RMS, AUC, difference).\n",
    "\n",
    "**Interpretation:**  \n",
    "- **Recording order has a clear directional effect:**  \n",
    "  - **Females:** Metrics increase with recording order (late > early).\n",
    "  - **Males:** Metrics decrease with recording order (early > late).\n",
    "- **This effect is robust across dates and metrics.**\n",
    "- **Always control for recording order in analysis, as it can confound experimental results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63320467",
   "metadata": {},
   "source": [
    "### ---> peakTime higher and reactionTime lower with less strength?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3aeec27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between strength metrics and peakTime/reactionTime:\n",
      "  strength_metric reaction_metric  pearson_r     pearson_p  spearman_r  \\\n",
      "0       peakValue        peakTime   0.087235  1.170776e-01    0.025790   \n",
      "1       peakValue    reactionTime  -0.400215  6.811440e-14   -0.536682   \n",
      "2             RMS        peakTime   0.149436  7.047380e-03    0.077919   \n",
      "3             RMS    reactionTime  -0.403854  3.849695e-14   -0.538670   \n",
      "4             tau        peakTime   0.181496  1.032215e-03    0.160016   \n",
      "5             tau    reactionTime   0.117104  3.511889e-02    0.136935   \n",
      "6             AUC        peakTime   0.153613  5.591734e-03    0.081657   \n",
      "7             AUC    reactionTime  -0.385134  6.737467e-13   -0.505347   \n",
      "\n",
      "     spearman_p    n  mean_diff  \n",
      "0  6.437244e-01  324 -30.073451  \n",
      "1  1.449731e-25  324 -10.122217  \n",
      "2  1.617386e-01  324 -30.075950  \n",
      "3  8.901558e-26  324 -10.124715  \n",
      "4  3.879662e-03  324 -30.037172  \n",
      "5  1.362777e-02  324 -10.085938  \n",
      "6  1.424866e-01  324 -30.081894  \n",
      "7  2.099658e-22  324 -10.130659  \n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['peakTime', 'reactionTime']\n",
    "\n",
    "correlation_results = []\n",
    "\n",
    "for metric in strength_metrics:\n",
    "    for reaction_var in reaction_metrics:\n",
    "        x = df[metric].dropna()\n",
    "        y = df[reaction_var].dropna()\n",
    "        # Align indices to avoid mismatches\n",
    "        common_idx = x.index.intersection(y.index)\n",
    "        x_aligned = x.loc[common_idx]\n",
    "        y_aligned = y.loc[common_idx]\n",
    "        if len(x_aligned) > 2:\n",
    "            # Pearson correlation\n",
    "            pearson_r, pearson_p = pearsonr(x_aligned, y_aligned)\n",
    "            # Spearman correlation\n",
    "            spearman_r, spearman_p = spearmanr(x_aligned, y_aligned)\n",
    "            mean_diff = x_aligned.mean() - y_aligned.mean()\n",
    "            correlation_results.append({\n",
    "                'strength_metric': metric,\n",
    "                'reaction_metric': reaction_var,\n",
    "                'pearson_r': pearson_r,\n",
    "                'pearson_p': pearson_p,\n",
    "                'spearman_r': spearman_r,\n",
    "                'spearman_p': spearman_p,\n",
    "                'n': len(x_aligned),\n",
    "                'mean_diff': mean_diff\n",
    "            })\n",
    "\n",
    "test_peakTime_reactionTime_to_strength_cor = pd.DataFrame(correlation_results)\n",
    "print(\"Correlation between strength metrics and peakTime/reactionTime:\")\n",
    "print(test_peakTime_reactionTime_to_strength_cor)\n",
    "\n",
    "test_peakTime_reactionTime_to_strength_cor.to_excel(os.path.join(output_dir, \"TEST_PEAKTIME_REACTIONTIME_TO_STRENGTH.xlsx\"), index=False)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd7085",
   "metadata": {},
   "source": [
    "### Correlation between Strength Metrics and PeakTime/ReactionTime\n",
    "\n",
    "| Strength Metric | Reaction Metric | Pearson r | Pearson p | Spearman r | Spearman p |   n   |\n",
    "|-----------------|----------------|-----------|-----------|------------|------------|-------|\n",
    "| peakValue       | peakTime       |  0.087    |  0.117    |   0.026    |   0.644    |  324  |\n",
    "| peakValue       | reactionTime   | -0.400    | 6.8e-14   |  -0.537    | 1.4e-25    |  324  |\n",
    "| RMS             | peakTime       |  0.149    | 0.007     |   0.078    |  0.162     |  324  |\n",
    "| RMS             | reactionTime   | -0.404    | 3.8e-14   |  -0.539    | 8.9e-26    |  324  |\n",
    "| tau             | peakTime       |  0.181    | 0.001     |   0.160    |  0.004     |  324  |\n",
    "| tau             | reactionTime   |  0.117    | 0.035     |   0.137    |  0.014     |  324  |\n",
    "| AUC             | peakTime       |  0.154    | 0.006     |   0.082    |  0.143     |  324  |\n",
    "| AUC             | reactionTime   | -0.385    | 6.7e-13   |  -0.505    | 2.1e-22    |  324  |\n",
    "\n",
    "**Interpretation:**\n",
    "- **PeakTime:** Weak positive correlations with all strength metrics; only tau is significant for Spearman (p = 0.004).\n",
    "- **ReactionTime:** Moderate negative correlations with peakValue, RMS, and AUC (Pearson r  -0.4, Spearman r  -0.5, p < 1e-12), indicating higher strength is associated with shorter reaction time.\n",
    "- **tau:** Shows weak positive correlation with reactionTime (Pearson r = 0.12, Spearman r = 0.14, p < 0.05).\n",
    "- **Summary:** ReactionTime is more strongly and consistently (negatively) correlated with strength metrics than peakTime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0aeb2",
   "metadata": {},
   "source": [
    "### ---> despite being correlated negatively with strength, reactionTime still goes down over the course of a day when strength also decreases down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64d0e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebb7c9",
   "metadata": {},
   "source": [
    "## Experiment Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4fde521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment effects on metrics (parametric for strength, non-parametric for reaction metrics):\n",
      "       sex     date        metric            test       stat         p  \\\n",
      "0   female  April16     peakValue           ANOVA   0.980462  0.498748   \n",
      "1   female  April16           RMS           ANOVA   1.164230  0.339109   \n",
      "2   female  April16           tau           ANOVA   0.577098  0.886888   \n",
      "3   female  April16           AUC           ANOVA   1.098563  0.391711   \n",
      "4   female  April16  reactionTime  Kruskal-Wallis  20.457419  0.251504   \n",
      "5   female  April16      peakTime  Kruskal-Wallis   9.130543  0.936077   \n",
      "6   female  April16    difference  Kruskal-Wallis  11.613911  0.822932   \n",
      "7   female   June26     peakValue           ANOVA   0.784332  0.698134   \n",
      "8   female   June26           RMS           ANOVA   0.721425  0.761322   \n",
      "9   female   June26           tau           ANOVA   0.343029  0.989380   \n",
      "10  female   June26           AUC           ANOVA   0.632730  0.842861   \n",
      "11  female   June26  reactionTime  Kruskal-Wallis   9.902469  0.907650   \n",
      "12  female   June26      peakTime  Kruskal-Wallis  13.543954  0.699079   \n",
      "13  female   June26    difference  Kruskal-Wallis  16.359838  0.498484   \n",
      "14  female    May20     peakValue           ANOVA   0.288886  0.995885   \n",
      "15  female    May20           RMS           ANOVA   0.588117  0.878696   \n",
      "16  female    May20           tau           ANOVA   0.096859  0.999997   \n",
      "17  female    May20           AUC           ANOVA   1.152710  0.347954   \n",
      "18  female    May20  reactionTime  Kruskal-Wallis  17.786615  0.402421   \n",
      "19  female    May20      peakTime  Kruskal-Wallis   9.790628  0.912160   \n",
      "20  female    May20    difference  Kruskal-Wallis  12.174134  0.789480   \n",
      "21    male  April16     peakValue           ANOVA   0.919715  0.558851   \n",
      "22    male  April16           RMS           ANOVA   0.821568  0.659758   \n",
      "23    male  April16           tau           ANOVA   0.710947  0.771511   \n",
      "24    male  April16           AUC           ANOVA   0.594058  0.874166   \n",
      "25    male  April16  reactionTime  Kruskal-Wallis  17.624789  0.412873   \n",
      "26    male  April16      peakTime  Kruskal-Wallis  12.128485  0.792295   \n",
      "27    male  April16    difference  Kruskal-Wallis  19.383479  0.306970   \n",
      "28    male   June26     peakValue           ANOVA   0.051114  1.000000   \n",
      "29    male   June26           RMS           ANOVA   0.049981  1.000000   \n",
      "30    male   June26           tau           ANOVA   0.109335  0.999994   \n",
      "31    male   June26           AUC           ANOVA   0.056134  1.000000   \n",
      "32    male   June26  reactionTime  Kruskal-Wallis   5.788087  0.994500   \n",
      "33    male   June26      peakTime  Kruskal-Wallis   6.762558  0.986420   \n",
      "34    male   June26    difference  Kruskal-Wallis   7.030577  0.983149   \n",
      "35    male    May20     peakValue           ANOVA   0.586804  0.879687   \n",
      "36    male    May20           RMS           ANOVA   0.227365  0.999021   \n",
      "37    male    May20           tau           ANOVA   0.047001  1.000000   \n",
      "38    male    May20           AUC           ANOVA   0.099310  0.999997   \n",
      "39    male    May20  reactionTime  Kruskal-Wallis  14.567068  0.626634   \n",
      "40    male    May20      peakTime  Kruskal-Wallis  20.352470  0.256599   \n",
      "41    male    May20    difference  Kruskal-Wallis  15.053194  0.591650   \n",
      "\n",
      "    significant posthoc_p posthoc_test  exp1  exp2 effect_strength mean_diff  \n",
      "0         False      None         None  None  None            None      None  \n",
      "1         False      None         None  None  None            None      None  \n",
      "2         False      None         None  None  None            None      None  \n",
      "3         False      None         None  None  None            None      None  \n",
      "4         False      None         None  None  None            None      None  \n",
      "5         False      None         None  None  None            None      None  \n",
      "6         False      None         None  None  None            None      None  \n",
      "7         False      None         None  None  None            None      None  \n",
      "8         False      None         None  None  None            None      None  \n",
      "9         False      None         None  None  None            None      None  \n",
      "10        False      None         None  None  None            None      None  \n",
      "11        False      None         None  None  None            None      None  \n",
      "12        False      None         None  None  None            None      None  \n",
      "13        False      None         None  None  None            None      None  \n",
      "14        False      None         None  None  None            None      None  \n",
      "15        False      None         None  None  None            None      None  \n",
      "16        False      None         None  None  None            None      None  \n",
      "17        False      None         None  None  None            None      None  \n",
      "18        False      None         None  None  None            None      None  \n",
      "19        False      None         None  None  None            None      None  \n",
      "20        False      None         None  None  None            None      None  \n",
      "21        False      None         None  None  None            None      None  \n",
      "22        False      None         None  None  None            None      None  \n",
      "23        False      None         None  None  None            None      None  \n",
      "24        False      None         None  None  None            None      None  \n",
      "25        False      None         None  None  None            None      None  \n",
      "26        False      None         None  None  None            None      None  \n",
      "27        False      None         None  None  None            None      None  \n",
      "28        False      None         None  None  None            None      None  \n",
      "29        False      None         None  None  None            None      None  \n",
      "30        False      None         None  None  None            None      None  \n",
      "31        False      None         None  None  None            None      None  \n",
      "32        False      None         None  None  None            None      None  \n",
      "33        False      None         None  None  None            None      None  \n",
      "34        False      None         None  None  None            None      None  \n",
      "35        False      None         None  None  None            None      None  \n",
      "36        False      None         None  None  None            None      None  \n",
      "37        False      None         None  None  None            None      None  \n",
      "38        False      None         None  None  None            None      None  \n",
      "39        False      None         None  None  None            None      None  \n",
      "40        False      None         None  None  None            None      None  \n",
      "41        False      None         None  None  None            None      None  \n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway, kruskal, mannwhitneyu\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "df = dfs['RESULTS_MTT_MERGED']\n",
    "strength_metrics = ['peakValue', 'RMS', 'tau', 'AUC']\n",
    "reaction_metrics = ['reactionTime', 'peakTime', 'difference']\n",
    "\n",
    "results = []\n",
    "\n",
    "for sex in df['sex'].unique():\n",
    "    for date in df['date'].unique():\n",
    "        df_sub = df[(df['sex'] == sex) & (df['date'] == date)]\n",
    "        # Parametric ANOVA for strength metrics\n",
    "        for metric in strength_metrics:\n",
    "            groups = [df_sub[df_sub['experiment'] == exp][metric].dropna() for exp in df_sub['experiment'].unique()]\n",
    "            groups = [g for g in groups if len(g) > 1]\n",
    "            mean_diff = None\n",
    "            if len(groups) > 1:\n",
    "                stat, p = f_oneway(*groups)\n",
    "                posthoc_p, posthoc_test, exp1, exp2, eff = None, None, None, None, None\n",
    "                if p < 0.05:\n",
    "                    try:\n",
    "                        tukey = pairwise_tukeyhsd(df_sub[metric].dropna(), df_sub['experiment'][df_sub[metric].notna()])\n",
    "                        min_p = tukey.pvalues.min()\n",
    "                        idx = tukey.pvalues.argmin()\n",
    "                        exp1, exp2 = tukey.groupsunique[tukey._multicomp.pairindices[idx][0]], tukey.groupsunique[tukey._multicomp.pairindices[idx][1]]\n",
    "                        vals1 = df_sub[df_sub['experiment'] == exp1][metric].dropna()\n",
    "                        vals2 = df_sub[df_sub['experiment'] == exp2][metric].dropna()\n",
    "                        pooled_std = ((vals1.std(ddof=1) ** 2 + vals2.std(ddof=1) ** 2) / 2) ** 0.5\n",
    "                        eff = (vals1.mean() - vals2.mean()) / pooled_std if pooled_std > 0 else None\n",
    "                        mean_diff = vals1.mean() - vals2.mean()\n",
    "                        posthoc_p = min_p\n",
    "                        posthoc_test = \"Tukey HSD\"\n",
    "                    except Exception:\n",
    "                        posthoc_p, posthoc_test, mean_diff = None, \"Tukey HSD\", None\n",
    "                results.append({\n",
    "                    'sex': sex,\n",
    "                    'date': date,\n",
    "                    'metric': metric,\n",
    "                    'test': 'ANOVA',\n",
    "                    'stat': stat,\n",
    "                    'p': p,\n",
    "                    'significant': p < 0.05,\n",
    "                    'posthoc_p': posthoc_p,\n",
    "                    'posthoc_test': posthoc_test,\n",
    "                    'exp1': exp1,\n",
    "                    'exp2': exp2,\n",
    "                    'effect_strength': eff,\n",
    "                    'mean_diff': mean_diff\n",
    "                })\n",
    "        # Non-parametric Kruskal-Wallis for reaction metrics\n",
    "        for metric in reaction_metrics:\n",
    "            groups = [df_sub[df_sub['experiment'] == exp][metric].dropna() for exp in df_sub['experiment'].unique()]\n",
    "            groups = [g for g in groups if len(g) > 1]\n",
    "            mean_diff = None\n",
    "            if len(groups) > 1:\n",
    "                stat, p = kruskal(*groups)\n",
    "                posthoc_p, posthoc_test, exp1, exp2, eff = None, None, None, None, None\n",
    "                if p < 0.05:\n",
    "                    try:\n",
    "                        dunn = sp.posthoc_dunn(df_sub, val_col=metric, group_col='experiment', p_adjust='bonferroni')\n",
    "                        min_p = dunn.replace(0, float('nan')).min().min()\n",
    "                        idx = dunn.stack().idxmin()\n",
    "                        exp1, exp2 = idx\n",
    "                        vals1 = df_sub[df_sub['experiment'] == exp1][metric].dropna()\n",
    "                        vals2 = df_sub[df_sub['experiment'] == exp2][metric].dropna()\n",
    "                        u, _ = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "                        n1, n2 = len(vals1), len(vals2)\n",
    "                        eff = 1 - (2 * u) / (n1 * n2)\n",
    "                        mean_diff = vals1.mean() - vals2.mean()\n",
    "                        posthoc_p = min_p\n",
    "                        posthoc_test = \"Dunn\"\n",
    "                    except Exception:\n",
    "                        posthoc_p, posthoc_test, mean_diff = None, \"Dunn\", None\n",
    "                results.append({\n",
    "                    'sex': sex,\n",
    "                    'date': date,\n",
    "                    'metric': metric,\n",
    "                    'test': 'Kruskal-Wallis',\n",
    "                    'stat': stat,\n",
    "                    'p': p,\n",
    "                    'significant': p < 0.05,\n",
    "                    'posthoc_p': posthoc_p,\n",
    "                    'posthoc_test': posthoc_test,\n",
    "                    'exp1': exp1,\n",
    "                    'exp2': exp2,\n",
    "                    'effect_strength': eff,\n",
    "                    'mean_diff': mean_diff\n",
    "                })\n",
    "\n",
    "test_experiment = pd.DataFrame(results)\n",
    "print(\"Experiment effects on metrics (parametric for strength, non-parametric for reaction metrics):\")\n",
    "print(test_experiment)\n",
    "\n",
    "test_experiment.to_excel(os.path.join(output_dir, \"TEST_EXPERIMENT.xlsx\"), index=False)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e1e8e",
   "metadata": {},
   "source": [
    "## Experiment Effects on Metrics (Grouped by Sex and Date)\n",
    "\n",
    "**Summary Table:**  \n",
    "No significant experiment effects were found for any metric (all p > 0.05) when grouping by sex and date.\n",
    "\n",
    "| Sex    | Date    | Metric        | Test            | Stat      | p-value   | Significant |\n",
    "|--------|---------|--------------|-----------------|-----------|-----------|-------------|\n",
    "| female | April16 | peakValue    | ANOVA           | 0.98      | 0.50      | False       |\n",
    "| female | April16 | RMS          | ANOVA           | 1.16      | 0.34      | False       |\n",
    "| ...    | ...     | ...          | ...             | ...       | ...       | ...         |\n",
    "| male   | May20   | difference   | Kruskal-Wallis  | 15.05     | 0.59      | False       |\n",
    "\n",
    "**Interpretation:**\n",
    "- Across all combinations of sex and date, **none of the strength metrics (peakValue, RMS, tau, AUC) nor reaction metrics (reactionTime, peakTime, difference) showed significant differences between experiments**.\n",
    "- All p-values are much greater than 0.05, indicating **no experiment effect** on these metrics after controlling for sex and date.\n",
    "- **Post hoc tests** were not performed since no primary test was significant.\n",
    "- **Conclusion:**  \n",
    "  - Experimental manipulations (e.g., gap durations, offset_PPI, tone_in_noise) do **not** significantly alter strength or reaction metrics when sex and date are controlled.\n",
    "  - **Date and sex effects are much stronger than experiment effects** in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38248481",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
